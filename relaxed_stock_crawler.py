#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¾å®½æ¡ä»¶è‚¡ç¥¨çˆ¬è™« - ä½¿ç”¨æ–°çš„å®½æ¾ç­›é€‰æ ‡å‡†è·å–æ›´å¤šè‚¡ç¥¨
ç­›é€‰æ¡ä»¶:
- æœ€ä½è‚¡ä»·: â‰¥$2.00
- æœ€å°å¸‚å€¼: â‰¥$70M  
- æœ€å°æ—¥å‡æˆäº¤é‡: â‰¥10Kè‚¡
- Betaå€¼èŒƒå›´: -4.0åˆ°+4.0
- ä¸è€ƒè™‘æ³¢åŠ¨ç‡å’Œè´¨é‡åˆ†å±‚
"""

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import time
import json
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RelaxedStockCrawler:
    """æ”¾å®½æ¡ä»¶çš„è‚¡ç¥¨çˆ¬è™«"""
    
    def __init__(self):
        self.all_symbols = set()
        self.stock_data = {}
        self.failed_symbols = set()
        
        # æ–°çš„å®½æ¾ç­›é€‰æ ‡å‡†
        self.filters = {
            'min_price': 2.0,           # æœ€ä½è‚¡ä»· $2.00
            'min_market_cap': 70_000_000,   # æœ€å°å¸‚å€¼ $70M
            'min_avg_volume': 10_000,   # æœ€å°æ—¥å‡æˆäº¤é‡ 10Kè‚¡
            'min_beta': -4.0,           # æœ€å°Beta
            'max_beta': 4.0             # æœ€å¤§Beta
            # åˆ é™¤: max_volatility (æ³¢åŠ¨ç‡ä¸å†è€ƒè™‘)
            # åˆ é™¤: è´¨é‡åˆ†å±‚æ ‡å‡†
        }
    
    def get_comprehensive_symbol_list(self):
        """è·å–comprehensiveè‚¡ç¥¨ç¬¦å·åˆ—è¡¨"""
        logger.info("æ­£åœ¨è·å–comprehensiveè‚¡ç¥¨ç¬¦å·åˆ—è¡¨...")
        
        symbols = set()
        
        # 1. S&P 500
        try:
            sp500_url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
            sp500_table = pd.read_html(sp500_url)[0]
            sp500_symbols = sp500_table['Symbol'].str.replace('.', '-').tolist()
            symbols.update(sp500_symbols)
            logger.info(f"è·å–S&P 500: {len(sp500_symbols)}åª")
        except Exception as e:
            logger.warning(f"è·å–S&P 500å¤±è´¥: {e}")
        
        # 2. NASDAQåˆ—è¡¨ (ä½¿ç”¨æ›´å…¨é¢çš„æ–¹æ³•)
        nasdaq_symbols = self.get_nasdaq_comprehensive()
        symbols.update(nasdaq_symbols)
        logger.info(f"è·å–NASDAQ: {len(nasdaq_symbols)}åª")
        
        # 3. çƒ­é—¨è‚¡ç¥¨è¡¥å……
        popular_stocks = [
            # å¤§å‹ç§‘æŠ€è‚¡
            'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'META', 'TSLA', 'NVDA', 'ORCL', 'CRM',
            'ADBE', 'NFLX', 'PYPL', 'INTC', 'CSCO', 'AMD', 'UBER', 'LYFT', 'SNOW', 'PLTR',
            
            # é‡‘èè‚¡
            'JPM', 'BAC', 'WFC', 'GS', 'MS', 'C', 'USB', 'PNC', 'TFC', 'COF',
            
            # åŒ»ç–—è‚¡
            'JNJ', 'PFE', 'UNH', 'ABBV', 'MRK', 'TMO', 'ABT', 'DHR', 'BMY', 'AMGN',
            
            # æ¶ˆè´¹è‚¡
            'PG', 'KO', 'PEP', 'WMT', 'HD', 'MCD', 'NKE', 'SBUX', 'TGT', 'LOW',
            
            # å·¥ä¸šè‚¡
            'GE', 'BA', 'CAT', 'MMM', 'HON', 'UPS', 'FDX', 'LMT', 'RTX', 'NOC',
            
            # èƒ½æºè‚¡
            'XOM', 'CVX', 'COP', 'EOG', 'SLB', 'MPC', 'VLO', 'PSX', 'BKR', 'HAL',
            
            # ä¸­æ¦‚è‚¡
            'BABA', 'JD', 'PDD', 'BIDU', 'NIO', 'XPEV', 'LI', 'BILI', 'IQ', 'TME',
            
            # ç”Ÿç‰©ç§‘æŠ€
            'MRNA', 'BNTX', 'NVAX', 'REGN', 'VRTX', 'BIIB', 'GILD', 'ILMN',
            
            # æ–°å…´è‚¡ç¥¨
            'RBLX', 'COIN', 'HOOD', 'SQ', 'AFRM', 'UPST', 'SOFI', 'PATH', 'DDOG', 'CRWD',
            
            # çƒ­é—¨ETFå’Œå…¶ä»–
            'SPY', 'QQQ', 'IWM', 'VTI', 'ARKK', 'GME', 'AMC', 'BB', 'NOK'
        ]
        
        symbols.update(popular_stocks)
        logger.info(f"æ·»åŠ çƒ­é—¨è‚¡ç¥¨: {len(popular_stocks)}åª")
        
        # 4. å°ç›˜è‚¡è¡¥å…… (Russell 2000æ ·æœ¬)
        small_cap_samples = [
            'ABCB', 'ACIW', 'ACLS', 'ADTN', 'AEYE', 'AGIO', 'AGNC', 'ALRM', 'ALRS', 'AMWD',
            'ANET', 'APOG', 'ARCT', 'ARDX', 'ARKR', 'ARRY', 'ARTL', 'ASML', 'ASTR', 'ATEC',
            'ATRO', 'AUPH', 'AVIR', 'AXDX', 'BAND', 'BCPC', 'BDTX', 'BEAM', 'BGCP', 'BILI',
            'BLFS', 'BMBL', 'BMRN', 'BOOT', 'BPMC', 'BRMK', 'BTAI', 'BURL', 'BYND', 'CACC',
            'CAKE', 'CALM', 'CARA', 'CARG', 'CARS', 'CASY', 'CBRL', 'CCMP', 'CDAY', 'CDMO',
            'CELH', 'CERS', 'CGEM', 'CHGG', 'CHWY', 'CLOV', 'CNMD', 'CODX', 'COHU', 'COLB',
            'CONN', 'CORT', 'COTY', 'COUR', 'CREE', 'CRSR', 'CRUS', 'CSOD', 'CTLT', 'CTRA',
            'CUTR', 'CVBF', 'CVCO', 'CVGW', 'CWST', 'CYBE', 'CYTH', 'DARE', 'DASH', 'DBVT',
            'DCBO', 'DCOM', 'DFIN', 'DGII', 'DISH', 'DNLI', 'DOCU', 'DOMO', 'DRNA', 'DSGX',
            'DVAX', 'DXCM', 'DYNT', 'EBON', 'ECHO', 'EDIT', 'EGOV', 'EHTH', 'EIGI', 'ELLI'
        ]
        
        symbols.update(small_cap_samples)
        logger.info(f"æ·»åŠ å°ç›˜è‚¡æ ·æœ¬: {len(small_cap_samples)}åª")
        
        total_symbols = list(symbols)
        logger.info(f"æ€»è®¡æ”¶é›†åˆ°: {len(total_symbols)}åªç‹¬ç‰¹è‚¡ç¥¨ç¬¦å·")
        
        return total_symbols
    
    def get_nasdaq_comprehensive(self):
        """è·å–æ›´å…¨é¢çš„NASDAQè‚¡ç¥¨åˆ—è¡¨"""
        symbols = set()
        
        try:
            # æ–¹æ³•1: ä½¿ç”¨NASDAQ API (å¤šä¸ªé¡µé¢)
            url = "https://api.nasdaq.com/api/screener/stocks"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            for offset in range(0, 6000, 25):  # è·å–æ›´å¤šé¡µé¢
                params = {
                    'tableonly': 'true',
                    'limit': '25',
                    'offset': str(offset)
                }
                
                try:
                    response = requests.get(url, headers=headers, params=params, timeout=10)
                    if response.status_code == 200:
                        data = response.json()
                        
                        if 'data' in data and 'table' in data['data']:
                            rows = data['data']['table']['rows']
                            if not rows:
                                break
                                
                            for row in rows:
                                symbol = row.get('symbol', '').strip()
                                if symbol and len(symbol) <= 5:
                                    symbols.add(symbol)
                            
                            if offset % 500 == 0:
                                logger.info(f"NASDAQ API: å·²è·å– {len(symbols)} åªè‚¡ç¥¨ (offset: {offset})")
                        else:
                            break
                    else:
                        break
                        
                except Exception as e:
                    logger.debug(f"NASDAQ APIè¯·æ±‚å¤±è´¥ offset {offset}: {e}")
                    break
                
                time.sleep(0.1)
                
        except Exception as e:
            logger.warning(f"NASDAQ APIè·å–å¤±è´¥: {e}")
        
        return symbols
    
    def download_stock_data(self, symbol):
        """ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ® - ä½¿ç”¨æ–°çš„å®½æ¾ç­›é€‰æ ‡å‡†"""
        try:
            ticker = yf.Ticker(symbol)
            
            # è·å–åŸºæœ¬ä¿¡æ¯
            info = ticker.info
            if not info or len(info) < 3:
                return None
            
            # è·å–å†å²æ•°æ® (å‡å°‘åˆ°3ä¸ªæœˆæé«˜é€Ÿåº¦)
            hist = ticker.history(period="3mo")
            if hist.empty or len(hist) < 10:
                return None
            
            # æå–åŸºæœ¬ä¿¡æ¯
            price = info.get('currentPrice') or info.get('regularMarketPrice')
            if not price:
                price = hist['Close'].iloc[-1]
            
            if not price or price <= 0:
                return None
            
            # åº”ç”¨æ–°çš„å®½æ¾ç­›é€‰æ ‡å‡†
            
            # 1. è‚¡ä»·ç­›é€‰ (â‰¥$2.00)
            if price < self.filters['min_price']:
                return None
            
            # 2. å¸‚å€¼ç­›é€‰ (â‰¥$70M)
            market_cap = info.get('marketCap', 0)
            if market_cap < self.filters['min_market_cap']:
                return None
            
            # 3. æˆäº¤é‡ç­›é€‰ (â‰¥10K)
            volume = hist['Volume'].tail(10).mean()
            if volume < self.filters['min_avg_volume']:
                return None
            
            # 4. Betaå€¼ç­›é€‰ (-4.0 åˆ° +4.0)
            beta = info.get('beta')
            if beta is not None:
                if beta < self.filters['min_beta'] or beta > self.filters['max_beta']:
                    return None
            else:
                beta = 1.0  # é»˜è®¤å€¼
            
            # ä¸å†è®¡ç®—æ³¢åŠ¨ç‡ (åˆ é™¤äº†æ³¢åŠ¨ç‡ç­›é€‰)
            
            stock_data = {
                'symbol': symbol,
                'name': str(info.get('longName', info.get('shortName', symbol)))[:50],
                'sector': str(info.get('sector', 'Unknown'))[:30],
                'industry': str(info.get('industry', 'Unknown'))[:50],
                'market_cap': float(market_cap) if market_cap else 0,
                'price': float(price),
                'volume': float(volume) if volume > 0 else 0,
                'beta': float(beta),
                'exchange': str(info.get('exchange', 'Unknown')),
                'currency': str(info.get('currency', 'USD')),
                'country': str(info.get('country', 'US')),
                'updated_at': datetime.now().isoformat(),
                'meets_criteria': True  # æ‰€æœ‰é€šè¿‡ç­›é€‰çš„éƒ½æ ‡è®°ä¸ºç¬¦åˆæ ‡å‡†
            }
            
            return stock_data
            
        except Exception as e:
            logger.debug(f"è·å– {symbol} æ•°æ®å¤±è´¥: {e}")
            return None
    
    def download_all_data(self, symbols):
        """å¹¶å‘ä¸‹è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®"""
        logger.info(f"å¼€å§‹ä¸‹è½½ {len(symbols)} åªè‚¡ç¥¨çš„æ•°æ®...")
        
        successful_count = 0
        failed_count = 0
        
        # ä½¿ç”¨æ›´å¤šçº¿ç¨‹åŠ é€Ÿ
        with ThreadPoolExecutor(max_workers=15) as executor:
            future_to_symbol = {executor.submit(self.download_stock_data, symbol): symbol 
                              for symbol in symbols}
            
            for i, future in enumerate(as_completed(future_to_symbol), 1):
                symbol = future_to_symbol[future]
                
                try:
                    data = future.result(timeout=20)
                    if data:
                        self.stock_data[symbol] = data
                        successful_count += 1
                    else:
                        self.failed_symbols.add(symbol)
                        failed_count += 1
                        
                except Exception as e:
                    self.failed_symbols.add(symbol)
                    failed_count += 1
                    logger.debug(f"{symbol} å¤„ç†å¼‚å¸¸: {e}")
                
                if i % 200 == 0:
                    logger.info(f"è¿›åº¦: {i}/{len(symbols)}, æˆåŠŸ: {successful_count}, å¤±è´¥: {failed_count}")
        
        logger.info(f"æ•°æ®ä¸‹è½½å®Œæˆ! æˆåŠŸ: {successful_count}, å¤±è´¥: {failed_count}")
        return successful_count
    
    def save_results(self):
        """ä¿å­˜ç»“æœ - ä¸å†åˆ†å±‚ï¼Œæ‰€æœ‰è‚¡ç¥¨ç»Ÿä¸€å¤„ç†"""
        logger.info("æ­£åœ¨ä¿å­˜ç»“æœ...")
        
        os.makedirs("relaxed_stock_data", exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æŒ‰è¡Œä¸šåˆ†ç±»ä½†ä¸åˆ†è´¨é‡å±‚çº§
        stocks_by_sector = {}
        for symbol, data in self.stock_data.items():
            sector = data.get('sector', 'Unknown')
            if sector not in stocks_by_sector:
                stocks_by_sector[sector] = []
            stocks_by_sector[sector].append(data)
        
        # æŒ‰å¸‚å€¼æ’åºæ¯ä¸ªè¡Œä¸šçš„è‚¡ç¥¨
        for sector in stocks_by_sector:
            stocks_by_sector[sector].sort(key=lambda x: x['market_cap'], reverse=True)
        
        # ä¿å­˜æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
        all_qualified_stocks = list(self.stock_data.values())
        all_qualified_stocks.sort(key=lambda x: x['market_cap'], reverse=True)
        
        # ä¿å­˜è‚¡ç¥¨åˆ—è¡¨æ–‡ä»¶
        txt_file = f"relaxed_stock_data/all_qualified_stocks_{timestamp}.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"# æ”¾å®½æ¡ä»¶è‚¡ç¥¨åˆ—è¡¨\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# ç­›é€‰æ ‡å‡†: è‚¡ä»·â‰¥$2.00, å¸‚å€¼â‰¥$70M, æˆäº¤é‡â‰¥10K, -4â‰¤Betaâ‰¤4\n")
            f.write(f"# è‚¡ç¥¨æ•°é‡: {len(all_qualified_stocks)} åª\n\n")
            
            for stock in all_qualified_stocks:
                f.write(f"{stock['symbol']}\n")
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        json_file = f"relaxed_stock_data/all_qualified_details_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(all_qualified_stocks, f, indent=2, ensure_ascii=False, default=str)
        
        # æŒ‰è¡Œä¸šä¿å­˜
        sector_file = f"relaxed_stock_data/stocks_by_sector_{timestamp}.json"
        with open(sector_file, 'w', encoding='utf-8') as f:
            json.dump(stocks_by_sector, f, indent=2, ensure_ascii=False, default=str)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(all_qualified_stocks, stocks_by_sector, timestamp)
        
        logger.info(f"ä¿å­˜å®Œæˆ: {len(all_qualified_stocks)} åªè‚¡ç¥¨")
        return all_qualified_stocks, txt_file, json_file
    
    def generate_report(self, stocks, sectors, timestamp):
        """ç”ŸæˆæŠ¥å‘Š"""
        report = f"""# æ”¾å®½æ¡ä»¶è‚¡ç¥¨çˆ¬è™«æŠ¥å‘Š

## çˆ¬å–æ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ æ–°ç­›é€‰æ ‡å‡† (æ”¾å®½æ¡ä»¶)
- **æœ€ä½è‚¡ä»·**: â‰¥$2.00 (é¿å…ä»™è‚¡)
- **æœ€å°å¸‚å€¼**: â‰¥$70M (å¤§å¹…é™ä½ï¼ŒåŒ…å«æ›´å¤šå°ç›˜è‚¡)
- **æœ€å°æ—¥å‡æˆäº¤é‡**: â‰¥10Kè‚¡ (å¤§å¹…é™ä½ï¼Œç¡®ä¿åŸºæœ¬æµåŠ¨æ€§)
- **Betaå€¼èŒƒå›´**: -4.0åˆ°+4.0 (åˆç†çš„å¸‚åœºæ•æ„Ÿåº¦)
- **å·²åˆ é™¤**: ä¸å†è€ƒè™‘æ³¢åŠ¨ç‡ç­›é€‰
- **å·²åˆ é™¤**: ä¸å†è¿›è¡Œè´¨é‡åˆ†å±‚ï¼Œç»Ÿä¸€å¤„ç†

## ğŸ“Š çˆ¬å–ç»“æœ
- **æ€»çˆ¬å–è‚¡ç¥¨æ•°**: {len(self.stock_data):,}
- **ç¬¦åˆæ¡ä»¶è‚¡ç¥¨æ•°**: {len(stocks):,}
- **ç­›é€‰é€šè¿‡ç‡**: {len(stocks)/len(self.stock_data)*100:.1f}%
- **å¤±è´¥è‚¡ç¥¨æ•°**: {len(self.failed_symbols):,}

## ğŸ¢ è¡Œä¸šåˆ†å¸ƒ
"""
        
        for sector, sector_stocks in sorted(sectors.items(), key=lambda x: len(x[1]), reverse=True):
            report += f"- **{sector}**: {len(sector_stocks)} åªè‚¡ç¥¨\n"
        
        report += f"""
## ğŸ’° å¸‚å€¼åˆ†å¸ƒ
"""
        
        # å¸‚å€¼ç»Ÿè®¡
        market_caps = [s['market_cap'] for s in stocks if s['market_cap'] > 0]
        if market_caps:
            report += f"- **æœ€å¤§å¸‚å€¼**: ${max(market_caps)/1e9:.1f}B\n"
            report += f"- **æœ€å°å¸‚å€¼**: ${min(market_caps)/1e6:.1f}M\n"
            report += f"- **å¹³å‡å¸‚å€¼**: ${sum(market_caps)/len(market_caps)/1e6:.1f}M\n"
        
        # å¸‚å€¼åˆ†æ®µç»Ÿè®¡
        mega_cap = len([s for s in stocks if s['market_cap'] >= 200e9])  # â‰¥$200B
        large_cap = len([s for s in stocks if 10e9 <= s['market_cap'] < 200e9])  # $10B-$200B
        mid_cap = len([s for s in stocks if 2e9 <= s['market_cap'] < 10e9])    # $2B-$10B
        small_cap = len([s for s in stocks if 300e6 <= s['market_cap'] < 2e9])  # $300M-$2B
        micro_cap = len([s for s in stocks if 70e6 <= s['market_cap'] < 300e6]) # $70M-$300M
        
        report += f"""
### å¸‚å€¼åˆ†æ®µç»Ÿè®¡
- **å·¨å‹è‚¡** (â‰¥$200B): {mega_cap} åª
- **å¤§ç›˜è‚¡** ($10B-$200B): {large_cap} åª  
- **ä¸­ç›˜è‚¡** ($2B-$10B): {mid_cap} åª
- **å°ç›˜è‚¡** ($300M-$2B): {small_cap} åª
- **å¾®ç›˜è‚¡** ($70M-$300M): {micro_cap} åª

## ğŸ“ˆ è‚¡ä»·åˆ†å¸ƒ
"""
        
        prices = [s['price'] for s in stocks]
        if prices:
            under_5 = len([p for p in prices if p < 5])
            under_10 = len([p for p in prices if 5 <= p < 10])
            under_50 = len([p for p in prices if 10 <= p < 50])
            under_100 = len([p for p in prices if 50 <= p < 100])
            over_100 = len([p for p in prices if p >= 100])
            
            report += f"- **$2-$5**: {under_5} åª\n"
            report += f"- **$5-$10**: {under_10} åª\n"
            report += f"- **$10-$50**: {under_50} åª\n"
            report += f"- **$50-$100**: {under_100} åª\n"
            report += f"- **â‰¥$100**: {over_100} åª\n"
        
        report += f"""
## ğŸ” å‰20åªè‚¡ç¥¨ (æŒ‰å¸‚å€¼)
"""
        
        top_20 = sorted(stocks, key=lambda x: x['market_cap'], reverse=True)[:20]
        for i, stock in enumerate(top_20, 1):
            report += f"{i:2d}. {stock['symbol']:5s} - {stock['name'][:30]:30s} - ${stock['market_cap']/1e9:.1f}B\n"
        
        report += f"""
## ğŸ“ ç”Ÿæˆæ–‡ä»¶
- `relaxed_stock_data/all_qualified_stocks_{timestamp}.txt` - æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨åˆ—è¡¨
- `relaxed_stock_data/all_qualified_details_{timestamp}.json` - è¯¦ç»†è‚¡ç¥¨æ•°æ®
- `relaxed_stock_data/stocks_by_sector_{timestamp}.json` - æŒ‰è¡Œä¸šåˆ†ç±»æ•°æ®

---
ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}
ç­›é€‰æ ‡å‡†: å¤§å¹…æ”¾å®½ï¼Œæ¶µç›–æ›´å¤šè‚¡ç¥¨
"""
        
        report_file = f"relaxed_stock_data/RELAXED_CRAWLER_REPORT_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("æ”¾å®½æ¡ä»¶è‚¡ç¥¨çˆ¬è™« - è·å–æ›´å¤šè‚¡ç¥¨")
    print("=" * 70)
    print("æ–°ç­›é€‰æ ‡å‡†:")
    print("- æœ€ä½è‚¡ä»·: â‰¥$2.00")
    print("- æœ€å°å¸‚å€¼: â‰¥$70M")  
    print("- æœ€å°æ—¥å‡æˆäº¤é‡: â‰¥10Kè‚¡")
    print("- Betaå€¼èŒƒå›´: -4.0åˆ°+4.0")
    print("- ä¸è€ƒè™‘æ³¢åŠ¨ç‡å’Œè´¨é‡åˆ†å±‚")
    print("=" * 70)
    
    crawler = RelaxedStockCrawler()
    
    try:
        # 1. æ”¶é›†è‚¡ç¥¨ç¬¦å·
        logger.info("ç¬¬ä¸€æ­¥: æ”¶é›†è‚¡ç¥¨ç¬¦å·...")
        all_symbols = crawler.get_comprehensive_symbol_list()
        
        if len(all_symbols) < 100:
            logger.error("æ”¶é›†åˆ°çš„è‚¡ç¥¨ç¬¦å·å¤ªå°‘ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            return False
        
        # 2. ä¸‹è½½æ•°æ®
        logger.info("ç¬¬äºŒæ­¥: ä¸‹è½½è‚¡ç¥¨æ•°æ®...")
        success_count = crawler.download_all_data(all_symbols)
        
        if success_count == 0:
            logger.error("æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•è‚¡ç¥¨æ•°æ®")
            return False
        
        # 3. ä¿å­˜ç»“æœ
        logger.info("ç¬¬ä¸‰æ­¥: ä¿å­˜ç»“æœ...")
        qualified_stocks, txt_file, json_file = crawler.save_results()
        
        # 4. æ˜¾ç¤ºæ€»ç»“
        print("\n" + "=" * 70)
        print("æ”¾å®½æ¡ä»¶çˆ¬è™«å®Œæˆ!")
        print("=" * 70)
        print(f"æ€»çˆ¬å–: {len(crawler.stock_data):,} åªè‚¡ç¥¨")
        print(f"ç¬¦åˆæ¡ä»¶: {len(qualified_stocks):,} åªè‚¡ç¥¨")
        print(f"å¤±è´¥: {len(crawler.failed_symbols):,} åªè‚¡ç¥¨")
        
        # æ˜¾ç¤ºå¸‚å€¼åˆ†å¸ƒ
        if qualified_stocks:
            market_caps = [s['market_cap'] for s in qualified_stocks if s['market_cap'] > 0]
            if market_caps:
                print(f"\nå¸‚å€¼èŒƒå›´: ${min(market_caps)/1e6:.0f}M - ${max(market_caps)/1e9:.1f}B")
                
                mega_cap = len([s for s in qualified_stocks if s['market_cap'] >= 200e9])
                large_cap = len([s for s in qualified_stocks if 10e9 <= s['market_cap'] < 200e9])
                mid_cap = len([s for s in qualified_stocks if 2e9 <= s['market_cap'] < 10e9])
                small_cap = len([s for s in qualified_stocks if 300e6 <= s['market_cap'] < 2e9])
                micro_cap = len([s for s in qualified_stocks if s['market_cap'] < 300e6])
                
                print(f"å·¨å‹è‚¡: {mega_cap}, å¤§ç›˜è‚¡: {large_cap}, ä¸­ç›˜è‚¡: {mid_cap}")
                print(f"å°ç›˜è‚¡: {small_cap}, å¾®ç›˜è‚¡: {micro_cap}")
        
        print(f"\nç»“æœæ–‡ä»¶:")
        print(f"- {txt_file}")
        print(f"- {json_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"çˆ¬è™«æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… æ”¾å®½æ¡ä»¶çˆ¬è™«æˆåŠŸ! è·å¾—æ›´å¤šè‚¡ç¥¨ç”¨äºæ¨¡å‹è®­ç»ƒã€‚")
    else:
        print("\nâŒ çˆ¬è™«å¤±è´¥!")