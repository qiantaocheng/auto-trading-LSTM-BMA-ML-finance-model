#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Comprehensive Model Backtest - 完整的模型回测分析
================================================================
使用已训练模型在allfac数据上做滚动预测，分别统计每个模型的性能

任务：
1. 加载最新模型快照 (ElasticNet, XGBoost, CatBoost, LambdaRank, Ridge Stacking)
2. 在allfac数据上每周做一次预测
3. 确保时间正确分割（防止信息泄漏）
4. 分别统计每个模型的性能：
   - IC & Rank IC
   - MSE/MAE/R²
   - Top 20% / Bottom 20% 分组收益
5. 对比Nasdaq的T+10收益
"""

import os
import sys
import json
import logging
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
from scipy.stats import spearmanr, pearsonr
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

warnings.filterwarnings('ignore')

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ComprehensiveModelBacktest:
    """完整的模型回测分析"""

    def __init__(self, data_dir: str = "data/factor_exports/allfac"):
        """
        初始化回测引擎

        Args:
            data_dir: allfac数据目录
        """
        self.data_dir = data_dir
        self.models = {}
        self.ridge_stacker = None
        self.lambda_rank_stacker = None
        self.lambda_percentile_transformer = None
        self.snapshot_id = None

        # Feature mappings for each model
        self.model_features = {}

        # 加载模型
        self._load_models()
        self._extract_model_features()

    def _load_models(self):
        """加载最新的模型快照"""
        logger.info("=" * 80)
        logger.info("📦 加载最新模型快照")
        logger.info("=" * 80)

        try:
            from bma_models.model_registry import load_manifest, load_models_from_snapshot

            # Load latest snapshot
            manifest = load_manifest(snapshot_id=None)  # None = latest
            self.snapshot_id = manifest['snapshot_id']

            logger.info(f"快照ID: {self.snapshot_id}")
            logger.info(f"创建时间: {datetime.fromtimestamp(manifest['created_at']).strftime('%Y-%m-%d %H:%M:%S')}")

            # Load all models
            loaded = load_models_from_snapshot(self.snapshot_id)

            self.models = loaded['models']
            self.ridge_stacker = loaded.get('ridge_stacker')
            self.lambda_rank_stacker = loaded.get('lambda_rank_stacker')
            self.lambda_percentile_transformer = loaded.get('lambda_percentile_transformer')

            # Count loaded models
            model_names = []
            if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
                model_names.append("ElasticNet")
            if 'xgboost' in self.models and self.models['xgboost'] is not None:
                model_names.append("XGBoost")
            if 'catboost' in self.models and self.models['catboost'] is not None:
                model_names.append("CatBoost")
            if self.lambda_rank_stacker is not None:
                model_names.append("LambdaRank")
            if self.ridge_stacker is not None:
                model_names.append("Ridge Stacking")

            logger.info(f"✅ 成功加载 {len(model_names)} 个模型: {', '.join(model_names)}")
            logger.info("=" * 80)

        except Exception as e:
            logger.error(f"❌ 模型加载失败: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    def _extract_model_features(self):
        """提取每个模型期望的特征列表"""
        logger.info("提取模型特征信息...")

        # ElasticNet
        if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
            en = self.models['elastic_net']
            if hasattr(en, 'feature_names_in_'):
                self.model_features['elastic_net'] = list(en.feature_names_in_)
                logger.info(f"  ElasticNet: {len(self.model_features['elastic_net'])} features")

        # XGBoost
        if 'xgboost' in self.models and self.models['xgboost'] is not None:
            xgb = self.models['xgboost']
            if hasattr(xgb, 'get_booster'):
                booster = xgb.get_booster()
                self.model_features['xgboost'] = booster.feature_names
                logger.info(f"  XGBoost: {len(self.model_features['xgboost'])} features")

        # CatBoost
        if 'catboost' in self.models and self.models['catboost'] is not None:
            cat = self.models['catboost']
            if hasattr(cat, 'feature_names_'):
                self.model_features['catboost'] = list(cat.feature_names_)
                logger.info(f"  CatBoost: {len(self.model_features['catboost'])} features")

        # LambdaRank - use same as XGBoost/CatBoost
        if self.lambda_rank_stacker is not None:
            if 'xgboost' in self.model_features:
                self.model_features['lambdarank'] = self.model_features['xgboost']
                logger.info(f"  LambdaRank: using same features as XGBoost")

    def load_allfac_data(self) -> pd.DataFrame:
        """
        加载所有allfac数据

        Returns:
            合并后的完整数据集
        """
        logger.info("📊 加载allfac数据...")

        # Read manifest
        manifest_path = os.path.join(self.data_dir, "manifest.parquet")
        manifest = pd.read_parquet(manifest_path)

        logger.info(f"发现 {len(manifest)} 个批次文件")

        # Load all batches
        all_data = []
        for idx, row in manifest.iterrows():
            batch_id = row['batch_id']
            batch_file = os.path.join(self.data_dir, f"polygon_factors_batch_{batch_id:04d}.parquet")

            if os.path.exists(batch_file):
                batch_data = pd.read_parquet(batch_file)
                all_data.append(batch_data)
                logger.info(f"  ✅ Batch {batch_id}: {batch_data.shape}")

        # Concatenate all batches
        full_data = pd.concat(all_data, axis=0)

        # Sort by date
        full_data = full_data.sort_index()

        logger.info(f"✅ 总数据: {full_data.shape}")
        logger.info(f"   日期范围: {full_data.index.get_level_values('date').min()} 至 {full_data.index.get_level_values('date').max()}")
        logger.info(f"   股票数量: {full_data.index.get_level_values('ticker').nunique()}")

        return full_data

    def get_weekly_dates(self, data: pd.DataFrame) -> List[pd.Timestamp]:
        """
        获取每周的预测日期（每周一）

        Args:
            data: 完整数据集

        Returns:
            每周一的日期列表
        """
        all_dates = data.index.get_level_values('date').unique().sort_values()

        # Convert to datetime
        all_dates = pd.to_datetime(all_dates)

        # Get weekly dates (Monday of each week)
        weekly_dates = []
        current_week = None

        for date in all_dates:
            week = date.isocalendar()[1]  # Week number
            year = date.year
            week_key = (year, week)

            if week_key != current_week:
                weekly_dates.append(date)
                current_week = week_key

        logger.info(f"📅 生成 {len(weekly_dates)} 个每周预测日期")

        return weekly_dates

    def predict_single_model(self,
                            model_name: str,
                            model,
                            X: pd.DataFrame,
                            required_features: List[str] = None) -> pd.Series:
        """
        使用单个模型进行预测

        Args:
            model_name: 模型名称
            model: 模型对象
            X: 特征矩阵（包含所有可用特征）
            required_features: 模型需要的特征列表

        Returns:
            预测结果 (pd.Series)
        """
        try:
            if model is None:
                logger.warning(f"⚠️ {model_name} 模型为空")
                return None

            # Select only required features
            if required_features is not None:
                X_model = X[required_features].copy()
            else:
                X_model = X.copy()

            # Make prediction
            if model_name == 'lambdarank':
                # LambdaRank may need special handling
                predictions = model.predict(X_model)

                # Apply percentile transformer if available
                if self.lambda_percentile_transformer is not None:
                    predictions = self.lambda_percentile_transformer.transform(predictions)
            else:
                predictions = model.predict(X_model)

            # Convert to Series with same index as X
            pred_series = pd.Series(predictions, index=X.index, name=model_name)

            return pred_series

        except Exception as e:
            logger.error(f"❌ {model_name} 预测失败: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def rolling_prediction(self, data: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """
        滚动预测：在每个时间点使用可用数据进行预测

        Args:
            data: 完整数据集（包含target）

        Returns:
            每个模型的预测结果字典 {model_name: predictions_df}
        """
        logger.info("=" * 80)
        logger.info("🔮 开始滚动预测")
        logger.info("=" * 80)

        # Get weekly dates
        weekly_dates = self.get_weekly_dates(data)

        # Get all available features from data (exclude target and Close)
        all_feature_cols = [col for col in data.columns if col not in ['target', 'Close']]
        logger.info(f"数据包含 {len(all_feature_cols)} 个特征")

        # Initialize results storage
        all_predictions = {
            'elastic_net': [],
            'xgboost': [],
            'catboost': [],
            'lambdarank': [],
            'ridge_stacking': []
        }

        # Rolling prediction
        for i, pred_date in enumerate(weekly_dates):
            # Get features for this exact date (for prediction)
            try:
                # Use xs to cross-section by date (drop_level=True to get ticker index only)
                date_data = data.xs(pred_date, level='date', drop_level=True)
            except KeyError:
                # This date might not exist in the index
                continue

            if len(date_data) == 0:
                continue

            # Prepare features - use all available features
            X = date_data[all_feature_cols].copy()
            X = X.fillna(0)  # Fill NaN same as training

            # Get actual target (for later evaluation)
            if 'target' in date_data.columns:
                actual_target = date_data['target']
            else:
                actual_target = pd.Series(np.nan, index=date_data.index)

            # Get tickers for this date
            tickers = date_data.index.tolist()

            # Predict with each model (using model-specific features)
            # 1. ElasticNet
            if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
                required_features = self.model_features.get('elastic_net')
                pred = self.predict_single_model('elastic_net', self.models['elastic_net'], X, required_features)
                if pred is not None:
                    pred_df = pd.DataFrame({
                        'date': pred_date,
                        'ticker': tickers,
                        'prediction': pred.values,
                        'actual': actual_target.values
                    })
                    all_predictions['elastic_net'].append(pred_df)

            # 2. XGBoost
            if 'xgboost' in self.models and self.models['xgboost'] is not None:
                required_features = self.model_features.get('xgboost')
                pred = self.predict_single_model('xgboost', self.models['xgboost'], X, required_features)
                if pred is not None:
                    pred_df = pd.DataFrame({
                        'date': pred_date,
                        'ticker': tickers,
                        'prediction': pred.values,
                        'actual': actual_target.values
                    })
                    all_predictions['xgboost'].append(pred_df)

            # 3. CatBoost
            if 'catboost' in self.models and self.models['catboost'] is not None:
                required_features = self.model_features.get('catboost')
                pred = self.predict_single_model('catboost', self.models['catboost'], X, required_features)
                if pred is not None:
                    pred_df = pd.DataFrame({
                        'date': pred_date,
                        'ticker': tickers,
                        'prediction': pred.values,
                        'actual': actual_target.values
                    })
                    all_predictions['catboost'].append(pred_df)

            # 4. LambdaRank
            # TODO: Fix alpha_factor_cols issue before enabling
            # if self.lambda_rank_stacker is not None:
            #     required_features = self.model_features.get('lambdarank')
            #     pred = self.predict_single_model('lambdarank', self.lambda_rank_stacker, X, required_features)
            #     if pred is not None:
            #         pred_df = pd.DataFrame({
            #             'date': pred_date,
            #             'ticker': tickers,
            #             'prediction': pred.values,
            #             'actual': actual_target.values
            #         })
            #         all_predictions['lambdarank'].append(pred_df)

            # 5. Ridge Stacking (combine first 4 models)
            if self.ridge_stacker is not None:
                # Create stacking features
                stacking_features = pd.DataFrame(index=X.index)

                # Note: RidgeStacker expects specific column names from training
                if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
                    en_features = self.model_features.get('elastic_net')
                    en_pred = self.predict_single_model('elastic_net', self.models['elastic_net'], X, en_features)
                    if en_pred is not None:
                        stacking_features['pred_elastic'] = en_pred  # Ridge expects 'pred_elastic'

                if 'xgboost' in self.models and self.models['xgboost'] is not None:
                    xgb_features = self.model_features.get('xgboost')
                    xgb_pred = self.predict_single_model('xgboost', self.models['xgboost'], X, xgb_features)
                    if xgb_pred is not None:
                        stacking_features['pred_xgb'] = xgb_pred  # Ridge expects 'pred_xgb'

                if 'catboost' in self.models and self.models['catboost'] is not None:
                    cat_features = self.model_features.get('catboost')
                    cat_pred = self.predict_single_model('catboost', self.models['catboost'], X, cat_features)
                    if cat_pred is not None:
                        stacking_features['pred_catboost'] = cat_pred  # Ridge expects 'pred_catboost'

                # TODO: Fix LambdaRank alpha_factor_cols issue before enabling
                # if self.lambda_rank_stacker is not None:
                #     lambda_features = self.model_features.get('lambdarank')
                #     lambda_pred = self.predict_single_model('lambdarank', self.lambda_rank_stacker, X, lambda_features)
                #     if lambda_pred is not None:
                #         stacking_features['lambdarank'] = lambda_pred

                if len(stacking_features.columns) > 0:
                    # RidgeStacker expects MultiIndex (date, ticker)
                    stacking_features_with_date = stacking_features.copy()
                    stacking_features_with_date.index = pd.MultiIndex.from_arrays(
                        [[pred_date] * len(tickers), tickers],
                        names=['date', 'ticker']
                    )

                    ridge_pred = self.ridge_stacker.predict(stacking_features_with_date)

                    # Ensure ridge_pred is 1D
                    if isinstance(ridge_pred, pd.DataFrame):
                        ridge_pred = ridge_pred.values.ravel()
                    elif isinstance(ridge_pred, pd.Series):
                        ridge_pred = ridge_pred.values
                    elif isinstance(ridge_pred, np.ndarray) and ridge_pred.ndim > 1:
                        ridge_pred = ridge_pred.ravel()

                    pred_df = pd.DataFrame({
                        'date': pred_date,
                        'ticker': tickers,
                        'prediction': ridge_pred,
                        'actual': actual_target.values
                    })
                    all_predictions['ridge_stacking'].append(pred_df)

            if (i + 1) % 10 == 0:
                logger.info(f"  进度: {i+1}/{len(weekly_dates)} ({(i+1)/len(weekly_dates)*100:.1f}%)")

        # Concatenate all predictions
        results = {}
        for model_name, pred_list in all_predictions.items():
            if len(pred_list) > 0:
                results[model_name] = pd.concat(pred_list, axis=0, ignore_index=True)
                logger.info(f"✅ {model_name}: {len(results[model_name])} 条预测")

        logger.info("=" * 80)
        return results

    def calculate_metrics(self, predictions: pd.DataFrame) -> Dict:
        """
        计算性能指标

        Args:
            predictions: 预测结果 DataFrame (date, ticker, prediction, actual)

        Returns:
            性能指标字典
        """
        # Remove NaN
        valid_data = predictions.dropna(subset=['prediction', 'actual'])

        if len(valid_data) == 0:
            logger.warning("⚠️ 没有有效的预测数据")
            return {}

        y_true = valid_data['actual'].values
        y_pred = valid_data['prediction'].values

        # Calculate metrics
        metrics = {}

        # IC (Pearson correlation)
        ic, ic_pval = pearsonr(y_pred, y_true)
        metrics['IC'] = ic
        metrics['IC_pvalue'] = ic_pval

        # Rank IC (Spearman correlation)
        rank_ic, rank_ic_pval = spearmanr(y_pred, y_true)
        metrics['Rank_IC'] = rank_ic
        metrics['Rank_IC_pvalue'] = rank_ic_pval

        # MSE, MAE, R²
        metrics['MSE'] = mean_squared_error(y_true, y_pred)
        metrics['MAE'] = mean_absolute_error(y_true, y_pred)
        metrics['R2'] = r2_score(y_true, y_pred)

        return metrics

    def calculate_group_returns(self, predictions: pd.DataFrame, quantile: float = 0.2) -> Dict:
        """
        计算分组收益（Top/Bottom quantile）

        Args:
            predictions: 预测结果 DataFrame
            quantile: 分位数（默认0.2表示Top/Bottom 20%）

        Returns:
            分组收益字典
        """
        results = []

        # Group by date
        for date, date_group in predictions.groupby('date'):
            # Remove NaN
            valid_group = date_group.dropna(subset=['prediction', 'actual'])

            if len(valid_group) < 10:  # Need minimum stocks
                continue

            # Sort by prediction
            sorted_group = valid_group.sort_values('prediction', ascending=False)

            # Calculate quantile thresholds
            n_top = max(1, int(len(sorted_group) * quantile))
            n_bottom = max(1, int(len(sorted_group) * quantile))

            # Get top and bottom groups
            top_group = sorted_group.head(n_top)
            bottom_group = sorted_group.tail(n_bottom)

            # Calculate average returns
            top_return = top_group['actual'].mean()
            bottom_return = bottom_group['actual'].mean()
            all_return = sorted_group['actual'].mean()

            results.append({
                'date': date,
                'top_return': top_return,
                'bottom_return': bottom_return,
                'all_return': all_return,
                'long_short': top_return - bottom_return
            })

        if len(results) == 0:
            return {}

        results_df = pd.DataFrame(results)

        # Calculate summary statistics
        summary = {
            'avg_top_return': results_df['top_return'].mean(),
            'avg_bottom_return': results_df['bottom_return'].mean(),
            'avg_all_return': results_df['all_return'].mean(),
            'avg_long_short': results_df['long_short'].mean(),
            'long_short_sharpe': results_df['long_short'].mean() / results_df['long_short'].std() if results_df['long_short'].std() > 0 else 0,
            'win_rate': (results_df['long_short'] > 0).sum() / len(results_df)
        }

        return summary

    def generate_report(self, all_results: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        生成性能对比报告

        Args:
            all_results: 所有模型的预测结果

        Returns:
            性能对比表格
        """
        logger.info("=" * 80)
        logger.info("📊 生成性能报告")
        logger.info("=" * 80)

        report_rows = []

        for model_name, predictions in all_results.items():
            logger.info(f"\n分析 {model_name}...")

            # Calculate metrics
            metrics = self.calculate_metrics(predictions)

            # Calculate group returns
            group_returns = self.calculate_group_returns(predictions, quantile=0.2)

            # Combine into report row
            row = {
                'Model': model_name,
                'N_Predictions': len(predictions),
                **metrics,
                **group_returns
            }

            report_rows.append(row)

            # Print summary
            if metrics:
                logger.info(f"  IC: {metrics.get('IC', np.nan):.4f} (p={metrics.get('IC_pvalue', np.nan):.4f})")
                logger.info(f"  Rank IC: {metrics.get('Rank_IC', np.nan):.4f} (p={metrics.get('Rank_IC_pvalue', np.nan):.4f})")
                logger.info(f"  MSE: {metrics.get('MSE', np.nan):.6f}, MAE: {metrics.get('MAE', np.nan):.6f}, R²: {metrics.get('R2', np.nan):.4f}")

            if group_returns:
                logger.info(f"  Top 20% Avg Return: {group_returns.get('avg_top_return', np.nan):.4f}%")
                logger.info(f"  Bottom 20% Avg Return: {group_returns.get('avg_bottom_return', np.nan):.4f}%")
                logger.info(f"  Long-Short Return: {group_returns.get('avg_long_short', np.nan):.4f}%")
                logger.info(f"  Long-Short Sharpe: {group_returns.get('long_short_sharpe', np.nan):.4f}")
                logger.info(f"  Win Rate: {group_returns.get('win_rate', np.nan):.2%}")

        report_df = pd.DataFrame(report_rows)

        logger.info("=" * 80)
        logger.info("📋 最终性能对比表格:")
        logger.info("\n" + report_df.to_string())
        logger.info("=" * 80)

        return report_df

    def run_backtest(self) -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame]:
        """
        运行完整回测

        Returns:
            (all_results, report_df)
        """
        # Load data
        data = self.load_allfac_data()

        # Rolling prediction
        all_results = self.rolling_prediction(data)

        # Generate report
        report_df = self.generate_report(all_results)

        return all_results, report_df


def main():
    """主函数"""
    logger.info("=" * 80)
    logger.info("🚀 Comprehensive Model Backtest - 完整模型回测分析")
    logger.info("=" * 80)

    # Initialize backtest engine
    backtest = ComprehensiveModelBacktest(data_dir="data/factor_exports/allfac")

    # Run backtest
    all_results, report_df = backtest.run_backtest()

    # Save results
    output_dir = "result/model_backtest"
    os.makedirs(output_dir, exist_ok=True)

    # Save report
    report_path = os.path.join(output_dir, f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    report_df.to_csv(report_path, index=False)
    logger.info(f"📄 性能报告已保存: {report_path}")

    # Save detailed predictions
    for model_name, predictions in all_results.items():
        pred_path = os.path.join(output_dir, f"{model_name}_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet")
        predictions.to_parquet(pred_path, index=False)
        logger.info(f"📄 {model_name} 预测结果已保存: {pred_path}")

    logger.info("=" * 80)
    logger.info("✅ 回测完成！")
    logger.info("=" * 80)


if __name__ == '__main__':
    main()

