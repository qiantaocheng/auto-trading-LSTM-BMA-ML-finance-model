# 子集训练时间分析

## 📊 当前状态

**检查时间**: 2026-01-22 21:35

### 训练状态

- **运行**: `run_20260122_203734`
- **开始时间**: 2026-01-22 20:37:34
- **运行时长**: **约58分钟** (0h 57m 40s)
- **状态**: 🔄 **进行中**
- **Snapshot ID**: 尚未生成

### Python进程状态

- **进程ID**: 12976 (新进程，21:08:47启动)
- **运行时长**: 约26分钟
- **内存使用**: 2.6 GB
- **CPU使用**: 正常

### 评估状态

- **状态**: ⏳ **等待训练完成**
- **最新评估运行**: 未找到（子集评估尚未开始）

## ⏱️ 为什么需要这么长时间？

### 1. 训练流程复杂

训练过程包括多个阶段：

#### 阶段1: 第一层模型训练
- **ElasticNet**: 需要训练和交叉验证
- **XGBoost**: 需要训练和交叉验证
- **CatBoost**: 需要训练和交叉验证
- **LambdaRank**: 需要训练和交叉验证

#### 阶段2: 第二层模型训练
- **MetaRankerStacker (Ridge Stacking)**: 基于第一层OOF预测训练
- **LambdaRank Stacker**: 基于第一层预测训练

#### 阶段3: 模型保存
- 保存所有模型到snapshot
- 保存配置和元数据

### 2. 交叉验证耗时

从配置文件中看到：
- **CV折数**: 6折
- **CV方法**: TimeSeriesSplit
- **Gap days**: 5天
- **Embargo days**: 5天
- **Min train size**: 252天（1年）

**每个模型都需要进行6折交叉验证**，这意味着：
- ElasticNet: 6次训练
- XGBoost: 6次训练
- CatBoost: 6次训练
- LambdaRank: 6次训练

**总计**: 至少24次模型训练（不包括第二层）

### 3. 数据量仍然较大

虽然使用了1/5子集，但数据量仍然不小：
- **Ticker数**: 784 (20% of 3,921)
- **行数**: 827,900 (约20% of 4,180,394)
- **日期数**: 1,244个交易日（完整日期范围）

### 4. 模型复杂度

#### XGBoost和CatBoost
- 树模型训练相对耗时
- 需要调优超参数
- 需要early stopping

#### LambdaRank
- 排序模型训练更复杂
- 需要计算pairwise损失
- 需要多次迭代

### 5. 内存和I/O操作

- **数据加载**: 需要读取130MB的parquet文件
- **特征计算**: 需要计算各种技术指标
- **OOF预测**: 需要存储和计算OOF预测
- **模型保存**: 需要序列化所有模型

## 📈 预计完成时间

### 基于当前进度

- **已运行**: 58分钟
- **预计总时间**: 1.5-2小时（基于全量数据经验）

### 与全量数据对比

- **全量数据训练时间**: 约8-10小时
- **子集数据训练时间**: 预计1.5-2小时
- **加速比**: 约5倍（符合预期）

## 🔍 如何监控进度

### 方法1: 检查训练日志

如果有日志文件，可以查看：
```bash
# 检查是否有日志文件
ls results/full_dataset_training/run_20260122_203734/*.log
```

### 方法2: 检查进程状态

```bash
# Windows PowerShell
Get-Process python | Select-Object Id, ProcessName, StartTime, CPU, @{Name="Memory(MB)";Expression={[math]::Round($_.WorkingSet64/1MB, 2)}}
```

### 方法3: 检查目录变化

```bash
# 检查目录是否有新文件
ls results/full_dataset_training/run_20260122_203734/
```

## 💡 优化建议

### 如果训练时间过长

1. **减少CV折数**: 从6折减少到4折
2. **减少训练数据**: 使用更小的日期范围
3. **简化模型**: 禁用某些模型（如LambdaRank）
4. **并行训练**: 如果可能，使用多进程训练

### 如果内存不足

1. **减少batch size**: 降低内存使用
2. **分批处理**: 分批加载数据
3. **清理缓存**: 定期清理中间结果

## 📋 预期输出

### 训练完成后

- **Snapshot ID**: `results/full_dataset_training/run_20260122_203734/snapshot_id.txt`
- **训练时间**: 预计1.5-2小时
- **模型文件**: 保存在snapshot中

### 80/20评估完成后

- **报告文件**: `results/t10_time_split_80_20_final/run_*/report_df.csv`
- **评估时间**: 预计30-60分钟
- **总时间**: 预计2-3小时

## 🎯 下一步

1. **继续等待**: 训练仍在进行中，预计还需要30-60分钟
2. **监控进程**: 定期检查Python进程状态
3. **检查结果**: 训练完成后检查snapshot_id.txt
4. **开始评估**: 训练完成后自动开始80/20评估

---

**状态**: 🔄 **训练进行中，预计还需要30-60分钟**

**建议**: 继续等待，训练过程正常。如果超过2小时仍未完成，可能需要检查是否有错误。
