#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¡ç®— CatBoost å’Œ LambdaRank çš„ç´¯è®¡æ”¶ç›Šï¼ˆåŸºäºéé‡å å›æµ‹ï¼‰
ä»æœ€æ–°çš„è¯„ä¼°è¿è¡Œä¸­æå–é¢„æµ‹æ•°æ®å¹¶è®¡ç®—
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import glob

# Add project root to path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "scripts"))

from scripts.time_split_80_20_oos_eval import calculate_group_returns_hold10d_nonoverlap

def find_latest_run_with_predictions():
    """æ‰¾åˆ°æœ€æ–°çš„åŒ…å«é¢„æµ‹æ•°æ®çš„è¿è¡Œç›®å½•"""
    result_dirs = glob.glob(str(project_root / "results" / "t10_time_split_80_20" / "run_*"))
    if not result_dirs:
        return None
    
    # Sort by modification time
    latest_dir = max(result_dirs, key=lambda x: Path(x).stat().st_mtime)
    return Path(latest_dir)

def load_predictions_from_run(run_dir: Path):
    """ä»è¿è¡Œç›®å½•åŠ è½½é¢„æµ‹æ•°æ®ï¼ˆå¦‚æœå·²ä¿å­˜ï¼‰"""
    # Check if there's a predictions file
    pred_files = list(run_dir.glob("*_predictions*.parquet")) + list(run_dir.glob("*_predictions*.csv"))
    if pred_files:
        latest_pred = max(pred_files, key=lambda x: x.stat().st_mtime)
        if latest_pred.suffix == '.parquet':
            return pd.read_parquet(latest_pred)
        else:
            return pd.read_csv(latest_pred)
    return None

def calculate_accumulated_returns():
    """è®¡ç®— CatBoost å’Œ LambdaRank çš„ç´¯è®¡æ”¶ç›Š"""
    print("=" * 80)
    print("è®¡ç®— CatBoost å’Œ LambdaRank ç´¯è®¡æ”¶ç›Šï¼ˆéé‡å å›æµ‹ï¼‰")
    print("=" * 80)
    
    # Find latest run
    latest_run = find_latest_run_with_predictions()
    if not latest_run:
        print("âŒ æœªæ‰¾åˆ°è¿è¡Œç›®å½•")
        return
    
    print(f"\nğŸ“ æœ€æ–°è¿è¡Œç›®å½•: {latest_run.name}")
    
    # Try to load predictions
    predictions = load_predictions_from_run(latest_run)
    
    if predictions is None:
        print("\nâš ï¸  æœªæ‰¾åˆ°ä¿å­˜çš„é¢„æµ‹æ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ éœ€è¦é‡æ–°è¿è¡Œè¯„ä¼°ä»¥ç”Ÿæˆé¢„æµ‹æ•°æ®")
        print(f"\nè¿è¡Œå‘½ä»¤:")
        print(f"python scripts/time_split_80_20_oos_eval.py \\")
        print(f"    --horizon-days 10 --top-n 20 --cost-bps 10 \\")
        print(f"    --output-dir results/t10_time_split_80_20 \\")
        print(f"    --models catboost lambdarank --snapshot-id <snapshot_id>")
        return
    
    print(f"âœ… åŠ è½½é¢„æµ‹æ•°æ®: {len(predictions)} æ¡è®°å½•")
    
    # Check required columns
    required_cols = ['date', 'ticker', 'prediction', 'actual']
    missing = [col for col in required_cols if col not in predictions.columns]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing}")
        return
    
    # Calculate for each model
    models = ['catboost', 'lambdarank']
    results = {}
    
    for model_name in models:
        # Filter predictions for this model
        # Assuming predictions have a 'model' column or we need to filter differently
        if 'model' in predictions.columns:
            model_preds = predictions[predictions['model'] == model_name].copy()
        else:
            # If no model column, assume all predictions are for the same model
            # We'll need to check the actual structure
            print(f"\nâš ï¸  é¢„æµ‹æ•°æ®ä¸­æ²¡æœ‰'model'åˆ—ï¼Œå°è¯•ä½¿ç”¨å…¨éƒ¨æ•°æ®")
            model_preds = predictions.copy()
        
        if model_preds.empty:
            print(f"\nâš ï¸  {model_name}: æœªæ‰¾åˆ°é¢„æµ‹æ•°æ®")
            continue
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {model_name.upper()}")
        print(f"{'='*60}")
        print(f"é¢„æµ‹æ•°é‡: {len(model_preds)}")
        print(f"æ—¥æœŸèŒƒå›´: {model_preds['date'].min()} åˆ° {model_preds['date'].max()}")
        
        # Calculate non-overlapping returns
        try:
            group_ts = calculate_group_returns_hold10d_nonoverlap(
                model_preds, 
                top_n=20, 
                horizon_days=10, 
                cost_bps=10.0, 
                start_offset=0
            )
            
            if group_ts.empty:
                print(f"âŒ {model_name}: æ—¶é—´åºåˆ—ä¸ºç©º")
                continue
            
            print(f"\nâœ… éé‡å å›æµ‹ç»“æœ:")
            print(f"   æ—¶é—´åºåˆ—è¡Œæ•°: {len(group_ts)} (æ¯10å¤©ä¸€æœŸ)")
            print(f"   æ—¥æœŸèŒƒå›´: {group_ts['date'].min()} åˆ° {group_ts['date'].max()}")
            
            # Calculate cumulative returns
            def _cum_pct(s_pct: pd.Series) -> pd.Series:
                r = pd.to_numeric(s_pct, errors="coerce").fillna(0.0) / 100.0
                return (1.0 + r).cumprod() - 1.0
            
            # Convert to percent and calculate cumulative
            top_return_pct = group_ts['top_return'] * 100.0
            top_return_net_pct = group_ts['top_return_net'] * 100.0
            
            cum_gross = _cum_pct(top_return_pct) * 100.0
            cum_net = _cum_pct(top_return_net_pct) * 100.0
            
            final_gross = cum_gross.iloc[-1]
            final_net = cum_net.iloc[-1]
            
            print(f"\nğŸ“ˆ ç´¯è®¡æ”¶ç›Š:")
            print(f"   æœ€ç»ˆç´¯è®¡æ”¶ç›Š (Gross): {final_gross:.2f}%")
            print(f"   æœ€ç»ˆç´¯è®¡æ”¶ç›Š (Net):   {final_net:.2f}%")
            
            # Calculate statistics
            periods_per_year = 252.0 / 10
            net_series = group_ts['top_return_net'].dropna()
            if len(net_series) > 1 and net_series.std() > 0:
                sharpe = (net_series.mean() / net_series.std()) * np.sqrt(periods_per_year)
                win_rate = (net_series > 0).mean()
                print(f"\nğŸ“Š ç»Ÿè®¡æŒ‡æ ‡:")
                print(f"   Sharpe Ratio: {sharpe:.4f}")
                print(f"   èƒœç‡: {win_rate:.2%}")
                print(f"   å¹³å‡æ”¶ç›Š (Net): {net_series.mean()*100:.4f}%")
            
            results[model_name] = {
                'final_gross': final_gross,
                'final_net': final_net,
                'num_periods': len(group_ts),
                'timeseries': group_ts
            }
            
            # Save timeseries
            output_file = latest_run / f"{model_name}_top20_nonoverlap_timeseries.csv"
            group_ts.to_csv(output_file, index=False)
            print(f"\nğŸ’¾ æ—¶é—´åºåˆ—å·²ä¿å­˜: {output_file.name}")
            
        except Exception as e:
            print(f"âŒ {model_name}: è®¡ç®—å¤±è´¥ - {e}")
            import traceback
            traceback.print_exc()
    
    # Summary comparison
    if results:
        print(f"\n{'='*80}")
        print("ğŸ“Š ç´¯è®¡æ”¶ç›Šå¯¹æ¯”æ€»ç»“")
        print(f"{'='*80}")
        print(f"{'æ¨¡å‹':<15} {'æœ€ç»ˆç´¯è®¡æ”¶ç›Š (Gross)':<25} {'æœ€ç»ˆç´¯è®¡æ”¶ç›Š (Net)':<25} {'æœŸæ•°':<10}")
        print("-" * 80)
        for model_name, data in results.items():
            print(f"{model_name:<15} {data['final_gross']:>20.2f}% {data['final_net']:>20.2f}% {data['num_periods']:>10}")

if __name__ == "__main__":
    calculate_accumulated_returns()
