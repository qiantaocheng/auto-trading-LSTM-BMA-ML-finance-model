#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lightweight grid search runner (base models first, ridge separate)
=================================================================

è®¾è®¡ç›®æ ‡
- å¤ç”¨ç°æœ‰ `full_grid_search.py` ä¸­çš„è®­ç»ƒ/å›æµ‹/å‚æ•°ç½‘æ ¼é€»è¾‘
- é»˜è®¤åªè·‘å››ä¸ªåŸºæ¨¡å‹ï¼ˆelastic_net, xgboost, catboost, lambdarankï¼‰
- å¦‚æœå‘½ä»¤åŒæ—¶åŒ…å« ridge ä¸å…¶ä»–æ¨¡å‹ï¼Œä¼šè·³è¿‡ ridge å¹¶æç¤ºï¼›ä»…å½“ --models é‡Œåªå« ridge æ—¶æ‰ä¼šè¿è¡ŒäºŒå±‚ ridge ç½‘æ ¼æœç´¢
- è¯„åˆ†é€»è¾‘ä¸ç°æœ‰å®ç°ä¸€è‡´ï¼šå›æµ‹åªå–ç›®æ ‡æ¨¡å‹è¡Œçš„ avg_top_return
"""

from __future__ import annotations

import argparse
import logging
import sys
from pathlib import Path
from typing import Dict

import pandas as pd

# ç¡®ä¿å¯ä»¥é€šè¿‡ scripts.* å¯¼å…¥åŒç›®å½•ä¸‹æ¨¡å—
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# å¤ç”¨å·²æœ‰å®ç°ï¼Œé¿å…å¤åˆ¶é€»è¾‘
from scripts.full_grid_search import (
    run_single_training,
    run_backtest_for_snapshot,
    get_param_combinations,
)


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def grid_search_single_model(
    model_name: str,
    data_file: str,
    data_dir: str,
    base_config: str,
    snapshot_dir: str,
    output_dir: str,
    max_combos: int | None = None,
    feature_sets: list[list[str] | None] | None = None,
    params_mode: str = "grid",
) -> pd.DataFrame:
    """å¯¹å•ä¸ªæ¨¡å‹æ‰§è¡Œå®Œæ•´ç½‘æ ¼æœç´¢ï¼ˆè®­ç»ƒ + å›æµ‹ï¼‰ï¼Œå¯éå†å¤šç»„ç‰¹å¾å­é›†ã€‚"""
    feature_sets = feature_sets or [None]
    all_results = []

    for fset in feature_sets:
        # None -> all features; [] -> compulsory-only; [..] -> compulsory + selected optional
        if fset is None:
            fset_label = "all_features"
        elif len(fset) == 0:
            fset_label = "compulsory_only"
        else:
            fset_label = "|".join(fset)

        if params_mode == "default":
            param_combos = [{}]  # use unified_config defaults (already tuned) and only test feature subsets
        else:
            param_combos = get_param_combinations(model_name)
        if max_combos is not None:
            param_combos = param_combos[:max_combos]
        results = []
        total = len(param_combos)

        logger.info("=" * 80)
        logger.info(f"ğŸ” Start grid search: {model_name} ({total} combos) | feature_set={fset_label}")
        logger.info("=" * 80)

        for idx, params in enumerate(param_combos, 1):
            logger.info(f"[{idx}/{total}] {model_name} params = {params} | feature_set={fset_label}")

            snapshot_id, train_success = run_single_training(
                model_name=model_name,
                params=params,
                data_file=data_file,
                base_config=base_config,
                snapshot_dir=snapshot_dir,
                feature_list=fset,
            )

            if not train_success or not snapshot_id:
                logger.error(f"âŒ Training failed for combo #{idx}")
                results.append(
                    {
                        "model": model_name,
                        "combination_id": idx,
                        "params": params,
                        **params,
                        "feature_set": fset_label,
                        "feature_list": fset if fset else [],
                        "snapshot_id": None,
                        "top20_avg_return": float("nan"),
                        "train_success": False,
                        "backtest_success": False,
                    }
                )
                continue

            top_ret, full_metrics, backtest_success = run_backtest_for_snapshot(
                model_name=model_name,
                snapshot_id=snapshot_id,
                data_dir=data_dir,
                feature_list=fset,
                data_file=data_file,
            )

            results.append(
                {
                    "model": model_name,
                    "combination_id": idx,
                    "params": params,
                    **params,
                    "feature_set": fset_label,
                    "feature_list": fset if fset else [],
                    "snapshot_id": snapshot_id,
                    "top20_avg_return": top_ret,
                    "train_success": train_success,
                    "backtest_success": backtest_success,
                }
            )

            # å†™å…¥ä¸­é—´ç»“æœï¼ˆç´¯ç§¯å½“å‰feature_setï¼‰
            inter_path = Path(output_dir) / f"{model_name}_grid_search_intermediate.csv"
            out_df = pd.DataFrame(results)
            # IMPORTANT: `results` already contains *all* rows for the current run,
            # so we should overwrite instead of appending; otherwise rows duplicate
            # and the intermediate file can blow up quadratically.
            out_df.to_csv(inter_path, index=False)
            logger.info(f"ğŸ’¾ Intermediate saved: {inter_path}")

        all_results.extend(results)

    # æœ€ç»ˆç»“æœæ’åºå¹¶è½ç›˜
    final_df = pd.DataFrame(all_results)
    if not final_df.empty:
        final_df = final_df.sort_values("top20_avg_return", ascending=False)
    final_path = Path(output_dir) / f"{model_name}_grid_search_final.csv"
    final_df.to_csv(final_path, index=False)
    logger.info(f"âœ… Finished {model_name}, best={final_df['top20_avg_return'].max() if not final_df.empty else 'nan'}")
    logger.info(f"Results saved: {final_path}")
    return final_df


def main():
    parser = argparse.ArgumentParser(description="Lightweight grid search runner")
    parser.add_argument("--data-file", required=True, help="è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆMultiIndex parquet/csvï¼‰")
    parser.add_argument("--data-dir", default="data/factor_exports/factors", help="å›æµ‹æ•°æ®ç›®å½•")
    parser.add_argument("--output-dir", required=True, help="ç»“æœè¾“å‡ºç›®å½•")
    parser.add_argument(
        "--models",
        nargs="+",
        choices=["elastic_net", "xgboost", "catboost", "lambdarank", "ridge"],
        default=["elastic_net", "xgboost", "catboost", "lambdarank"],
        help="é»˜è®¤ä»…å››ä¸ªåŸºæ¨¡å‹ï¼›ridge éœ€å•ç‹¬è¿è¡Œ",
    )
    parser.add_argument(
        "--base-config",
        default="bma_models/unified_config.yaml",
        help="åŸºç¡€é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯è¢«ä¸´æ—¶è¦†ç›–ï¼‰",
    )
    parser.add_argument(
        "--snapshot-dir",
        default="cache/grid_search_snapshots",
        help="è®­ç»ƒå¿«ç…§è¾“å‡ºç›®å½•",
    )
    parser.add_argument(
        "--max-combos",
        type=int,
        default=None,
        help="æ¯ä¸ªæ¨¡å‹æœ€å¤šæµ‹è¯•å¤šå°‘ä¸ªè¶…å‚ç»„åˆï¼ˆä»…ç”¨äºsmoke testï¼Œä¸ä¼ åˆ™å…¨é‡ç½‘æ ¼ï¼‰",
    )
    parser.add_argument(
        "--feature-combos",
        type=str,
        default=None,
        help="JSONæ•°ç»„ï¼ŒæŒ‡å®šç‰¹å¾å­é›†åˆ—è¡¨ï¼›æ¯ä¸ªå­é›†ä¸ºç‰¹å¾åæ•°ç»„ã€‚è‹¥ä¸ºç©ºåˆ™ä½¿ç”¨å…¨éƒ¨ç‰¹å¾ã€‚",
    )
    parser.add_argument(
        "--feature-combos-file",
        type=str,
        default=None,
        help="ç‰¹å¾å­é›†JSONæ–‡ä»¶è·¯å¾„ï¼ˆå†…å®¹ä¸ºJSONæ•°ç»„ï¼‰ã€‚ä¼˜å…ˆçº§é«˜äº --feature-combosã€‚",
    )
    parser.add_argument(
        "--params-mode",
        choices=["grid", "default"],
        default="grid",
        help="grid=å…¨é‡è¶…å‚ç½‘æ ¼ï¼›default=åªç”¨unified_configé»˜è®¤å‚æ•°ï¼ˆç”¨äºå¤§è§„æ¨¡ç‰¹å¾ç»„åˆæµ‹è¯•ï¼‰",
    )
    args = parser.parse_args()

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Parse feature combos
    feature_sets = [None]
    feature_json_text = None
    if args.feature_combos_file:
        try:
            feature_json_text = Path(args.feature_combos_file).read_text(encoding="utf-8")
        except Exception as e:
            logger.warning(f"Failed to read --feature-combos-file, fallback to all features. Error: {e}")
            feature_json_text = None
    elif args.feature_combos:
        feature_json_text = args.feature_combos

    if feature_json_text:
        try:
            import json

            parsed = json.loads(feature_json_text)
            if isinstance(parsed, list):
                feature_sets = []
                for item in parsed:
                    if item is None:
                        feature_sets.append(None)
                    elif isinstance(item, list):
                        feature_sets.append([str(x) for x in item])
            logger.info(f"[FEATURE] Using feature subsets: {feature_sets}")
        except Exception as e:
            logger.warning(f"Failed to parse --feature-combos, fallback to all features. Error: {e}")
            feature_sets = [None]

    results: Dict[str, pd.DataFrame] = {}

    for model in args.models:
        # åªæœ‰åœ¨å•ç‹¬è¿è¡Œ ridge æ—¶æ‰æ‰§è¡Œï¼›å¦åˆ™è·³è¿‡
        if model == "ridge" and len(args.models) > 1:
            logger.warning("Skip ridge in mixed run. Run `--models ridge` alone after base models are tuned.")
            continue

        df = grid_search_single_model(
            model_name=model,
            data_file=args.data_file,
            data_dir=args.data_dir,
            base_config=args.base_config,
            snapshot_dir=args.snapshot_dir,
            output_dir=str(output_dir),
            max_combos=args.max_combos,
            feature_sets=feature_sets,
            params_mode=args.params_mode,
        )
        results[model] = df

    # åˆå¹¶è¾“å‡º
    if results:
        combined = pd.concat(results.values(), ignore_index=True)
        combined_path = output_dir / "all_models_grid_search_results.csv"
        combined.to_csv(combined_path, index=False)
        logger.info(f"ğŸ“¦ Combined results saved: {combined_path}")

    logger.info("ğŸ Grid search finished.")


if __name__ == "__main__":
    main()

