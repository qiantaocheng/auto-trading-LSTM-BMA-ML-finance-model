# ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æœ‰å‘ç”Ÿå¤šä¸ªé¢„æµ‹çš„é—®é¢˜

## ğŸ” å…³é”®å‘ç°

### ä¹‹å‰çš„æ•°æ®æµï¼ˆè®­ç»ƒ/è¯„ä¼°ï¼‰

```
1. ä»parquetæ–‡ä»¶åŠ è½½æ•°æ®
   â†“
2. polygon_factors_all_filtered_clean_final_v2.parquet
   â†“
3. æ•°æ®å·²ç»å»é‡ï¼ˆparquetæ–‡ä»¶æœ¬èº«æ˜¯å¹²å‡€çš„ï¼‰
   â†“
4. compute_all_17_factors() æˆ–ç›´æ¥ä½¿ç”¨parquetæ•°æ®
   â†“
5. æ²¡æœ‰é‡å¤çš„(date, ticker)ç»„åˆ
   â†“
6. é¢„æµ‹æ­£å¸¸ï¼Œæ¯ä¸ªtickeråªæœ‰ä¸€ä¸ªé¢„æµ‹
```

### ç°åœ¨çš„æ•°æ®æµï¼ˆDirect Predictï¼‰

```
1. ä»Polygon APIå®æ—¶è·å–æ•°æ®
   â†“
2. fetch_market_data() â†’ å¯èƒ½è¿”å›é‡å¤æ•°æ®
   â†“
3. compute_all_17_factors() â†’ ä¿ç•™é‡å¤
   â†“
4. all_feature_data æœ‰é‡å¤çš„(date, ticker)ç»„åˆ
   â†“
5. predict_with_snapshot() â†’ å¯¹æ¯ä¸ªé‡å¤ç´¢å¼•éƒ½äº§ç”Ÿé¢„æµ‹
   â†“
6. Top20è¡¨æ ¼æ˜¾ç¤ºç›¸åŒè‚¡ç¥¨é‡å¤å¤šæ¬¡
```

---

## ğŸ¯ æ ¹æœ¬åŸå› 

### åŸå› 1: æ•°æ®æºä¸åŒ

**ä¹‹å‰ï¼ˆè®­ç»ƒ/è¯„ä¼°ï¼‰**:
- ä½¿ç”¨**parquetæ–‡ä»¶**ï¼ˆ`polygon_factors_all_filtered_clean_final_v2.parquet`ï¼‰
- æ–‡ä»¶åœ¨åˆ›å»ºæ—¶å·²ç»å»é‡
- æ¯ä¸ª(date, ticker)ç»„åˆåªå‡ºç°ä¸€æ¬¡

**ç°åœ¨ï¼ˆDirect Predictï¼‰**:
- ä½¿ç”¨**Polygon APIå®æ—¶æ•°æ®**
- APIå¯èƒ½è¿”å›é‡å¤æ•°æ®ï¼ˆä¾‹å¦‚ï¼šåŒä¸€tickeråœ¨åŒä¸€å¤©æœ‰å¤šæ¡è®°å½•ï¼‰
- `fetch_market_data()`æ²¡æœ‰å»é‡é€»è¾‘

### åŸå› 2: `compute_all_17_factors`æ²¡æœ‰å»é‡

**ä½ç½®**: `bma_models/simple_25_factor_engine.py` line ~563-572

**ä»£ç **:
```python
factors_df = pd.concat(all_factors, axis=1)
factors_df.index = pd.MultiIndex.from_arrays(
    [compute_data['date'], compute_data['ticker']], 
    names=['date', 'ticker']
)
```

**é—®é¢˜**:
- å¦‚æœ`compute_data`æœ‰é‡å¤çš„(date, ticker)ç»„åˆ
- `factors_df.index`ä¹Ÿä¼šæœ‰é‡å¤
- **æ²¡æœ‰å»é‡é€»è¾‘**

### åŸå› 3: `_prepare_standard_data_format`çš„å»é‡å¯èƒ½ä¸å¤Ÿ

**ä½ç½®**: `bma_models/é‡åŒ–æ¨¡å‹_bma_ultra_enhanced.py` line ~6624

**ä»£ç **:
```python
feature_data = feature_data[~feature_data.index.duplicated(keep='last')]
```

**é—®é¢˜**:
- è¿™ä¸ªå»é‡é€»è¾‘**åº”è¯¥èƒ½å·¥ä½œ**
- ä½†æ˜¯å¦‚æœåœ¨`predict_with_snapshot`çš„å…¶ä»–åœ°æ–¹äº§ç”Ÿäº†é‡å¤ï¼Œå¯èƒ½å·²ç»å½±å“äº†é¢„æµ‹

---

## ğŸ“Š ä¸ºä»€ä¹ˆä¹‹å‰æ²¡å‘ç°ï¼Ÿ

### 1. è®­ç»ƒ/è¯„ä¼°ä½¿ç”¨parquetæ–‡ä»¶

- Parquetæ–‡ä»¶æ•°æ®æ˜¯**é¢„å¤„ç†è¿‡çš„**ï¼Œå·²ç»å»é‡
- å³ä½¿`compute_all_17_factors`æ²¡æœ‰å»é‡ï¼Œè¾“å…¥æ•°æ®æœ¬èº«æ²¡æœ‰é‡å¤
- æ‰€ä»¥ä¸ä¼šäº§ç”Ÿå¤šä¸ªé¢„æµ‹

### 2. Direct Predictæ˜¯æ–°åŠŸèƒ½

- Direct Predictæ˜¯**æœ€è¿‘æ·»åŠ çš„åŠŸèƒ½**
- ä½¿ç”¨å®æ—¶APIæ•°æ®ï¼Œè€Œä¸æ˜¯parquetæ–‡ä»¶
- æš´éœ²äº†`compute_all_17_factors`æ²¡æœ‰å»é‡çš„é—®é¢˜

### 3. æ•°æ®æºå·®å¼‚

**Parquetæ–‡ä»¶**:
- æ•°æ®ç»è¿‡æ¸…æ´—å’Œå»é‡
- æ¯ä¸ª(date, ticker)ç»„åˆå”¯ä¸€
- æ ¼å¼ç»Ÿä¸€

**Polygon API**:
- å¯èƒ½è¿”å›åŸå§‹æ•°æ®
- åŒä¸€tickeråœ¨åŒä¸€å¤©å¯èƒ½æœ‰å¤šä¸ªæ—¶é—´ç‚¹çš„æ•°æ®
- éœ€è¦æ‰‹åŠ¨å»é‡

---

## âœ… è§£å†³æ–¹æ¡ˆ

### ä¿®å¤1: åœ¨`fetch_market_data`è¿”å›å‰å»é‡

**ä½ç½®**: `bma_models/simple_25_factor_engine.py` line ~210, ~260

**ä¿®æ”¹**:
```python
# åœ¨optimized_downloaderè¿”å›å
if not optimized_data.empty:
    data_with_cols = optimized_data.reset_index()
    
    # ğŸ”§ FIX: Remove duplicate (date, ticker) combinations
    if 'date' in data_with_cols.columns and 'ticker' in data_with_cols.columns:
        duplicates = data_with_cols.duplicated(subset=['date', 'ticker'], keep='last')
        if duplicates.any():
            logger.warning(f"âš ï¸ fetch_market_data: Removing {duplicates.sum()} duplicate (date, ticker) combinations")
            data_with_cols = data_with_cols[~duplicates].reset_index(drop=True)
    
    return data_with_cols

# åœ¨legacy methodè¿”å›å‰
if all_data:
    combined = pd.concat(all_data, ignore_index=False)
    combined = combined.reset_index()
    
    # ğŸ”§ FIX: Remove duplicate (date, ticker) combinations
    if 'date' in combined.columns and 'ticker' in combined.columns:
        duplicates = combined.duplicated(subset=['date', 'ticker'], keep='last')
        if duplicates.any():
            logger.warning(f"âš ï¸ fetch_market_data (legacy): Removing {duplicates.sum()} duplicate (date, ticker) combinations")
            combined = combined[~duplicates].reset_index(drop=True)
    
    return combined
```

### ä¿®å¤2: åœ¨`compute_data`åˆ›å»ºåç«‹å³å»é‡

**ä½ç½®**: `bma_models/simple_25_factor_engine.py` line ~350

**ä¿®æ”¹**:
```python
compute_data = market_data_clean.copy()
compute_data['date'] = pd.to_datetime(compute_data['date']).dt.normalize()
compute_data = compute_data.sort_values(['ticker', 'date']).reset_index(drop=True)

# ğŸ”§ FIX: Remove duplicate (date, ticker) combinations immediately
if 'date' in compute_data.columns and 'ticker' in compute_data.columns:
    duplicates = compute_data.duplicated(subset=['date', 'ticker'], keep='last')
    if duplicates.any():
        logger.warning(f"âš ï¸ compute_data: Removing {duplicates.sum()} duplicate (date, ticker) combinations")
        compute_data = compute_data[~duplicates].reset_index(drop=True)
```

### ä¿®å¤3: åœ¨`compute_all_17_factors`è¿”å›å‰å»é‡

**ä½ç½®**: `bma_models/simple_25_factor_engine.py` line ~572

**ä¿®æ”¹**:
```python
factors_df.index = pd.MultiIndex.from_arrays(
    [compute_data['date'], compute_data['ticker']], 
    names=['date', 'ticker']
)

# ğŸ”§ FIX: Remove duplicate indices immediately after setting MultiIndex
duplicates = factors_df.index.duplicated()
if duplicates.any():
    logger.warning(f"âš ï¸ compute_all_17_factors: Removing {duplicates.sum()} duplicate indices")
    factors_df = factors_df[~duplicates]

# Ensure each (date, ticker) combination appears only once
factors_df = factors_df.groupby(level=['date', 'ticker']).first()
```

---

## ğŸ¯ æ€»ç»“

**ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æœ‰å‘ç”Ÿï¼Ÿ**

1. **æ•°æ®æºä¸åŒ**: ä¹‹å‰ä½¿ç”¨parquetæ–‡ä»¶ï¼ˆå·²å»é‡ï¼‰ï¼Œç°åœ¨ä½¿ç”¨APIå®æ—¶æ•°æ®ï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰
2. **åŠŸèƒ½ä¸åŒ**: Direct Predictæ˜¯æ–°åŠŸèƒ½ï¼Œä½¿ç”¨ä¸åŒçš„æ•°æ®è·¯å¾„
3. **å»é‡ç¼ºå¤±**: `compute_all_17_factors`æ²¡æœ‰å»é‡é€»è¾‘ï¼Œä¹‹å‰å› ä¸ºè¾“å…¥æ•°æ®æœ¬èº«æ²¡æœ‰é‡å¤ï¼Œæ‰€ä»¥æ²¡æš´éœ²é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
- åœ¨æ•°æ®æµçš„**æ¯ä¸ªå…³é”®èŠ‚ç‚¹**æ·»åŠ å»é‡é€»è¾‘
- ç¡®ä¿æ¯ä¸ª(date, ticker)ç»„åˆåªå‡ºç°ä¸€æ¬¡
- ç‰¹åˆ«æ˜¯`fetch_market_data`å’Œ`compute_all_17_factors`è¿”å›å‰

---

**çŠ¶æ€**: âš ï¸ **éœ€è¦ä¿®å¤æ•°æ®è·å–å’Œå› å­è®¡ç®—çš„å»é‡é€»è¾‘**

**ä¸‹ä¸€æ­¥**: å®æ–½ä¿®å¤ï¼Œç¡®ä¿Direct Predictå’Œè®­ç»ƒ/è¯„ä¼°ä½¿ç”¨ä¸€è‡´çš„å»é‡é€»è¾‘
