# 训练 vs 评估流程说明

## 📋 完整流程

`retrain_with_tracking.py` 执行**两个独立的步骤**：

### 步骤1: 训练阶段 (`train_full_dataset.py`)
- **目的**: 训练一个**生产模型**，使用所有可用数据
- **数据使用**: 使用**全部**训练数据（在这个case中是1/5子集的全部数据）
- **内部机制**: 
  - 模型内部进行**Cross-Validation (CV)**，这是时间序列分割的
  - 使用PurgedCV，避免数据泄漏
- **输出**: 保存模型快照（snapshot）用于后续预测

**为什么叫"full dataset"？**
- 这里的"full"指的是使用**所有可用的训练数据**来训练模型
- 不是指没有时间分割，而是指**训练阶段**使用全部数据
- 训练过程中的CV是**内部**的时间分割，用于模型选择和超参数 tuning

### 步骤2: 评估阶段 (`time_split_80_20_oos_eval.py`)
- **目的**: 在**独立测试集**上评估模型性能
- **数据分割**: 
  - 80% 数据用于训练（重新训练或使用快照）
  - 20% 数据用于测试（Out-of-Sample评估）
- **评估方式**: 
  - 加载步骤1生成的模型快照
  - 在测试集上进行预测和性能评估
  - 计算Top-N收益、Sharpe比率等指标

## 🔄 流程图

```
retrain_with_tracking.py
│
├─ [步骤1] train_full_dataset.py
│  │
│  ├─ 加载数据（1/5子集，全部数据）
│  ├─ 训练模型（使用全部数据）
│  │  └─ 内部CV（时间序列分割，PurgedCV）
│  ├─ 训练MetaRankerStacker（第二层）
│  └─ 保存快照 → snapshot_id
│
└─ [步骤2] time_split_80_20_oos_eval.py
   │
   ├─ 加载快照（从步骤1）
   ├─ 数据分割：80%训练 / 20%测试
   ├─ 在测试集上预测
   └─ 评估性能（Top-N收益、Sharpe等）
```

## 📊 关键区别

| 阶段 | 脚本 | 数据使用 | 时间分割 | 目的 |
|------|------|----------|----------|------|
| **训练** | `train_full_dataset.py` | 全部数据 | 内部CV（PurgedCV） | 训练生产模型 |
| **评估** | `time_split_80_20_oos_eval.py` | 80/20分割 | 80%训练，20%测试 | OOS性能评估 |

## 💡 为什么这样设计？

1. **训练阶段使用全部数据**:
   - 生产模型应该使用所有可用数据训练，以获得最佳性能
   - 内部CV用于模型选择和避免过拟合

2. **评估阶段使用80/20分割**:
   - 模拟真实场景：用历史数据训练，在新数据上测试
   - 提供**无偏的**性能估计（Out-of-Sample）
   - 评估模型在**未来数据**上的表现

## ✅ 当前状态

- ✅ 步骤1已完成：训练成功
- ⚠️ 步骤1遇到问题：快照保存失败（`training_results['traditional_models']['models']`缺失）
- ⏳ 步骤2待执行：需要先修复快照保存问题

## 🔧 下一步

修复快照保存问题后，步骤2会自动执行80/20评估。
