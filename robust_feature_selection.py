#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¨³å¥ç‰¹å¾é€‰æ‹©ç³»ç»Ÿ
åŸºäºæ»šåŠ¨ICåˆ†æï¼Œä¿ç•™å°‘é‡é«˜è´¨é‡ã€äº’å¼‚çš„ç‰¹å¾(Kâ‰ˆ12-20)
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from sklearn.cluster import AgglomerativeClustering
from scipy.stats import spearmanr
from scipy.cluster.hierarchy import linkage, fcluster
import warnings
warnings.filterwarnings('ignore')

class RobustFeatureSelector:
    """
    ç¨³å¥ç‰¹å¾é€‰æ‹©å™¨
    
    é€šè¿‡æ»šåŠ¨ICåˆ†æä¿ç•™é«˜è´¨é‡ã€ä½ç›¸å…³æ€§çš„ç‰¹å¾
    """
    
    def __init__(self, 
                 target_features: int = 16,  # ç›®æ ‡ç‰¹å¾æ•°é‡
                 ic_window: int = 126,       # ICè®¡ç®—çª—å£(çº¦6ä¸ªæœˆ)
                 min_ic_mean: float = 0.01,  # æœ€å°ICå‡å€¼
                 min_ic_ir: float = 0.3,     # æœ€å°ICä¿¡æ¯æ¯”ç‡
                 max_correlation: float = 0.6  # æœ€å¤§ç‰¹å¾é—´ç›¸å…³æ€§
                 ):
        self.target_features = target_features
        self.ic_window = ic_window
        self.min_ic_mean = min_ic_mean
        self.min_ic_ir = min_ic_ir
        self.max_correlation = max_correlation
        
        # ä¿å­˜é€‰æ‹©çš„ç‰¹å¾
        self.selected_features_ = None
        self.feature_stats_ = None
        self.correlation_matrix_ = None
        self.feature_clusters_ = None
        
    def rolling_ic(self, X: pd.DataFrame, y: pd.Series, dates: pd.Series) -> Dict[str, Tuple[float, float]]:
        """
        è®¡ç®—æ»šåŠ¨ICç»Ÿè®¡
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            dates: æ—¥æœŸåºåˆ—
            
        Returns:
            Dict[ç‰¹å¾å, (ICå‡å€¼, ICæ ‡å‡†å·®)]
        """
        print(f"è®¡ç®—æ»šåŠ¨ICç»Ÿè®¡ï¼Œçª—å£: {self.ic_window}å¤©")
        
        out = {}
        
        for col in X.columns:
            try:
                # æ„å»ºåˆ†ææ•°æ®æ¡†
                df = pd.DataFrame({
                    'x': X[col], 
                    'y': y, 
                    'd': dates
                }).dropna()
                
                if len(df) < self.ic_window:
                    print(f"âš ï¸ ç‰¹å¾ {col}: æ•°æ®ä¸è¶³({len(df)} < {self.ic_window})")
                    continue
                
                # ç›´æ¥è®¡ç®—æ»šåŠ¨ç›¸å…³æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰
                # å¯¹äºæ—¶é—´åºåˆ—æ•°æ®ï¼Œç›´æ¥è®¡ç®—æ»šåŠ¨ç›¸å…³æ€§
                df_sorted = df.sort_values('d')
                
                if len(df_sorted) < self.ic_window:
                    print(f"âš ï¸ ç‰¹å¾ {col}: æ•°æ®ä¸è¶³({len(df_sorted)} < {self.ic_window})")
                    continue
                
                # è®¡ç®—æ»šåŠ¨Spearmanç›¸å…³æ€§
                rolling_ic_list = []
                for i in range(self.ic_window, len(df_sorted) + 1):
                    window_data = df_sorted.iloc[i-self.ic_window:i]
                    if len(window_data) >= 10:  # è‡³å°‘éœ€è¦10ä¸ªç‚¹è®¡ç®—ç›¸å…³æ€§
                        try:
                            ic = spearmanr(window_data['x'], window_data['y'])[0]
                            if not np.isnan(ic):
                                rolling_ic_list.append(ic)
                        except:
                            continue
                
                if len(rolling_ic_list) == 0:
                    print(f"âš ï¸ ç‰¹å¾ {col}: æ— æ³•è®¡ç®—æœ‰æ•ˆIC")
                    continue
                
                daily_ic = pd.Series(rolling_ic_list)
                
                if len(daily_ic) < self.ic_window // 2:
                    print(f"âš ï¸ ç‰¹å¾ {col}: æœ‰æ•ˆICå¤©æ•°ä¸è¶³({len(daily_ic)})")
                    continue
                
                # è®¡ç®—ICç»Ÿè®¡
                ic_mean = daily_ic.mean()
                ic_std = daily_ic.std()
                
                out[col] = (ic_mean, ic_std)
                
                # è¯¦ç»†ç»Ÿè®¡
                ic_ir = ic_mean / (ic_std + 1e-8)
                print(f"âœ“ ç‰¹å¾ {col}: ICå‡å€¼={ic_mean:.4f}, ICæ ‡å‡†å·®={ic_std:.4f}, IC_IR={ic_ir:.4f}")
                
            except Exception as e:
                print(f"âŒ ç‰¹å¾ {col} ICè®¡ç®—å¤±è´¥: {e}")
                continue
        
        print(f"æ»šåŠ¨ICè®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆç‰¹å¾: {len(out)}/{len(X.columns)}")
        return out
    
    def filter_by_ic_quality(self, ic_stats: Dict[str, Tuple[float, float]]) -> List[str]:
        """
        æ ¹æ®ICè´¨é‡è¿‡æ»¤ç‰¹å¾
        
        Args:
            ic_stats: ICç»Ÿè®¡ç»“æœ
            
        Returns:
            å€™é€‰ç‰¹å¾åˆ—è¡¨
        """
        candidates = []
        
        for feature, (ic_mean, ic_std) in ic_stats.items():
            # è®¡ç®—ICä¿¡æ¯æ¯”ç‡
            ic_ir = ic_mean / (ic_std + 1e-8) if ic_std > 1e-6 else 0
            
            # è¿‡æ»¤æ¡ä»¶
            if ic_mean > self.min_ic_mean and ic_ir > self.min_ic_ir:
                candidates.append(feature)
                print(f"âœ“ å€™é€‰ç‰¹å¾ {feature}: IC={ic_mean:.4f}, IC_IR={ic_ir:.4f}")
            else:
                print(f"âœ— è¿‡æ»¤ç‰¹å¾ {feature}: IC={ic_mean:.4f}, IC_IR={ic_ir:.4f} (ä¸ç¬¦åˆæ ‡å‡†)")
        
        print(f"ICè´¨é‡è¿‡æ»¤: {len(candidates)}/{len(ic_stats)} ç‰¹å¾é€šè¿‡")
        return candidates
    
    def remove_redundant_features(self, X: pd.DataFrame, candidates: List[str], 
                                ic_stats: Dict[str, Tuple[float, float]]) -> List[str]:
        """
        å»é™¤å†—ä½™ç‰¹å¾ï¼šæŒ‰ç›¸å…³æ€§èšç±»ï¼Œæ¯ç°‡é€‰æ‹©ICæœ€é«˜çš„ç‰¹å¾
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            candidates: å€™é€‰ç‰¹å¾åˆ—è¡¨
            ic_stats: ICç»Ÿè®¡ç»“æœ
            
        Returns:
            æœ€ç»ˆé€‰æ‹©çš„ç‰¹å¾åˆ—è¡¨
        """
        if len(candidates) <= self.target_features:
            print(f"å€™é€‰ç‰¹å¾æ•°({len(candidates)})å·²å°‘äºç›®æ ‡æ•°({self.target_features})ï¼Œç›´æ¥è¿”å›")
            return candidates
        
        print(f"å¼€å§‹å»å†—ä½™ï¼Œå€™é€‰ç‰¹å¾: {len(candidates)}")
        
        # è®¡ç®—å€™é€‰ç‰¹å¾çš„ç›¸å…³æ€§çŸ©é˜µ
        X_candidates = X[candidates].fillna(0)
        corr_matrix = X_candidates.corr().abs()
        self.correlation_matrix_ = corr_matrix
        
        # ä½¿ç”¨å±‚æ¬¡èšç±»åŸºäºç›¸å…³æ€§èšç±»
        # è·ç¦» = 1 - |correlation|
        distance_matrix = 1 - corr_matrix
        
        # è¿›è¡Œå±‚æ¬¡èšç±»
        linkage_matrix = linkage(distance_matrix.values, method='average')
        
        # åŠ¨æ€ç¡®å®šèšç±»æ•°ï¼Œç¡®ä¿æ¯ç°‡çš„å¹³å‡ç›¸å…³æ€§ä¸è¶…è¿‡é˜ˆå€¼
        best_clusters = self.target_features
        for n_clusters in range(self.target_features, len(candidates)):
            cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
            
            # æ£€æŸ¥ç°‡å†…æœ€å¤§ç›¸å…³æ€§
            max_intra_corr = 0
            for cluster_id in np.unique(cluster_labels):
                cluster_features = [candidates[i] for i in range(len(candidates)) if cluster_labels[i] == cluster_id]
                if len(cluster_features) > 1:
                    cluster_corr = corr_matrix.loc[cluster_features, cluster_features]
                    max_corr_in_cluster = cluster_corr.values[np.triu_indices_from(cluster_corr.values, k=1)].max()
                    max_intra_corr = max(max_intra_corr, max_corr_in_cluster)
            
            if max_intra_corr <= self.max_correlation:
                best_clusters = n_clusters
                break
        
        # ä½¿ç”¨æœ€ä½³èšç±»æ•°è¿›è¡Œèšç±»
        cluster_labels = fcluster(linkage_matrix, best_clusters, criterion='maxclust')
        
        print(f"å±‚æ¬¡èšç±»å®Œæˆï¼Œèšç±»æ•°: {best_clusters}")
        
        # æ¯ä¸ªç°‡é€‰æ‹©ICæœ€é«˜çš„ç‰¹å¾
        selected_features = []
        cluster_info = {}
        
        for cluster_id in np.unique(cluster_labels):
            cluster_features = [candidates[i] for i in range(len(candidates)) if cluster_labels[i] == cluster_id]
            
            # é€‰æ‹©è¯¥ç°‡ä¸­ICå‡å€¼æœ€é«˜çš„ç‰¹å¾
            best_feature = max(cluster_features, key=lambda f: ic_stats[f][0])
            selected_features.append(best_feature)
            
            # ä¿å­˜ç°‡ä¿¡æ¯
            cluster_info[cluster_id] = {
                'features': cluster_features,
                'selected': best_feature,
                'ic_stats': {f: ic_stats[f] for f in cluster_features}
            }
            
            print(f"ç°‡ {cluster_id} (å…±{len(cluster_features)}ä¸ªç‰¹å¾): é€‰æ‹© {best_feature} (IC={ic_stats[best_feature][0]:.4f})")
        
        self.feature_clusters_ = cluster_info
        
        print(f"å»å†—ä½™å®Œæˆ: {len(candidates)} -> {len(selected_features)} ç‰¹å¾")
        return selected_features
    
    def fit(self, X: pd.DataFrame, y: pd.Series, dates: pd.Series) -> 'RobustFeatureSelector':
        """
        æ‹Ÿåˆç‰¹å¾é€‰æ‹©å™¨ (Stage-A: å…¨å±€ç¨³å¥å±‚)
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡  
            dates: æ—¥æœŸåºåˆ—
            
        Returns:
            self
        """
        print("=" * 60)
        print("Stage-A: å…¨å±€ç¨³å¥ç‰¹å¾é€‰æ‹© (å”¯ä¸€å…¥å£)")
        print("=" * 60)
        print(f"è¾“å…¥: {X.shape[1]} ä¸ªç‰¹å¾, {len(X)} ä¸ªæ ·æœ¬")
        print(f"ç›®æ ‡: é€‰æ‹© {self.target_features} ä¸ªç¨³å¥ç‰¹å¾")
        print(f"æ ‡å‡†: IC>{self.min_ic_mean}, IC_IR>{self.min_ic_ir}, ç›¸å…³æ€§<{self.max_correlation}")
        
        # 1. è®¡ç®—æ»šåŠ¨ICç»Ÿè®¡
        ic_stats = self.rolling_ic(X, y, dates)
        self.feature_stats_ = ic_stats
        
        if len(ic_stats) == 0:
            raise ValueError("æ²¡æœ‰ç‰¹å¾é€šè¿‡ICè®¡ç®—")
        
        # 2. æ ¹æ®ICè´¨é‡è¿‡æ»¤ç‰¹å¾
        candidates = self.filter_by_ic_quality(ic_stats)
        
        if len(candidates) == 0:
            raise ValueError("æ²¡æœ‰ç‰¹å¾é€šè¿‡ICè´¨é‡è¿‡æ»¤")
        
        # 3. å»é™¤å†—ä½™ç‰¹å¾
        selected = self.remove_redundant_features(X, candidates, ic_stats)
        
        self.selected_features_ = selected
        
        # 4. ğŸ”¥ NEW: æ³¨å†Œåˆ°FeatureRegistryç³»ç»Ÿ
        self._register_to_feature_registry(X, y, dates, selected, ic_stats)
        
        print("\n" + "=" * 60)
        print(f"Stage-Aç‰¹å¾é€‰æ‹©å®Œæˆ: {X.shape[1]} -> {len(selected)} ç‰¹å¾")
        print(f"æœ€ç»ˆç‰¹å¾: {selected}")
        print("âœ… å·²æ³¨å†Œåˆ°FeatureRegistryï¼Œé˜²æ­¢é‡å¤é€‰æ‹©")
        print("=" * 60)
        
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        è½¬æ¢ç‰¹å¾çŸ©é˜µï¼Œåªä¿ç•™é€‰æ‹©çš„ç‰¹å¾
        
        Args:
            X: è¾“å…¥ç‰¹å¾çŸ©é˜µ
            
        Returns:
            è½¬æ¢åçš„ç‰¹å¾çŸ©é˜µ
        """
        if self.selected_features_ is None:
            raise ValueError("ç‰¹å¾é€‰æ‹©å™¨æœªæ‹Ÿåˆ")
        
        return X[self.selected_features_]
    
    def fit_transform(self, X: pd.DataFrame, y: pd.Series, dates: pd.Series) -> pd.DataFrame:
        """
        æ‹Ÿåˆå¹¶è½¬æ¢ - SSOTå”¯ä¸€ç‰¹å¾é€‰æ‹©å…¥å£
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            dates: æ—¥æœŸåºåˆ—
            
        Returns:
            è½¬æ¢åçš„ç‰¹å¾çŸ©é˜µ
        """
        result = self.fit(X, y, dates).transform(X)
        
        # ğŸš¨ SSOTç‰¹å¾é€‰æ‹©è®°å½•ï¼šè½ç›˜evaluation_report.json
        self._save_feature_selection_report(X, result, y, dates)
        
        return result
    
    def _save_feature_selection_report(self, X_original: pd.DataFrame, X_selected: pd.DataFrame, 
                                     y: pd.Series, dates: pd.Series):
        """ä¿å­˜ç‰¹å¾é€‰æ‹©æŠ¥å‘Šåˆ°evaluation_report.json"""
        try:
            import json
            import hashlib
            from datetime import datetime
            
            # åˆ›å»ºç‰¹å¾é€‰æ‹©æŠ¥å‘Š
            feature_report = {
                "feature_selection": {
                    "selector": "RobustFeatureSelector",
                    "timestamp": datetime.now().isoformat(),
                    "original_features": len(X_original.columns),
                    "selected_features": len(X_selected.columns),
                    "reduction_ratio": 1 - len(X_selected.columns) / len(X_original.columns),
                    "selected_feature_names": X_selected.columns.tolist(),
                    "removed_feature_names": [col for col in X_original.columns if col not in X_selected.columns],
                    "selection_criteria": {
                        "min_ic_threshold": getattr(self, 'min_ic_threshold', 0.015),
                        "max_correlation": getattr(self, 'max_correlation', 0.85),
                        "min_ic_ir": getattr(self, 'min_ic_ir', 1.5)
                    },
                    "data_hash": hashlib.md5(str(X_original.values.tobytes()).encode()).hexdigest()[:8]
                }
            }
            
            # å°è¯•è¯»å–ç°æœ‰æŠ¥å‘Š
            evaluation_report = {}
            try:
                with open('evaluation_report.json', 'r', encoding='utf-8') as f:
                    evaluation_report = json.load(f)
            except FileNotFoundError:
                pass
            
            # æ›´æ–°æŠ¥å‘Š
            evaluation_report.update(feature_report)
            
            # ä¿å­˜æŠ¥å‘Š
            with open('evaluation_report.json', 'w', encoding='utf-8') as f:
                json.dump(evaluation_report, f, indent=2, ensure_ascii=False)
                
            print(f"âœ… SSOTç‰¹å¾é€‰æ‹©æŠ¥å‘Šå·²ä¿å­˜åˆ°evaluation_report.json")
            print(f"   åŸå§‹ç‰¹å¾: {len(X_original.columns)} â†’ é€‰æ‹©ç‰¹å¾: {len(X_selected.columns)}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç‰¹å¾é€‰æ‹©æŠ¥å‘Šå¤±è´¥: {e}")
    
    def get_feature_report(self) -> pd.DataFrame:
        """
        è·å–ç‰¹å¾é€‰æ‹©æŠ¥å‘Š
        
        Returns:
            ç‰¹å¾æŠ¥å‘ŠDataFrame
        """
        if self.feature_stats_ is None:
            raise ValueError("ç‰¹å¾é€‰æ‹©å™¨æœªæ‹Ÿåˆ")
        
        report_data = []
        
        for feature, (ic_mean, ic_std) in self.feature_stats_.items():
            ic_ir = ic_mean / (ic_std + 1e-8)
            selected = feature in (self.selected_features_ or [])
            
            # æ‰¾åˆ°ç‰¹å¾æ‰€å±çš„ç°‡
            cluster_id = None
            if self.feature_clusters_:
                for cid, cinfo in self.feature_clusters_.items():
                    if feature in cinfo['features']:
                        cluster_id = cid
                        break
            
            report_data.append({
                'feature': feature,
                'ic_mean': ic_mean,
                'ic_std': ic_std,
                'ic_ir': ic_ir,
                'selected': selected,
                'cluster': cluster_id
            })
        
        report_df = pd.DataFrame(report_data)
        return report_df.sort_values('ic_ir', ascending=False)
    
    def _register_to_feature_registry(self, X: pd.DataFrame, y: pd.Series, 
                                    dates: pd.Series, selected_features: List[str], 
                                    ic_stats: Dict[str, Tuple[float, float]]):
        """
        å°†Stage-Aé€‰æ‹©ç»“æœæ³¨å†Œåˆ°FeatureRegistry
        
        Args:
            X: åŸå§‹ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            dates: æ—¥æœŸåºåˆ—
            selected_features: é€‰æ‹©çš„ç‰¹å¾åˆ—è¡¨
            ic_stats: ICç»Ÿè®¡ç»“æœ
        """
        try:
            from .feature_registry import get_feature_registry
            
            registry = get_feature_registry()
            
            # å‡†å¤‡ç‰¹å¾å…ƒæ•°æ®
            feature_metadata = {}
            for feature in selected_features:
                if feature in ic_stats:
                    ic_mean, ic_std = ic_stats[feature]
                    ic_ir = ic_mean / (ic_std + 1e-8)
                    
                    # æ‰¾åˆ°ç‰¹å¾æ‰€å±ç°‡
                    cluster_id = None
                    if self.feature_clusters_:
                        for cid, cinfo in self.feature_clusters_.items():
                            if feature in cinfo['features']:
                                cluster_id = cid
                                break
                    
                    feature_metadata[feature] = {
                        'ic_mean': ic_mean,
                        'ic_std': ic_std,
                        'ic_ir': ic_ir,
                        'cluster': cluster_id,
                        'family': self._get_feature_family(feature)
                    }
            
            # å‡†å¤‡é€‰æ‹©ç»Ÿè®¡
            selection_stats = {
                'input_features': len(X.columns),
                'output_features': len(selected_features),
                'reduction_ratio': len(selected_features) / len(X.columns),
                'ic_candidates': len([f for f, stats in ic_stats.items() 
                                    if stats[0] > self.min_ic_mean]),
                'final_avg_ic': np.mean([ic_stats[f][0] for f in selected_features]),
                'final_avg_ic_ir': np.mean([ic_stats[f][0]/(ic_stats[f][1]+1e-8) 
                                          for f in selected_features]),
                'selection_date_range': {
                    'start': str(dates.min()),
                    'end': str(dates.max()),
                    'days': int((dates.max() - dates.min()).days)
                }
            }
            
            # å‡†å¤‡é€‰æ‹©å™¨é…ç½®
            selector_config = {
                'target_features': self.target_features,
                'ic_window': self.ic_window,
                'min_ic_mean': self.min_ic_mean,
                'min_ic_ir': self.min_ic_ir,
                'max_correlation': self.max_correlation,
                'method': 'RobustFeatureSelector_v1'
            }
            
            # æ³¨å†Œåˆ°ç³»ç»Ÿ
            registry_id = registry.register_stage_a_selection(
                selected_features=selected_features,
                feature_metadata=feature_metadata,
                selection_stats=selection_stats,
                selector_config=selector_config
            )
            
            print(f"âœ… Stage-Aç»“æœå·²æ³¨å†Œ: {registry_id}")
            
        except ImportError as e:
            print(f"âš ï¸ FeatureRegistryå¯¼å…¥å¤±è´¥ï¼Œè·³è¿‡æ³¨å†Œ: {e}")
        except Exception as e:
            print(f"âš ï¸ FeatureRegistryæ³¨å†Œå¤±è´¥: {e}")
    
    def _get_feature_family(self, feature_name: str) -> str:
        """
        æ ¹æ®ç‰¹å¾åæ¨æ–­ç‰¹å¾æ—
        
        Args:
            feature_name: ç‰¹å¾å
            
        Returns:
            ç‰¹å¾æ—åç§°
        """
        feature_lower = feature_name.lower()
        
        if 'rsi' in feature_lower:
            return 'momentum_rsi'
        elif 'macd' in feature_lower:
            return 'momentum_macd'
        elif 'bb' in feature_lower or 'bollinger' in feature_lower:
            return 'volatility_bb'
        elif 'volume' in feature_lower or 'vol' in feature_lower:
            return 'volume'
        elif 'price' in feature_lower or 'close' in feature_lower:
            return 'price'
        elif 'return' in feature_lower:
            return 'returns'
        elif 'alpha' in feature_lower:
            return 'alpha_factors'
        else:
            return 'other'


def test_robust_feature_selection():
    """æµ‹è¯•ç¨³å¥ç‰¹å¾é€‰æ‹©"""
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    # np.random.seed removed
    n_samples = 1000
    n_features = 50
    
    dates = pd.date_range('2020-01-01', periods=n_samples, freq='D')
    
    # åˆ›å»ºåŸºç¡€ä¿¡å·
    base_signal = np.cumsum(np.zeros(n_samples) * 0.01)  # æ¨¡æ‹Ÿä»·æ ¼èµ°åŠ¿
    
    # åˆ›å»ºä¸€äº›æœ‰é¢„æµ‹èƒ½åŠ›çš„ç‰¹å¾
    X = pd.DataFrame()
    
    # é«˜è´¨é‡ç‰¹å¾ (ä¸æœªæ¥æ”¶ç›Šæ­£ç›¸å…³)
    for i in range(10):
        # åˆ›å»ºä¸æœªæ¥ä¿¡å·ç›¸å…³çš„ç‰¹å¾
        feature = np.roll(base_signal, -5) + np.zeros(n_samples) * 0.5  # å‰ç»5å¤©çš„ä¿¡å·åŠ å™ªå£°
        X[f'good_feature_{i}'] = feature
    
    # ä¸­ç­‰è´¨é‡ç‰¹å¾ (å¼±ç›¸å…³)
    for i in range(15):
        feature = np.roll(base_signal, -2) + np.zeros(n_samples) * 1.0  # å‰ç»2å¤©ä½†å™ªå£°æ›´å¤§
        X[f'medium_feature_{i}'] = feature
    
    # ä½è´¨é‡ç‰¹å¾ (æ— ç›¸å…³æ€§)
    for i in range(25):
        X[f'bad_feature_{i}'] = np.zeros(n_samples)
    
    # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆæœªæ¥æ”¶ç›Šï¼‰
    future_return = np.diff(base_signal, prepend=base_signal[0])  # æ”¶ç›Šç‡
    y = pd.Series(future_return + np.zeros(n_samples) * 0.2)  # åŠ å…¥å™ªå£°
    
    print("æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ")
    print(f"ç‰¹å¾æ•°: {X.shape[1]}, æ ·æœ¬æ•°: {len(X)}")
    
    # è¿è¡Œç‰¹å¾é€‰æ‹©
    selector = RobustFeatureSelector(
        target_features=15,
        ic_window=60,  # 2ä¸ªæœˆçª—å£
        min_ic_mean=0.005,
        min_ic_ir=0.2,
        max_correlation=0.7
    )
    
    X_selected = selector.fit_transform(X, y, dates)
    
    print(f"\næœ€ç»ˆé€‰æ‹©çš„ç‰¹å¾: {list(X_selected.columns)}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = selector.get_feature_report()
    
    print("\nç‰¹å¾é€‰æ‹©æŠ¥å‘Š (Top 20):")
    print(report.head(20).to_string(index=False))
    
    print(f"\né€‰æ‹©çš„ç‰¹å¾ç»Ÿè®¡:")
    selected_report = report[report['selected']]
    print(f"å¹³å‡IC: {selected_report['ic_mean'].mean():.4f}")
    print(f"å¹³å‡IC_IR: {selected_report['ic_ir'].mean():.4f}")
    print(f"ICèŒƒå›´: {selected_report['ic_mean'].min():.4f} - {selected_report['ic_mean'].max():.4f}")


if __name__ == "__main__":
    test_robust_feature_selection()
