#!/usr/bin/env python3
"""
å…¨é¢åˆ†ææ•°æ®ç»“æ„é—®é¢˜çš„è¯Šæ–­è„šæœ¬
1. è¯­æ³•é”™è¯¯æ£€æµ‹
2. æ•°æ®ç»“æ„æ¨¡å¼åˆ†æ
3. å†…å­˜ä½¿ç”¨æ¨¡å¼åˆ†æ
4. ç´¢å¼•ç­–ç•¥é—®é¢˜
5. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
"""

import os
import re
import ast
import sys
from typing import List, Dict, Any
import subprocess

def analyze_syntax_errors(file_path: str) -> List[str]:
    """åˆ†æè¯­æ³•é”™è¯¯"""
    print("1. åˆ†æè¯­æ³•é”™è¯¯...")
    errors = []
    
    try:
        # ä½¿ç”¨py_compileæ£€æŸ¥è¯­æ³•
        result = subprocess.run([sys.executable, '-m', 'py_compile', file_path], 
                              capture_output=True, text=True)
        if result.returncode != 0:
            errors.append(f"è¯­æ³•é”™è¯¯: {result.stderr}")
    except Exception as e:
        errors.append(f"è¯­æ³•æ£€æŸ¥å¤±è´¥: {e}")
    
    return errors

def analyze_data_structure_patterns(content: str) -> Dict[str, Any]:
    """åˆ†ææ•°æ®ç»“æ„ä½¿ç”¨æ¨¡å¼"""
    print("2. åˆ†ææ•°æ®ç»“æ„ä½¿ç”¨æ¨¡å¼...")
    
    patterns = {
        'copy_operations': len(re.findall(r'\.copy\(\)', content)),
        'reset_index_operations': len(re.findall(r'\.reset_index\(\)', content)),
        'set_index_operations': len(re.findall(r'\.set_index\(', content)),
        'concat_operations': len(re.findall(r'pd\.concat\(', content)),
        'merge_operations': len(re.findall(r'\.merge\(', content)),
        'fillna_operations': len(re.findall(r'\.fillna\(', content)),
        'shift_operations': len(re.findall(r'\.shift\(', content)),
        'rolling_operations': len(re.findall(r'\.rolling\(', content)),
        'multiindex_checks': len(re.findall(r'isinstance.*MultiIndex', content)),
        'dataframe_creations': len(re.findall(r'pd\.DataFrame\(', content)),
    }
    
    return patterns

def analyze_memory_issues(content: str) -> List[str]:
    """åˆ†æå†…å­˜ä½¿ç”¨é—®é¢˜"""
    print("3. åˆ†æå†…å­˜ä½¿ç”¨é—®é¢˜...")
    issues = []
    
    # æ£€æŸ¥å¤§å‹æ•°æ®å¤åˆ¶
    copy_in_loops = re.findall(r'for.*:\s*\n.*\.copy\(\)', content, re.MULTILINE)
    if copy_in_loops:
        issues.append(f"å‘ç°å¾ªç¯ä¸­çš„copyæ“ä½œ: {len(copy_in_loops)}ä¸ª")
    
    # æ£€æŸ¥è¿ç»­çš„DataFrameæ“ä½œ
    chained_ops = re.findall(r'\.copy\(\)\..*\..*\.', content)
    if chained_ops:
        issues.append(f"å‘ç°é“¾å¼DataFrameæ“ä½œ: {len(chained_ops)}ä¸ª")
    
    # æ£€æŸ¥ä¸å¿…è¦çš„ä¸­é—´å˜é‡
    temp_vars = re.findall(r'temp_\w+\s*=.*\.copy\(\)', content)
    if temp_vars:
        issues.append(f"å‘ç°ä¸´æ—¶å˜é‡copy: {len(temp_vars)}ä¸ª")
    
    return issues

def analyze_index_strategy_issues(content: str) -> List[str]:
    """åˆ†æç´¢å¼•ç­–ç•¥é—®é¢˜"""
    print("4. åˆ†æç´¢å¼•ç­–ç•¥é—®é¢˜...")
    issues = []
    
    # æ£€æŸ¥ç´¢å¼•é‡ç½®æ¨¡å¼
    reset_set_pattern = re.findall(r'\.reset_index\(\).*\.set_index\(', content)
    if reset_set_pattern:
        issues.append(f"å‘ç°reset_index -> set_indexæ¨¡å¼: {len(reset_set_pattern)}ä¸ª")
    
    # æ£€æŸ¥ä¸ä¸€è‡´çš„ç´¢å¼•å‘½å
    index_names = re.findall(r'\.set_index\(\[(.*?)\]\)', content)
    unique_patterns = set(index_names)
    if len(unique_patterns) > 1:
        issues.append(f"ç´¢å¼•å‘½åä¸ä¸€è‡´: {unique_patterns}")
    
    # æ£€æŸ¥MultiIndexé¢‘ç¹æ£€æŸ¥
    multiindex_checks = len(re.findall(r'isinstance.*MultiIndex', content))
    if multiindex_checks > 20:
        issues.append(f"è¿‡å¤šMultiIndexæ£€æŸ¥: {multiindex_checks}æ¬¡")
    
    return issues

def analyze_temporal_safety_issues(content: str) -> List[str]:
    """åˆ†ææ—¶é—´å®‰å…¨é—®é¢˜"""
    print("5. åˆ†ææ—¶é—´å®‰å…¨é—®é¢˜...")
    issues = []
    
    # æ£€æŸ¥è´Ÿæ•°shift
    negative_shifts = re.findall(r'\.shift\(-\d+\)', content)
    if negative_shifts:
        issues.append(f"å‘ç°è´Ÿæ•°shiftæ“ä½œ: {len(negative_shifts)}ä¸ª - å¯èƒ½å¯¼è‡´æ•°æ®æ³„æ¼")
    
    # æ£€æŸ¥åå‘å¡«å……
    backward_fill = re.findall(r"fillna\(method=['\"]backward['\"]", content)
    if backward_fill:
        issues.append(f"å‘ç°åå‘å¡«å……: {len(backward_fill)}ä¸ª - ä¼šå¯¼è‡´æ•°æ®æ³„æ¼")
    
    # æ£€æŸ¥center=Trueçš„rolling
    center_rolling = re.findall(r'\.rolling\([^)]*center=True', content)
    if center_rolling:
        issues.append(f"å‘ç°center=Trueçš„rolling: {len(center_rolling)}ä¸ª - ä½¿ç”¨æœªæ¥æ•°æ®")
    
    return issues

def find_problematic_code_sections(content: str) -> Dict[str, List[str]]:
    """æ‰¾å‡ºæœ‰é—®é¢˜çš„ä»£ç æ®µ"""
    print("6. è¯†åˆ«æœ‰é—®é¢˜çš„ä»£ç æ®µ...")
    
    problems = {
        'malformed_lines': [],
        'incomplete_blocks': [],
        'syntax_issues': []
    }
    
    lines = content.split('\n')
    
    for i, line in enumerate(lines, 1):
        # æ£€æŸ¥æ ¼å¼é”™è¯¯çš„è¡Œ
        if '# OPTIMIZED:' in line and not line.strip().endswith((':', ')', ']', '}')):
            if "'" in line and line.count("'") % 2 == 1:
                problems['malformed_lines'].append(f"Line {i}: {line.strip()}")
        
        # æ£€æŸ¥æœªå®Œæˆçš„tryå—
        if line.strip().startswith('try:'):
            # æŸ¥æ‰¾å¯¹åº”çš„exceptæˆ–finally
            found_except = False
            for j in range(i, min(i+50, len(lines))):
                if lines[j].strip().startswith(('except', 'finally')):
                    found_except = True
                    break
            if not found_except:
                problems['incomplete_blocks'].append(f"Line {i}: æœªå®Œæˆçš„tryå—")
    
    return problems

def generate_fix_recommendations(analysis_results: Dict[str, Any]) -> List[str]:
    """ç”Ÿæˆä¿®å¤å»ºè®®"""
    print("7. ç”Ÿæˆä¿®å¤å»ºè®®...")
    
    recommendations = []
    
    # è¯­æ³•é”™è¯¯ä¿®å¤
    if analysis_results['syntax_errors']:
        recommendations.append("ğŸ”´ ç´§æ€¥: ä¿®å¤è¯­æ³•é”™è¯¯")
        recommendations.extend([f"  - {error}" for error in analysis_results['syntax_errors']])
    
    # æ€§èƒ½ä¼˜åŒ–å»ºè®®
    patterns = analysis_results['data_patterns']
    if patterns['copy_operations'] > 20:
        recommendations.append(f"âš¡ ä¼˜åŒ–: å‡å°‘copyæ“ä½œ (å½“å‰: {patterns['copy_operations']}æ¬¡)")
    
    if patterns['reset_index_operations'] > 15:
        recommendations.append(f"âš¡ ä¼˜åŒ–: ç»Ÿä¸€ç´¢å¼•ç­–ç•¥ (å½“å‰reset_index: {patterns['reset_index_operations']}æ¬¡)")
    
    # å†…å­˜ä¼˜åŒ–å»ºè®®
    if analysis_results['memory_issues']:
        recommendations.append("ğŸ’¾ å†…å­˜ä¼˜åŒ–:")
        recommendations.extend([f"  - {issue}" for issue in analysis_results['memory_issues']])
    
    # æ—¶é—´å®‰å…¨å»ºè®®
    if analysis_results['temporal_issues']:
        recommendations.append("âš ï¸  æ—¶é—´å®‰å…¨ä¿®å¤:")
        recommendations.extend([f"  - {issue}" for issue in analysis_results['temporal_issues']])
    
    return recommendations

def run_comprehensive_analysis():
    """è¿è¡Œå…¨é¢åˆ†æ"""
    file_path = "bma_models/é‡åŒ–æ¨¡å‹_bma_ultra_enhanced.py"
    
    print("=== å¼€å§‹å…¨é¢æ•°æ®ç»“æ„é—®é¢˜åˆ†æ ===\n")
    
    # è¯»å–æ–‡ä»¶
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦\n")
    except Exception as e:
        print(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    analysis_results = {
        'syntax_errors': analyze_syntax_errors(file_path),
        'data_patterns': analyze_data_structure_patterns(content),
        'memory_issues': analyze_memory_issues(content),
        'index_issues': analyze_index_strategy_issues(content),
        'temporal_issues': analyze_temporal_safety_issues(content),
        'code_problems': find_problematic_code_sections(content)
    }
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n=== åˆ†æç»“æœæŠ¥å‘Š ===")
    
    print("\nğŸ“Š æ•°æ®ç»“æ„æ“ä½œç»Ÿè®¡:")
    for op, count in analysis_results['data_patterns'].items():
        if count > 0:
            status = "ğŸ”´" if count > 30 else "ğŸŸ¡" if count > 15 else "ğŸŸ¢"
            print(f"  {status} {op}: {count}")
    
    print("\nğŸ” å‘ç°çš„é—®é¢˜:")
    total_issues = 0
    
    for category, issues in analysis_results.items():
        if isinstance(issues, list) and issues:
            total_issues += len(issues)
            print(f"\n{category.upper()}:")
            for issue in issues:
                print(f"  - {issue}")
        elif isinstance(issues, dict):
            for subcategory, subitems in issues.items():
                if subitems:
                    total_issues += len(subitems)
                    print(f"\n{subcategory.upper()}:")
                    for item in subitems:
                        print(f"  - {item}")
    
    print(f"\nğŸ“ˆ æ€»è®¡å‘ç°é—®é¢˜: {total_issues} ä¸ª")
    
    # ç”Ÿæˆä¿®å¤å»ºè®®
    recommendations = generate_fix_recommendations(analysis_results)
    
    print("\nğŸ”§ ä¿®å¤å»ºè®®:")
    for rec in recommendations:
        print(f"  {rec}")
    
    print("\n=== åˆ†æå®Œæˆ ===")
    
    return analysis_results

if __name__ == "__main__":
    run_comprehensive_analysis()