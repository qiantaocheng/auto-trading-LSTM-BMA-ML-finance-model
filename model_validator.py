#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹éªŒè¯å™¨ - ç¡®ä¿BMAå’ŒLSTMæ¨¡å‹è¿”å›æ­£ç¡®çš„JSONå’ŒExcelæ ¼å¼
æ¯å‘¨ä¸€è‡ªåŠ¨è¿è¡Œï¼Œç»“åˆä¸¤ä¸ªæ¨¡å‹çš„top10è‚¡ç¥¨
"""

import os
import sys
import json
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import glob
import schedule
import time
import threading

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))


class ModelValidator:
    """æ¨¡å‹éªŒè¯å™¨"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # æ–‡ä»¶è·¯å¾„é…ç½®
        self.result_dir = Path("result")
        self.bma_pattern = "bma_quantitative_analysis_*.xlsx"
        self.lstm_pattern = "*lstm_analysis_*.xlsx"
        
        # è¾“å‡ºè·¯å¾„
        self.output_dir = Path("model_outputs")
        self.output_dir.mkdir(exist_ok=True)
        
        # éªŒè¯æ ‡å‡†
        self.required_bma_columns = ['ticker', 'rating', 'score', 'recommendation']
        self.required_lstm_columns = ['ticker', 'rating', 'weighted_prediction', 'confidence_score']
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.validation_stats = {
            'bma': {'found': False, 'valid': False, 'top10': []},
            'lstm': {'found': False, 'valid': False, 'top10': []},
            'combined_top10': [],
            'last_validation': None
        }
    
    def find_latest_model_files(self) -> Tuple[Optional[Path], Optional[Path]]:
        """æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶"""
        try:
            # æŸ¥æ‰¾BMAæ–‡ä»¶
            bma_files = list(self.result_dir.glob(self.bma_pattern))
            latest_bma = max(bma_files, key=os.path.getmtime) if bma_files else None
            
            # æŸ¥æ‰¾LSTMæ–‡ä»¶
            lstm_files = list(self.result_dir.glob(self.lstm_pattern))
            latest_lstm = max(lstm_files, key=os.path.getmtime) if lstm_files else None
            
            if latest_bma:
                self.logger.info(f"âœ… æ‰¾åˆ°BMAæ–‡ä»¶: {latest_bma}")
            else:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°BMAæ–‡ä»¶")
            
            if latest_lstm:
                self.logger.info(f"âœ… æ‰¾åˆ°LSTMæ–‡ä»¶: {latest_lstm}")
            else:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°LSTMæ–‡ä»¶")
            
            return latest_bma, latest_lstm
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
            return None, None
    
    def validate_bma_file(self, file_path: Path) -> Dict:
        """éªŒè¯BMAæ–‡ä»¶æ ¼å¼"""
        validation_result = {
            'valid': False,
            'file_path': str(file_path),
            'file_size': 0,
            'sheets': [],
            'data_rows': 0,
            'top10': [],
            'errors': []
        }
        
        try:
            if not file_path.exists():
                validation_result['errors'].append("æ–‡ä»¶ä¸å­˜åœ¨")
                return validation_result
            
            validation_result['file_size'] = file_path.stat().st_size
            
            # è¯»å–Excelæ–‡ä»¶
            excel_file = pd.ExcelFile(file_path)
            validation_result['sheets'] = excel_file.sheet_names
            
            self.logger.info(f"ğŸ“Š BMAæ–‡ä»¶åŒ…å«å·¥ä½œè¡¨: {validation_result['sheets']}")
            
            # æŸ¥æ‰¾ä¸»è¦æ•°æ®å·¥ä½œè¡¨
            main_sheet = None
            for sheet_name in excel_file.sheet_names:
                if any(keyword in sheet_name.lower() for keyword in ['analysis', 'result', 'recommend', 'main']):
                    main_sheet = sheet_name
                    break
            
            if not main_sheet:
                main_sheet = excel_file.sheet_names[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            
            # è¯»å–æ•°æ®
            df = pd.read_excel(file_path, sheet_name=main_sheet)
            validation_result['data_rows'] = len(df)
            
            self.logger.info(f"ğŸ“ˆ BMAæ•°æ®è¡Œæ•°: {len(df)}")
            self.logger.info(f"ğŸ“‹ BMAåˆ—å: {list(df.columns)}")
            
            # æ£€æŸ¥å¿…è¦åˆ—
            missing_columns = []
            for col in self.required_bma_columns:
                # æ¨¡ç³ŠåŒ¹é…åˆ—å
                found = False
                for df_col in df.columns:
                    if col.lower() in str(df_col).lower():
                        found = True
                        break
                if not found:
                    missing_columns.append(col)
            
            if missing_columns:
                validation_result['errors'].append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            
            # å°è¯•æå–top10
            try:
                # å°è¯•ä¸åŒçš„è¯„åˆ†åˆ—å
                score_columns = ['score', 'rating', 'recommendation_score', 'bma_score']
                score_col = None
                
                for col in score_columns:
                    for df_col in df.columns:
                        if col.lower() in str(df_col).lower():
                            score_col = df_col
                            break
                    if score_col:
                        break
                
                if score_col:
                    # æ’åºå¹¶è·å–top10
                    top_df = df.nlargest(10, score_col)
                    
                    # æŸ¥æ‰¾tickeråˆ—
                    ticker_col = None
                    for col in ['ticker', 'symbol', 'stock', 'code']:
                        for df_col in df.columns:
                            if col.lower() in str(df_col).lower():
                                ticker_col = df_col
                                break
                        if ticker_col:
                            break
                    
                    if ticker_col:
                        validation_result['top10'] = [
                            {
                                'ticker': row[ticker_col],
                                'score': row[score_col],
                                'rank': i + 1
                            }
                            for i, (_, row) in enumerate(top_df.iterrows())
                        ]
                        
                        self.logger.info(f"ğŸ¯ BMA Top10: {[item['ticker'] for item in validation_result['top10']]}")
                    else:
                        validation_result['errors'].append("æ‰¾ä¸åˆ°è‚¡ç¥¨ä»£ç åˆ—")
                else:
                    validation_result['errors'].append("æ‰¾ä¸åˆ°è¯„åˆ†åˆ—")
                    
            except Exception as e:
                validation_result['errors'].append(f"æå–top10å¤±è´¥: {str(e)}")
            
            # éªŒè¯é€šè¿‡æ¡ä»¶
            validation_result['valid'] = (
                len(validation_result['errors']) == 0 and
                validation_result['data_rows'] > 0 and
                len(validation_result['top10']) > 0
            )
            
            if validation_result['valid']:
                self.logger.info("âœ… BMAæ–‡ä»¶éªŒè¯é€šè¿‡")
            else:
                self.logger.warning(f"âš ï¸ BMAæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result['errors']}")
            
            return validation_result
            
        except Exception as e:
            validation_result['errors'].append(f"è¯»å–æ–‡ä»¶å¼‚å¸¸: {str(e)}")
            self.logger.error(f"âŒ BMAæ–‡ä»¶éªŒè¯å¼‚å¸¸: {e}")
            return validation_result
    
    def validate_lstm_file(self, file_path: Path) -> Dict:
        """éªŒè¯LSTMæ–‡ä»¶æ ¼å¼"""
        validation_result = {
            'valid': False,
            'file_path': str(file_path),
            'file_size': 0,
            'sheets': [],
            'data_rows': 0,
            'top10': [],
            'errors': []
        }
        
        try:
            if not file_path.exists():
                validation_result['errors'].append("æ–‡ä»¶ä¸å­˜åœ¨")
                return validation_result
            
            validation_result['file_size'] = file_path.stat().st_size
            
            # è¯»å–Excelæ–‡ä»¶
            excel_file = pd.ExcelFile(file_path)
            validation_result['sheets'] = excel_file.sheet_names
            
            self.logger.info(f"ğŸ“Š LSTMæ–‡ä»¶åŒ…å«å·¥ä½œè¡¨: {validation_result['sheets']}")
            
            # æŸ¥æ‰¾ä¸»è¦æ•°æ®å·¥ä½œè¡¨
            main_sheet = None
            for sheet_name in excel_file.sheet_names:
                if any(keyword in sheet_name.lower() for keyword in ['prediction', 'result', 'analysis', 'main']):
                    main_sheet = sheet_name
                    break
            
            if not main_sheet:
                main_sheet = excel_file.sheet_names[0]
            
            # è¯»å–æ•°æ®
            df = pd.read_excel(file_path, sheet_name=main_sheet)
            validation_result['data_rows'] = len(df)
            
            self.logger.info(f"ğŸ“ˆ LSTMæ•°æ®è¡Œæ•°: {len(df)}")
            self.logger.info(f"ğŸ“‹ LSTMåˆ—å: {list(df.columns)}")
            
            # æ£€æŸ¥å¿…è¦åˆ—
            missing_columns = []
            for col in self.required_lstm_columns:
                found = False
                for df_col in df.columns:
                    if col.lower() in str(df_col).lower():
                        found = True
                        break
                if not found:
                    missing_columns.append(col)
            
            if missing_columns:
                validation_result['errors'].append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            
            # å°è¯•æå–top10
            try:
                # å°è¯•ä¸åŒçš„é¢„æµ‹åˆ—å
                pred_columns = ['weighted_prediction', 'prediction', 'confidence_score', 'lstm_score']
                pred_col = None
                
                for col in pred_columns:
                    for df_col in df.columns:
                        if col.lower() in str(df_col).lower():
                            pred_col = df_col
                            break
                    if pred_col:
                        break
                
                if pred_col:
                    # æ’åºå¹¶è·å–top10
                    top_df = df.nlargest(10, pred_col)
                    
                    # æŸ¥æ‰¾tickeråˆ—
                    ticker_col = None
                    for col in ['ticker', 'symbol', 'stock', 'code']:
                        for df_col in df.columns:
                            if col.lower() in str(df_col).lower():
                                ticker_col = df_col
                                break
                        if ticker_col:
                            break
                    
                    if ticker_col:
                        validation_result['top10'] = [
                            {
                                'ticker': row[ticker_col],
                                'score': row[pred_col],
                                'rank': i + 1
                            }
                            for i, (_, row) in enumerate(top_df.iterrows())
                        ]
                        
                        self.logger.info(f"ğŸ¯ LSTM Top10: {[item['ticker'] for item in validation_result['top10']]}")
                    else:
                        validation_result['errors'].append("æ‰¾ä¸åˆ°è‚¡ç¥¨ä»£ç åˆ—")
                else:
                    validation_result['errors'].append("æ‰¾ä¸åˆ°é¢„æµ‹è¯„åˆ†åˆ—")
                    
            except Exception as e:
                validation_result['errors'].append(f"æå–top10å¤±è´¥: {str(e)}")
            
            # éªŒè¯é€šè¿‡æ¡ä»¶
            validation_result['valid'] = (
                len(validation_result['errors']) == 0 and
                validation_result['data_rows'] > 0 and
                len(validation_result['top10']) > 0
            )
            
            if validation_result['valid']:
                self.logger.info("âœ… LSTMæ–‡ä»¶éªŒè¯é€šè¿‡")
            else:
                self.logger.warning(f"âš ï¸ LSTMæ–‡ä»¶éªŒè¯å¤±è´¥: {validation_result['errors']}")
            
            return validation_result
            
        except Exception as e:
            validation_result['errors'].append(f"è¯»å–æ–‡ä»¶å¼‚å¸¸: {str(e)}")
            self.logger.error(f"âŒ LSTMæ–‡ä»¶éªŒè¯å¼‚å¸¸: {e}")
            return validation_result
    
    def combine_top10_recommendations(self, bma_top10: List[Dict], lstm_top10: List[Dict]) -> List[Dict]:
        """ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„top10æ¨è"""
        try:
            # åˆ›å»ºè‚¡ç¥¨è¯„åˆ†å­—å…¸
            stock_scores = {}
            
            # æ·»åŠ BMAè¯„åˆ† (æƒé‡0.5)
            for item in bma_top10:
                ticker = item['ticker']
                score = item['score']
                rank = item['rank']
                
                if ticker not in stock_scores:
                    stock_scores[ticker] = {'bma_score': 0, 'lstm_score': 0, 'bma_rank': 999, 'lstm_rank': 999}
                
                stock_scores[ticker]['bma_score'] = float(score) if score is not None else 0
                stock_scores[ticker]['bma_rank'] = rank
            
            # æ·»åŠ LSTMè¯„åˆ† (æƒé‡0.5)
            for item in lstm_top10:
                ticker = item['ticker']
                score = item['score']
                rank = item['rank']
                
                if ticker not in stock_scores:
                    stock_scores[ticker] = {'bma_score': 0, 'lstm_score': 0, 'bma_rank': 999, 'lstm_rank': 999}
                
                stock_scores[ticker]['lstm_score'] = float(score) if score is not None else 0
                stock_scores[ticker]['lstm_rank'] = rank
            
            # è®¡ç®—ç»¼åˆè¯„åˆ†
            combined_scores = []
            for ticker, scores in stock_scores.items():
                # ç»¼åˆè¯„åˆ† = 0.5 * BMAè¯„åˆ† + 0.5 * LSTMè¯„åˆ† - æ’åæƒ©ç½š
                bma_norm = scores['bma_score'] / max([s['bma_score'] for s in stock_scores.values()]) if max([s['bma_score'] for s in stock_scores.values()]) > 0 else 0
                lstm_norm = scores['lstm_score'] / max([s['lstm_score'] for s in stock_scores.values()]) if max([s['lstm_score'] for s in stock_scores.values()]) > 0 else 0
                
                # æ’ååŠ åˆ† (æ’åè¶Šé«˜åŠ åˆ†è¶Šå¤š)
                rank_bonus = (20 - scores['bma_rank']) / 20 + (20 - scores['lstm_rank']) / 20
                
                combined_score = (bma_norm * 0.5 + lstm_norm * 0.5) + rank_bonus * 0.1
                
                combined_scores.append({
                    'ticker': ticker,
                    'combined_score': combined_score,
                    'bma_score': scores['bma_score'],
                    'lstm_score': scores['lstm_score'],
                    'bma_rank': scores['bma_rank'],
                    'lstm_rank': scores['lstm_rank'],
                    'in_both': scores['bma_rank'] <= 10 and scores['lstm_rank'] <= 10
                })
            
            # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼Œå–top10
            combined_scores.sort(key=lambda x: x['combined_score'], reverse=True)
            top10_combined = combined_scores[:10]
            
            # æ·»åŠ æœ€ç»ˆæ’å
            for i, item in enumerate(top10_combined):
                item['final_rank'] = i + 1
            
            self.logger.info(f"ğŸ† ç»¼åˆTop10: {[item['ticker'] for item in top10_combined]}")
            
            return top10_combined
            
        except Exception as e:
            self.logger.error(f"âŒ ç»“åˆtop10å¤±è´¥: {e}")
            return []
    
    def save_combined_results(self, combined_top10: List[Dict]) -> bool:
        """ä¿å­˜ç»¼åˆç»“æœ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜JSONæ ¼å¼
            json_file = self.output_dir / f"combined_top10_{timestamp}.json"
            json_data = {
                'generated_at': datetime.now().isoformat(),
                'model_combination': 'BMA + LSTM',
                'top10_stocks': combined_top10,
                'summary': {
                    'total_stocks': len(combined_top10),
                    'stocks_in_both_models': len([s for s in combined_top10 if s.get('in_both', False)]),
                    'bma_only': len([s for s in combined_top10 if s.get('bma_rank', 999) <= 10 and s.get('lstm_rank', 999) > 10]),
                    'lstm_only': len([s for s in combined_top10 if s.get('lstm_rank', 999) <= 10 and s.get('bma_rank', 999) > 10])
                }
            }
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜Excelæ ¼å¼
            excel_file = self.output_dir / f"combined_top10_{timestamp}.xlsx"
            df = pd.DataFrame(combined_top10)
            
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='Combined_Top10', index=False)
                
                # æ·»åŠ æ±‡æ€»ä¿¡æ¯
                summary_df = pd.DataFrame([json_data['summary']])
                summary_df.to_excel(writer, sheet_name='Summary', index=False)
            
            # ä¿å­˜ç®€å•çš„è‚¡ç¥¨åˆ—è¡¨
            symbols_file = self.output_dir / f"top10_symbols_{timestamp}.txt"
            with open(symbols_file, 'w', encoding='utf-8') as f:
                for item in combined_top10:
                    f.write(f"{item['ticker']}\n")
            
            self.logger.info(f"âœ… ç»¼åˆç»“æœå·²ä¿å­˜:")
            self.logger.info(f"   JSON: {json_file}")
            self.logger.info(f"   Excel: {excel_file}")
            self.logger.info(f"   ç¬¦å·åˆ—è¡¨: {symbols_file}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç»¼åˆç»“æœå¤±è´¥: {e}")
            return False
    
    def run_validation(self) -> Dict:
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹æ¨¡å‹éªŒè¯...")
        
        # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
        bma_file, lstm_file = self.find_latest_model_files()
        
        # éªŒè¯BMAæ–‡ä»¶
        bma_result = None
        if bma_file:
            self.validation_stats['bma']['found'] = True
            bma_result = self.validate_bma_file(bma_file)
            self.validation_stats['bma']['valid'] = bma_result['valid']
            self.validation_stats['bma']['top10'] = bma_result['top10']
        
        # éªŒè¯LSTMæ–‡ä»¶
        lstm_result = None
        if lstm_file:
            self.validation_stats['lstm']['found'] = True
            lstm_result = self.validate_lstm_file(lstm_file)
            self.validation_stats['lstm']['valid'] = lstm_result['valid']
            self.validation_stats['lstm']['top10'] = lstm_result['top10']
        
        # ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„ç»“æœ
        if (bma_result and bma_result['valid'] and 
            lstm_result and lstm_result['valid']):
            
            combined_top10 = self.combine_top10_recommendations(
                bma_result['top10'], 
                lstm_result['top10']
            )
            
            if combined_top10:
                self.validation_stats['combined_top10'] = combined_top10
                self.save_combined_results(combined_top10)
        
        self.validation_stats['last_validation'] = datetime.now().isoformat()
        
        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        report = {
            'validation_time': self.validation_stats['last_validation'],
            'bma': {
                'file_found': self.validation_stats['bma']['found'],
                'validation_passed': self.validation_stats['bma']['valid'],
                'file_path': str(bma_file) if bma_file else None,
                'top10_count': len(self.validation_stats['bma']['top10']),
                'details': bma_result
            },
            'lstm': {
                'file_found': self.validation_stats['lstm']['found'],
                'validation_passed': self.validation_stats['lstm']['valid'],
                'file_path': str(lstm_file) if lstm_file else None,
                'top10_count': len(self.validation_stats['lstm']['top10']),
                'details': lstm_result
            },
            'combined': {
                'success': len(self.validation_stats['combined_top10']) > 0,
                'top10_count': len(self.validation_stats['combined_top10']),
                'recommendations': self.validation_stats['combined_top10']
            }
        }
        
        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        report_file = self.output_dir / f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        self.logger.info(f"ğŸ“Š éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ‰“å°æ±‡æ€»
        self.logger.info("ğŸ“‹ éªŒè¯æ±‡æ€»:")
        self.logger.info(f"   BMAæ¨¡å‹: {'âœ…' if report['bma']['validation_passed'] else 'âŒ'}")
        self.logger.info(f"   LSTMæ¨¡å‹: {'âœ…' if report['lstm']['validation_passed'] else 'âŒ'}")
        self.logger.info(f"   ç»¼åˆæ¨è: {'âœ…' if report['combined']['success'] else 'âŒ'}")
        
        if report['combined']['success']:
            top_symbols = [item['ticker'] for item in self.validation_stats['combined_top10'][:5]]
            self.logger.info(f"   Top5æ¨è: {top_symbols}")
        
        return report


class WeeklyScheduler:
    """æ¯å‘¨ä¸€è‡ªåŠ¨è¿è¡Œè°ƒåº¦å™¨"""
    
    def __init__(self, validator: ModelValidator):
        self.validator = validator
        self.logger = logging.getLogger(__name__)
        self.is_running = False
        self.scheduler_thread = None
    
    def setup_schedule(self):
        """è®¾ç½®æ¯å‘¨ä¸€è¿è¡Œçš„è°ƒåº¦"""
        # æ¯å‘¨ä¸€ä¸Šåˆ9ç‚¹è¿è¡Œ
        schedule.every().monday.at("09:00").do(self._run_weekly_validation)
        
        # ä¹Ÿå¯ä»¥æ¯å¤©æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰æ–°çš„æ¨¡å‹æ–‡ä»¶
        schedule.every().day.at("10:00").do(self._check_for_new_models)
        
        self.logger.info("ğŸ“… å·²è®¾ç½®æ¯å‘¨ä¸€è‡ªåŠ¨éªŒè¯è°ƒåº¦")
    
    def _run_weekly_validation(self):
        """æ¯å‘¨éªŒè¯ä»»åŠ¡"""
        self.logger.info("ğŸ“… æ‰§è¡Œæ¯å‘¨ä¸€æ¨¡å‹éªŒè¯...")
        try:
            report = self.validator.run_validation()
            
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é‚®ä»¶é€šçŸ¥ç­‰
            if report['combined']['success']:
                self.logger.info("âœ… æ¯å‘¨éªŒè¯æˆåŠŸå®Œæˆ")
            else:
                self.logger.warning("âš ï¸ æ¯å‘¨éªŒè¯å®Œæˆä½†å­˜åœ¨é—®é¢˜")
                
        except Exception as e:
            self.logger.error(f"âŒ æ¯å‘¨éªŒè¯å¤±è´¥: {e}")
    
    def _check_for_new_models(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ¨¡å‹æ–‡ä»¶"""
        try:
            bma_file, lstm_file = self.validator.find_latest_model_files()
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯ä»Šå¤©ç”Ÿæˆçš„
            today = datetime.now().date()
            
            new_files = []
            if bma_file and datetime.fromtimestamp(bma_file.stat().st_mtime).date() == today:
                new_files.append(f"BMA: {bma_file.name}")
            
            if lstm_file and datetime.fromtimestamp(lstm_file.stat().st_mtime).date() == today:
                new_files.append(f"LSTM: {lstm_file.name}")
            
            if new_files:
                self.logger.info(f"ğŸ†• å‘ç°æ–°æ¨¡å‹æ–‡ä»¶: {', '.join(new_files)}")
                # è‡ªåŠ¨è¿è¡ŒéªŒè¯
                self.validator.run_validation()
                
        except Exception as e:
            self.logger.error(f"âŒ æ£€æŸ¥æ–°æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
    
    def start_scheduler(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.is_running:
            return
        
        self.setup_schedule()
        self.is_running = True
        
        def run_scheduler():
            while self.is_running:
                schedule.run_pending()
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        
        self.scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        self.scheduler_thread.start()
        
        self.logger.info("ğŸš€ è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop_scheduler(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self.is_running = False
        schedule.clear()
        self.logger.info("ğŸ›‘ è°ƒåº¦å™¨å·²åœæ­¢")


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / f"model_validator_{datetime.now().strftime('%Y%m%d')}.log", encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )


def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ æ¨¡å‹éªŒè¯å™¨å¯åŠ¨")
    
    try:
        # åˆ›å»ºéªŒè¯å™¨
        validator = ModelValidator()
        
        # è¿è¡Œç«‹å³éªŒè¯
        logger.info("ğŸ“Š æ‰§è¡Œç«‹å³éªŒè¯...")
        report = validator.run_validation()
        
        # åˆ›å»ºè°ƒåº¦å™¨
        scheduler = WeeklyScheduler(validator)
        scheduler.start_scheduler()
        
        logger.info("âœ… æ¨¡å‹éªŒè¯å™¨è¿è¡Œä¸­...")
        logger.info("   - ç«‹å³éªŒè¯å·²å®Œæˆ")
        logger.info("   - æ¯å‘¨ä¸€09:00è‡ªåŠ¨éªŒè¯")
        logger.info("   - æ¯å¤©10:00æ£€æŸ¥æ–°æ¨¡å‹æ–‡ä»¶")
        
        # ä¿æŒè¿è¡Œ
        try:
            while True:
                time.sleep(10)
        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
            scheduler.stop_scheduler()
    
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)