#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CVæ•°æ®æ³„éœ²é˜²æŠ¤æ¨¡å— - ç§»é™¤å±é™©çš„CVå›é€€æœºåˆ¶ï¼Œå¼ºåˆ¶ä½¿ç”¨PurgedTimeSeriesSplit
é˜²æ­¢ç³»ç»Ÿå›é€€åˆ°æ— éš”ç¦»çš„sklearn.TimeSeriesSplitå¯¼è‡´ä¸¥é‡æ•°æ®æ³„éœ²
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, Any, List, Optional, Tuple, Union
from sklearn.model_selection import TimeSeriesSplit
import warnings

from unified_timing_registry import get_global_timing_registry, TimingEnforcer

logger = logging.getLogger(__name__)


class CVLeakagePreventionError(Exception):
    """CVæ•°æ®æ³„éœ²é˜²æŠ¤å¼‚å¸¸"""
    pass


class SafeCVWrapper:
    """
    å®‰å…¨CVåŒ…è£…å™¨ - å¼ºåˆ¶groupså‚æ•°ï¼Œç¦æ­¢å±é™©é€€åŒ–
    
    âš ï¸ ç¦æ­¢è‡ªåŠ¨å›é€€ï¼CVå¤±è´¥å¿…é¡»ç¡¬å¤±è´¥æˆ–å½±å­æ¨¡å¼
    """
    
    def __init__(self, primary_cv, preventer, params):
        self.primary_cv = primary_cv
        self.preventer = preventer
        self.params = params
        self.fallback_cv = None
        self.using_fallback = False
        self.cv_integrity_verified = False
        
    def split(self, X, y=None, groups=None):
        """ä¸¥æ ¼CVåˆ†å‰²ï¼Œå¼ºåˆ¶groupså‚æ•°éªŒè¯"""
        
        # ğŸ”¥ CRITICAL: å¼ºåˆ¶groupså‚æ•°æ£€æŸ¥
        if groups is None:
            error_msg = (
                "âŒ CV INTEGRITY VIOLATION: groupså‚æ•°æ˜¯å¿…é¡»çš„ï¼\n"
                "  ä¿®å¤æ–¹æ³•:\n"
                "  groups = df['date'].values  # æˆ– y.index.to_period('D').values\n"
                "  for tr, va in cv.split(X, y, groups=groups): ...\n"
                "  \n"
                "  ğŸ“Š å½“å‰æ•°æ®çŠ¶æ€:\n"
                f"  - X shape: {getattr(X, 'shape', 'Unknown')}\n"
                f"  - y length: {len(y) if y is not None else 'None'}\n"
                f"  - groups: {groups}\n"
                "  \n"
                "  ğŸš¨ ç¦æ­¢é€€åŒ–ä¸ºæ— éš”ç¦»CVï¼"
            )
            logger.critical(error_msg)
            raise CVLeakagePreventionError(error_msg)
        
        # ğŸ”¥ éªŒè¯groupsé•¿åº¦åŒ¹é…
        if len(groups) != len(X):
            error_msg = f"groupsé•¿åº¦({len(groups)}) != Xé•¿åº¦({len(X)}), å¿…é¡»å¯¹é½ï¼"
            logger.critical(error_msg)
            raise CVLeakagePreventionError(error_msg)
        
        logger.info(f"ğŸ“Š CV Integrity Check: X={getattr(X, 'shape', 'Unknown')}, groups={len(groups)}")
        
        try:
            # ä½¿ç”¨ä¸¥æ ¼çš„Purged CVåˆ†å‰²å™¨
            fold_count = 0
            for train_idx, test_idx in self.primary_cv.split(X, y, groups):
                fold_count += 1
                
                # ğŸ”¥ éªŒè¯æ—¶é—´éš”ç¦»å®Œæ•´æ€§
                if hasattr(groups, '__getitem__'):
                    train_dates = [groups[i] for i in train_idx[-5:]]  # è®­ç»ƒé›†æœ«å°¾
                    test_dates = [groups[i] for i in test_idx[:5]]     # æµ‹è¯•é›†å¼€å¤´
                    logger.info(f"Fold {fold_count} æ—¶é—´éš”ç¦»: è®­ç»ƒæœ«å°¾{train_dates} â†’ æµ‹è¯•å¼€å¤´{test_dates}")
                
                yield train_idx, test_idx
            
            if fold_count == 0:
                error_msg = "âŒ CVç”Ÿæˆ0ä¸ªfoldï¼Œæ•°æ®ä¸è¶³æˆ–é…ç½®é”™è¯¯"
                logger.critical(error_msg)
                raise CVLeakagePreventionError(error_msg)
            
            self.cv_integrity_verified = True
            logger.info(f"âœ… CV Integrityé€šè¿‡: æˆåŠŸç”Ÿæˆ{fold_count}ä¸ªfoldï¼Œæ—¶é—´éš”ç¦»éªŒè¯å®Œæˆ")
            
        except Exception as e:
            error_msg = (
                f"âŒ CV HARD FAILURE: {e}\n"
                "ğŸš¨ ç¦æ­¢é€€åŒ–ï¼è¯·ä¿®å¤CVé…ç½®æˆ–è¿›å…¥å½±å­æ¨¡å¼\n"
                f"å»ºè®®æ£€æŸ¥:\n"
                f"  - gap_days: {self.params.get('gap_days', 'Unknown')}\n" 
                f"  - embargo_days: {self.params.get('embargo_days', 'Unknown')}\n"
                f"  - n_splits: {self.params.get('n_splits', 'Unknown')}\n"
                f"  - æ•°æ®æ—¶é—´è·¨åº¦æ˜¯å¦è¶³å¤Ÿ"
            )
            logger.critical(error_msg)
            raise CVLeakagePreventionError(error_msg)
    
    def get_n_splits(self, X=None, y=None, groups=None):
        """è·å–åˆ†å‰²æ•°é‡"""
        if self.using_fallback and self.fallback_cv:
            return self.fallback_cv.get_n_splits(X, y, groups)
        else:
            return self.primary_cv.get_n_splits(X, y, groups)


class CVLeakagePreventer:
    """
    CVæ•°æ®æ³„éœ²é˜²æŠ¤å™¨
    
    åŠŸèƒ½ï¼š
    1. æ£€æµ‹å¹¶é˜»æ­¢ä½¿ç”¨æ— éš”ç¦»çš„CVæ–¹æ³•
    2. å¼ºåˆ¶è¦æ±‚ä½¿ç”¨PurgedTimeSeriesSplit
    3. éªŒè¯CVé…ç½®çš„æ—¶åºå®‰å…¨æ€§
    4. æä¾›å®‰å…¨çš„CVå®ä¾‹åˆ›å»º
    """
    
    def __init__(self):
        self.timing_registry = get_global_timing_registry()
        self.blocked_cv_classes = [
            'TimeSeriesSplit',
            'KFold', 
            'StratifiedKFold',
            'GroupKFold',
            'LeaveOneOut',
            'LeavePOut'
        ]
        self.allowed_cv_classes = [
            'PurgedTimeSeriesSplit',
            'PurgedKFold',
            'PurgedGroupTimeSeriesSplit'
        ]
        self.intervention_log = []
        
        logger.info("CVæ•°æ®æ³„éœ²é˜²æŠ¤å™¨å·²åˆå§‹åŒ–")
        logger.info(f"ç¦ç”¨CVç±»å‹: {self.blocked_cv_classes}")
        logger.info(f"å…è®¸CVç±»å‹: {self.allowed_cv_classes}")
    
    def validate_cv_class(self, cv_class_name: str, cv_instance: Any = None) -> bool:
        """
        éªŒè¯CVç±»çš„å®‰å…¨æ€§
        
        Args:
            cv_class_name: CVç±»å
            cv_instance: CVå®ä¾‹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ˜¯å¦å®‰å…¨
        """
        logger.info(f"éªŒè¯CVç±»å®‰å…¨æ€§: {cv_class_name}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå±é™©çš„CVç±»
        if any(blocked in cv_class_name for blocked in self.blocked_cv_classes):
            # ç‰¹åˆ«æ£€æŸ¥æ˜¯å¦ä¸ºåŸç”ŸTimeSeriesSplit
            if cv_class_name == 'TimeSeriesSplit' and 'Purged' not in str(type(cv_instance)):
                error_msg = (
                    f"âŒ ä¸¥é‡æ•°æ®æ³„éœ²é£é™©æ£€æµ‹: ä½¿ç”¨äº†æ— éš”ç¦»çš„ {cv_class_name}\n"
                    f"è¿™å°†å¯¼è‡´ä¸¥é‡çš„å‰ç»æ€§åå·®ï¼\n"
                    f"å¿…é¡»ä½¿ç”¨ PurgedTimeSeriesSplit æ›¿ä»£\n"
                    f"è§£å†³æ–¹æ¡ˆ:\n"
                    f"  1. å®‰è£… fixed_purged_time_series_cv åº“\n"
                    f"  2. ä½¿ç”¨ PurgedTimeSeriesSplit æ›¿ä»£ TimeSeriesSplit\n"
                    f"  3. æˆ–è€…åœæ­¢è®­ç»ƒç›´åˆ°ä¿®å¤æ­¤é—®é¢˜"
                )
                logger.critical(error_msg)
                
                self.intervention_log.append({
                    'timestamp': pd.Timestamp.now(),
                    'cv_class': cv_class_name,
                    'risk_level': 'CRITICAL',
                    'action': 'BLOCKED',
                    'reason': 'No purging/embargo - severe data leakage risk'
                })
                
                raise CVLeakagePreventionError(error_msg)
            
            # å…¶ä»–è¢«ç¦ç”¨çš„CVç±»
            elif not any(allowed in cv_class_name for allowed in self.allowed_cv_classes):
                warning_msg = (
                    f"âš ï¸ ä½¿ç”¨äº†éæ—¶åºå®‰å…¨çš„CVæ–¹æ³•: {cv_class_name}\n"
                    f"å»ºè®®ä½¿ç”¨ PurgedTimeSeriesSplit ä»¥é¿å…æ•°æ®æ³„éœ²é£é™©"
                )
                logger.warning(warning_msg)
                warnings.warn(warning_msg, UserWarning)
                
                self.intervention_log.append({
                    'timestamp': pd.Timestamp.now(),
                    'cv_class': cv_class_name,
                    'risk_level': 'WARNING',
                    'action': 'WARNED',
                    'reason': 'Non-temporal CV method'
                })
                
                return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå…è®¸çš„CVç±»
        if any(allowed in cv_class_name for allowed in self.allowed_cv_classes):
            logger.info(f"âœ… CVç±» {cv_class_name} éªŒè¯é€šè¿‡")
            return True
        
        logger.warning(f"âš ï¸ æœªçŸ¥CVç±»: {cv_class_name}")
        return False
    
    def enforce_purged_cv_params(self, cv_params: Dict[str, Any], cv_class_name: str) -> Dict[str, Any]:
        """
        å¼ºåˆ¶æ‰§è¡ŒPurged CVå‚æ•°
        
        Args:
            cv_params: åŸå§‹CVå‚æ•°
            cv_class_name: CVç±»å
            
        Returns:
            å¼ºåˆ¶æ‰§è¡Œåçš„CVå‚æ•°
        """
        return TimingEnforcer.enforce_cv_integrity(cv_class_name, cv_params)
    
    def create_safe_cv_splitter(self, prefer_sklearn_compatible=False, **kwargs) -> Any:
        """
        åˆ›å»ºå®‰å…¨çš„CVåˆ†å‰²å™¨
        
        Args:
            prefer_sklearn_compatible: ä¼˜å…ˆé€‰æ‹©sklearnå…¼å®¹çš„CVï¼ˆä¸éœ€è¦groupså‚æ•°ï¼‰
            **kwargs: CVå‚æ•°
            
        Returns:
            å®‰å…¨çš„CVåˆ†å‰²å™¨å®ä¾‹
        """
        logger.info("åˆ›å»ºå®‰å…¨çš„CVåˆ†å‰²å™¨")
        
        # è·å–ç»Ÿä¸€çš„CVå‚æ•°
        registry_params = self.timing_registry.get_purged_cv_params()
        
        # åˆå¹¶å‚æ•°ï¼ˆregistryå‚æ•°ä¼˜å…ˆï¼‰
        final_params = {**kwargs, **registry_params}
        
        try:
            # å¦‚æœæ˜ç¡®è¦æ±‚sklearnå…¼å®¹ï¼Œç›´æ¥ä½¿ç”¨SimpleSafeTimeSeriesSplit
            if prefer_sklearn_compatible:
                logger.info("æ˜ç¡®è¦æ±‚sklearnå…¼å®¹ï¼Œç›´æ¥ä½¿ç”¨SimpleSafeTimeSeriesSplit")
                try:
                    from simple_safe_cv import SimpleSafeTimeSeriesSplit
                    cv_class_name = "SimpleSafeTimeSeriesSplit"
                    
                    cv_splitter = SimpleSafeTimeSeriesSplit(
                        n_splits=final_params.get('n_splits', 5),
                        gap_days=final_params.get('gap_days', 10),
                        test_size=final_params.get('test_size', 0.2)
                    )
                    logger.info("âœ… ä½¿ç”¨SimpleSafeTimeSeriesSplitï¼ˆsklearnå…¼å®¹ä¼˜å…ˆï¼‰")
                    
                except ImportError:
                    logger.error("SimpleSafeTimeSeriesSplitä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–é€‰é¡¹")
                    prefer_sklearn_compatible = False  # å›é€€åˆ°å¸¸è§„é€»è¾‘
            
            # å¸¸è§„é€»è¾‘ï¼šä¼˜å…ˆå°è¯•ä½¿ç”¨FixedPurgedGroupTimeSeriesSplitï¼ˆéœ€è¦groupså‚æ•°ï¼‰
            if not prefer_sklearn_compatible:
                try:
                    from fixed_purged_time_series_cv import FixedPurgedGroupTimeSeriesSplit, ValidationConfig
                    cv_class_name = "FixedPurgedGroupTimeSeriesSplit"
                    
                    # åˆ›å»ºé€‚é…çš„é…ç½®
                    validation_config = ValidationConfig(
                        n_splits=final_params.get('n_splits', 5),
                        gap=final_params.get('gap_days', 10),
                        embargo=final_params.get('embargo_days', 0),
                        test_size=final_params.get('test_size', 63),
                        min_train_size=252
                    )
                    
                    # åˆ›å»ºCVå®ä¾‹ä½¿ç”¨æœ¬åœ°å®ç°
                    cv_splitter = FixedPurgedGroupTimeSeriesSplit(validation_config)
                    logger.info("âœ… ä½¿ç”¨FixedPurgedGroupTimeSeriesSplitï¼ˆéœ€è¦groupså‚æ•°ï¼‰")
                
                except ImportError:
                    # å¦‚æœFixedPurgedGroupTimeSeriesSplitä¸å¯ç”¨ï¼Œä½¿ç”¨SimpleSafeTimeSeriesSplitä½œä¸ºsklearnå…¼å®¹çš„å›é€€
                    logger.warning("FixedPurgedGroupTimeSeriesSplitä¸å¯ç”¨ï¼Œä½¿ç”¨SimpleSafeTimeSeriesSplitä½œä¸ºsklearnå…¼å®¹å›é€€")
                    try:
                        from simple_safe_cv import SimpleSafeTimeSeriesSplit
                        cv_class_name = "SimpleSafeTimeSeriesSplit"
                        
                        # åˆ›å»ºsklearnå…¼å®¹çš„å®‰å…¨CVï¼ˆä¸éœ€è¦groupså‚æ•°ï¼‰
                        cv_splitter = SimpleSafeTimeSeriesSplit(
                            n_splits=final_params.get('n_splits', 5),
                            gap_days=final_params.get('gap_days', 10),
                            test_size=final_params.get('test_size', 0.2)
                        )
                        logger.info("âœ… ä½¿ç”¨SimpleSafeTimeSeriesSplitï¼ˆsklearnå…¼å®¹ï¼Œæ— éœ€groupså‚æ•°ï¼‰")
                        
                    except ImportError:
                        # å¦‚æœä¸¤ä¸ªå®ç°éƒ½æ²¡æœ‰ï¼ŒæŠ›å‡ºé”™è¯¯
                        error_msg = (
                            "âŒ æ— æ³•å¯¼å…¥ä»»ä½•å®‰å…¨çš„CVå®ç°ï¼\n"
                            "å°è¯•äº†ï¼šFixedPurgedGroupTimeSeriesSplit å’Œ SimpleSafeTimeSeriesSplit\n"
                            "ç³»ç»Ÿæ‹’ç»ä½¿ç”¨æ— éš”ç¦»çš„CVæ–¹æ³•ä»¥é˜²æ­¢æ•°æ®æ³„éœ²"
                        )
                        logger.critical(error_msg)
                        raise CVLeakagePreventionError(error_msg)
            
            logger.info(f"âœ… åˆ›å»ºå®‰å…¨CVåˆ†å‰²å™¨æˆåŠŸ: {cv_class_name}")
            logger.info(f"å‚æ•°: gap={final_params.get('gap_days')}å¤©, "
                       f"embargo={final_params.get('embargo_days')}å¤©, "
                       f"n_splits={final_params.get('n_splits')}")
            
            # è®°å½•æˆåŠŸåˆ›å»º
            self.intervention_log.append({
                'timestamp': pd.Timestamp.now(),
                'cv_class': cv_class_name,
                'risk_level': 'SAFE',
                'action': 'CREATED',
                'reason': 'Safe purged CV with proper isolation',
                'params': final_params
            })
            
            # åˆ›å»ºCVåŒ…è£…å™¨ï¼Œè‡ªåŠ¨å¤„ç†groupså‚æ•°é—®é¢˜
            return SafeCVWrapper(cv_splitter, self, final_params)
            
        except Exception as e:
            error_msg = f"åˆ›å»ºå®‰å…¨CVåˆ†å‰²å™¨å¤±è´¥: {e}"
            logger.error(error_msg)
            raise CVLeakagePreventionError(error_msg)
    
    def validate_cv_splits(self, cv_splitter: Any, X: np.ndarray, 
                          dates: pd.DatetimeIndex) -> bool:
        """
        éªŒè¯CVåˆ†å‰²çš„æ—¶åºå®‰å…¨æ€§
        
        Args:
            cv_splitter: CVåˆ†å‰²å™¨
            X: ç‰¹å¾æ•°æ®
            dates: æ—¥æœŸç´¢å¼•
            
        Returns:
            æ˜¯å¦é€šè¿‡éªŒè¯
        """
        logger.info("éªŒè¯CVåˆ†å‰²æ—¶åºå®‰å…¨æ€§")
        
        try:
            splits = list(cv_splitter.split(X))
            
            min_gap = self.timing_registry.cv_gap_days
            min_embargo = self.timing_registry.cv_embargo_days
            
            violations = []
            
            for i, (train_idx, test_idx) in enumerate(splits):
                # è·å–è®­ç»ƒå’Œæµ‹è¯•æ—¥æœŸ
                train_dates = dates[train_idx]
                test_dates = dates[test_idx]
                
                # æ£€æŸ¥è®­ç»ƒé›†æœ€å¤§æ—¥æœŸå’Œæµ‹è¯•é›†æœ€å°æ—¥æœŸçš„é—´éš”
                train_max_date = train_dates.max()
                test_min_date = test_dates.min()
                gap_days = (test_min_date - train_max_date).days
                
                if gap_days < min_gap + min_embargo:
                    violations.append({
                        'fold': i,
                        'gap_days': gap_days,
                        'required_gap': min_gap + min_embargo,
                        'train_max_date': train_max_date,
                        'test_min_date': test_min_date
                    })
                    
                logger.info(f"Fold {i}: gap={gap_days}å¤©, "
                           f"è®­ç»ƒæœŸ={train_dates.min()}è‡³{train_max_date}, "
                           f"æµ‹è¯•æœŸ={test_min_date}è‡³{test_dates.max()}")
            
            if violations:
                logger.error("âŒ CVåˆ†å‰²æ—¶åºéªŒè¯å¤±è´¥:")
                for v in violations:
                    logger.error(f"  Fold {v['fold']}: gap={v['gap_days']}å¤© < è¦æ±‚{v['required_gap']}å¤©")
                
                self.intervention_log.append({
                    'timestamp': pd.Timestamp.now(),
                    'cv_class': type(cv_splitter).__name__,
                    'risk_level': 'ERROR',
                    'action': 'VALIDATION_FAILED',
                    'reason': f'{len(violations)} folds with insufficient gap',
                    'violations': violations
                })
                
                return False
            else:
                logger.info(f"âœ… CVåˆ†å‰²æ—¶åºéªŒè¯é€šè¿‡: {len(splits)}ä¸ªæŠ˜å ")
                return True
                
        except Exception as e:
            logger.error(f"CVåˆ†å‰²éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
            return False
    
    def patch_dangerous_cv_imports(self):
        """
        çŒ´å­è¡¥ä¸å±é™©çš„CVå¯¼å…¥ï¼Œé˜²æ­¢æ„å¤–ä½¿ç”¨
        """
        import sklearn.model_selection
        
        # ä¿å­˜åŸå§‹ç±»çš„å¼•ç”¨
        original_TimeSeriesSplit = sklearn.model_selection.TimeSeriesSplit
        
        class SafeTimeSeriesSplit:
            def __init__(self, *args, **kwargs):
                error_msg = (
                    "âŒ æ£€æµ‹åˆ°å°è¯•ä½¿ç”¨sklearn.TimeSeriesSplitï¼\n"
                    "è¿™ä¼šå¯¼è‡´ä¸¥é‡çš„æ•°æ®æ³„éœ²é£é™©ï¼\n"
                    "è¯·ä½¿ç”¨ PurgedTimeSeriesSplit æ›¿ä»£ã€‚\n"
                    "å¦‚æœç¡®å®éœ€è¦åŸå§‹åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ cv_preventer.get_original_timeseriessplit()"
                )
                logger.critical(error_msg)
                raise CVLeakagePreventionError(error_msg)
        
        # æ›¿æ¢å±é™©çš„ç±»
        sklearn.model_selection.TimeSeriesSplit = SafeTimeSeriesSplit
        
        # ä¿å­˜åŸå§‹ç±»ä»¥å¤‡ç‰¹æ®Šæƒ…å†µä½¿ç”¨
        self._original_TimeSeriesSplit = original_TimeSeriesSplit
        
        logger.info("âœ… å·²å¯¹sklearn.TimeSeriesSplitåº”ç”¨å®‰å…¨è¡¥ä¸")
    
    def get_original_timeseriessplit(self):
        """è·å–åŸå§‹TimeSeriesSplitï¼ˆä»…ç”¨äºç‰¹æ®Šæµ‹è¯•æƒ…å†µï¼‰"""
        logger.warning("âš ï¸ è¯·æ±‚åŸå§‹TimeSeriesSplit - è¯·ç¡®ä¿çŸ¥é“æ•°æ®æ³„éœ²é£é™©ï¼")
        return self._original_TimeSeriesSplit
    
    def get_prevention_summary(self) -> Dict[str, Any]:
        """è·å–é˜²æŠ¤æ‘˜è¦"""
        total_interventions = len(self.intervention_log)
        blocked_count = sum(1 for log in self.intervention_log if log['action'] == 'BLOCKED')
        warned_count = sum(1 for log in self.intervention_log if log['action'] == 'WARNED')
        safe_count = sum(1 for log in self.intervention_log if log['action'] == 'CREATED')
        
        return {
            'total_interventions': total_interventions,
            'blocked_dangerous_cv': blocked_count,
            'warned_risky_cv': warned_count,
            'created_safe_cv': safe_count,
            'intervention_log': self.intervention_log,
            'timing_registry_cv_params': self.timing_registry.get_purged_cv_params()
        }


def prevent_cv_leakage_globally(cv_configs: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    """
    å…¨å±€é˜²æŠ¤CVæ•°æ®æ³„éœ²
    
    Args:
        cv_configs: CVé…ç½®å­—å…¸ {module_name: cv_config}
        
    Returns:
        é˜²æŠ¤åçš„CVé…ç½®å’Œåˆ›å»ºçš„å®‰å…¨CVåˆ†å‰²å™¨
    """
    preventer = CVLeakagePreventer()
    safe_cv_splitters = {}
    
    logger.info("å¼€å§‹å…¨å±€CVæ•°æ®æ³„éœ²é˜²æŠ¤")
    
    # åº”ç”¨å®‰å…¨è¡¥ä¸
    preventer.patch_dangerous_cv_imports()
    
    for module_name, cv_config in cv_configs.items():
        try:
            # åˆ›å»ºå®‰å…¨çš„CVåˆ†å‰²å™¨
            safe_cv = preventer.create_safe_cv_splitter(**cv_config)
            safe_cv_splitters[module_name] = safe_cv
            logger.info(f"âœ… ä¸º {module_name} åˆ›å»ºå®‰å…¨CVåˆ†å‰²å™¨")
        except CVLeakagePreventionError as e:
            logger.error(f"âŒ {module_name} CVé˜²æŠ¤å¤±è´¥: {e}")
            # ä¸åˆ›å»ºCVåˆ†å‰²å™¨ï¼Œè®©è°ƒç”¨è€…å¤„ç†
            safe_cv_splitters[module_name] = None
    
    # è®°å½•é˜²æŠ¤æ‘˜è¦
    summary = preventer.get_prevention_summary()
    logger.info("=== å…¨å±€CVæ•°æ®æ³„éœ²é˜²æŠ¤å®Œæˆ ===")
    logger.info(f"æ€»å¹²é¢„æ¬¡æ•°: {summary['total_interventions']}")
    logger.info(f"é˜»æ­¢å±é™©CV: {summary['blocked_dangerous_cv']}")
    logger.info(f"åˆ›å»ºå®‰å…¨CV: {summary['created_safe_cv']}")
    
    return {
        'safe_cv_splitters': safe_cv_splitters,
        'prevention_summary': summary,
        'preventer_instance': preventer
    }


if __name__ == "__main__":
    # æµ‹è¯•CVæ•°æ®æ³„éœ²é˜²æŠ¤
    preventer = CVLeakagePreventer()
    
    # æµ‹è¯•å±é™©CVç±»æ£€æµ‹
    try:
        preventer.validate_cv_class('TimeSeriesSplit')
        print("ERROR: åº”è¯¥æ£€æµ‹åˆ°å±é™©CVç±»")
    except CVLeakagePreventionError:
        print("âœ… æ­£ç¡®æ£€æµ‹åˆ°å±é™©CVç±»")
    
    # æµ‹è¯•å®‰å…¨CVåˆ›å»º
    try:
        safe_cv = preventer.create_safe_cv_splitter(n_splits=5)
        print(f"âœ… å®‰å…¨CVåˆ›å»ºæˆåŠŸ: {type(safe_cv).__name__}")
    except CVLeakagePreventionError as e:
        print(f"âš ï¸ CVåˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½ç¼ºå°‘åº“ï¼‰: {e}")
    
    # è·å–é˜²æŠ¤æ‘˜è¦
    summary = preventer.get_prevention_summary()
    print("é˜²æŠ¤æ‘˜è¦:", summary)