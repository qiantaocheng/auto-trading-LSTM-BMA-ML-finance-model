#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒ/é¢„æµ‹æ¨¡å¼åˆ†ç¦»ä¿®å¤è¡¥ä¸

ä¿®å¤ç›®æ ‡ï¼š
1. è®­ç»ƒæ¨¡å¼ï¼šéœ€è¦targetï¼Œä¼šdropnaï¼Œè®­ç»ƒåˆ°10-05
2. é¢„æµ‹æ¨¡å¼ï¼šä¸éœ€è¦targetï¼Œä¸dropnaï¼Œç”¨10-10çš„ç‰¹å¾é¢„æµ‹10-15

ä½¿ç”¨æ–¹æ³•ï¼š
åœ¨ä¸»æ¨¡å‹ä¸­æ·»åŠ modeå‚æ•°ï¼Œæ ¹æ®modeè°ƒç”¨ä¸åŒçš„æ•°æ®å‡†å¤‡é€»è¾‘
"""

import pandas as pd
import numpy as np
from datetime import timedelta
import logging

logger = logging.getLogger(__name__)


def prepare_data_with_mode(
    feature_data: pd.DataFrame,
    mode: str = 'train',
    horizon: int = 5
) -> pd.DataFrame:
    """
    æ ¹æ®æ¨¡å¼å‡†å¤‡æ•°æ®

    Args:
        feature_data: åŒ…å«ç‰¹å¾å’ŒCloseä»·æ ¼çš„DataFrame
        mode: 'train' æˆ– 'predict'
        horizon: é¢„æµ‹çª—å£ï¼ˆå¤©æ•°ï¼‰

    Returns:
        å¤„ç†åçš„DataFrame
    """
    logger.info(f"=" * 80)
    logger.info(f"ğŸ”„ æ•°æ®å‡†å¤‡æ¨¡å¼: {mode.upper()}")
    logger.info(f"=" * 80)

    if mode == 'train':
        logger.info("ğŸ“š è®­ç»ƒæ¨¡å¼: è®¡ç®—targetå¹¶åˆ é™¤æ— targetæ ·æœ¬")

        # è®­ç»ƒæ¨¡å¼ï¼šéœ€è¦è®¡ç®—target
        if 'Close' not in feature_data.columns:
            raise ValueError("è®­ç»ƒæ¨¡å¼éœ€è¦Closeä»·æ ¼åˆ—æ¥è®¡ç®—target")

        # è®¡ç®—target
        logger.info(f"   è®¡ç®—T+{horizon}çš„forward returns...")
        if isinstance(feature_data.index, pd.MultiIndex):
            # MultiIndex format
            target_series = (
                feature_data.groupby(level='ticker')['Close']
                .pct_change(horizon)
                .shift(-horizon)
            )
        else:
            # å¦‚æœæœ‰tickeråˆ—
            if 'ticker' in feature_data.columns:
                target_series = (
                    feature_data.groupby('ticker')['Close']
                    .pct_change(horizon)
                    .shift(-horizon)
                )
            else:
                # å•ä¸ªticker
                target_series = (
                    feature_data['Close']
                    .pct_change(horizon)
                    .shift(-horizon)
                )

        feature_data['target'] = target_series

        # ç»Ÿè®¡targetè´¨é‡
        total_samples = len(feature_data)
        valid_targets = target_series.notna().sum()
        valid_ratio = valid_targets / total_samples

        logger.info(f"   Targetç»Ÿè®¡:")
        logger.info(f"     æ€»æ ·æœ¬æ•°: {total_samples}")
        logger.info(f"     æœ‰æ•ˆtarget: {valid_targets}")
        logger.info(f"     æœ‰æ•ˆç‡: {valid_ratio:.1%}")

        # Dropnaåˆ é™¤æ²¡æœ‰targetçš„æ ·æœ¬
        samples_before = len(feature_data)
        feature_data = feature_data.dropna(subset=['target'])
        samples_after = len(feature_data)
        samples_removed = samples_before - samples_after

        logger.info(f"   Dropnaç»“æœ:")
        logger.info(f"     åˆ é™¤å‰: {samples_before} æ ·æœ¬")
        logger.info(f"     åˆ é™¤å: {samples_after} æ ·æœ¬")
        logger.info(f"     ç§»é™¤: {samples_removed} æ ·æœ¬ ({samples_removed/samples_before*100:.1f}%)")

        # è·å–è®­ç»ƒæ•°æ®çš„æ—¥æœŸèŒƒå›´
        if isinstance(feature_data.index, pd.MultiIndex) and 'date' in feature_data.index.names:
            min_date = feature_data.index.get_level_values('date').min()
            max_date = feature_data.index.get_level_values('date').max()
            logger.info(f"   è®­ç»ƒæ•°æ®æ—¥æœŸèŒƒå›´: {min_date} åˆ° {max_date}")
        elif 'date' in feature_data.columns:
            min_date = feature_data['date'].min()
            max_date = feature_data['date'].max()
            logger.info(f"   è®­ç»ƒæ•°æ®æ—¥æœŸèŒƒå›´: {min_date} åˆ° {max_date}")

    else:  # mode == 'predict'
        logger.info("ğŸ”® é¢„æµ‹æ¨¡å¼: ä¸è®¡ç®—targetï¼Œä¿ç•™æ‰€æœ‰æ ·æœ¬")

        # é¢„æµ‹æ¨¡å¼ï¼šä¸éœ€è¦target
        logger.info("   è·³è¿‡targetè®¡ç®—")
        logger.info("   è·³è¿‡dropnaæ“ä½œ")
        logger.info(f"   ä¿ç•™æ‰€æœ‰ {len(feature_data)} ä¸ªæ ·æœ¬ç”¨äºé¢„æµ‹")

        # æ·»åŠ ç©ºçš„targetåˆ—ï¼ˆå¦‚æœä¸‹æ¸¸éœ€è¦ï¼‰
        feature_data['target'] = np.nan

        # è·å–é¢„æµ‹æ•°æ®çš„æ—¥æœŸèŒƒå›´
        if isinstance(feature_data.index, pd.MultiIndex) and 'date' in feature_data.index.names:
            min_date = feature_data.index.get_level_values('date').min()
            max_date = feature_data.index.get_level_values('date').max()
            logger.info(f"   é¢„æµ‹æ•°æ®æ—¥æœŸèŒƒå›´: {min_date} åˆ° {max_date}")
            logger.info(f"   é¢„æµ‹ç›®æ ‡æ—¥æœŸ: {max_date + timedelta(days=horizon)}")
        elif 'date' in feature_data.columns:
            min_date = feature_data['date'].min()
            max_date = feature_data['date'].max()
            logger.info(f"   é¢„æµ‹æ•°æ®æ—¥æœŸèŒƒå›´: {min_date} åˆ° {max_date}")
            logger.info(f"   é¢„æµ‹ç›®æ ‡æ—¥æœŸ: {max_date + timedelta(days=horizon)}")

    logger.info(f"=" * 80)
    return feature_data


def get_end_date_for_mode(
    end_date: str,
    mode: str = 'train',
    horizon: int = 5
) -> str:
    """
    æ ¹æ®æ¨¡å¼è°ƒæ•´end_date

    Args:
        end_date: è¾“å…¥çš„ç»“æŸæ—¥æœŸ
        mode: 'train' æˆ– 'predict'
        horizon: é¢„æµ‹çª—å£ï¼ˆå¤©æ•°ï¼‰

    Returns:
        è°ƒæ•´åçš„end_dateå­—ç¬¦ä¸²
    """
    end_dt = pd.to_datetime(end_date)

    if mode == 'train':
        # è®­ç»ƒæ¨¡å¼ï¼šå°è¯•å»¶é•¿è·å–æœªæ¥æ•°æ®ä»¥è®¡ç®—target
        try:
            from pandas.tseries.offsets import BDay
            extended_end = (end_dt + BDay(horizon)).strftime('%Y-%m-%d')
        except:
            extended_end = (end_dt + timedelta(days=horizon + 2)).strftime('%Y-%m-%d')

        logger.info(f"ğŸ“š è®­ç»ƒæ¨¡å¼: å»¶é•¿end_dateä» {end_date} åˆ° {extended_end} (ç”¨äºè®¡ç®—T+{horizon}target)")
        return extended_end

    else:  # mode == 'predict'
        # é¢„æµ‹æ¨¡å¼ï¼šä¸éœ€è¦å»¶é•¿ï¼Œç›´æ¥ç”¨è¾“å…¥æ—¥æœŸ
        logger.info(f"ğŸ”® é¢„æµ‹æ¨¡å¼: ä½¿ç”¨åŸå§‹end_date {end_date} (ä¸éœ€è¦æœªæ¥æ•°æ®)")
        return end_date


def validate_mode_parameter(mode: str) -> str:
    """éªŒè¯å¹¶æ ‡å‡†åŒ–modeå‚æ•°"""
    if mode is None:
        mode = 'train'  # é»˜è®¤è®­ç»ƒæ¨¡å¼

    mode = str(mode).lower().strip()

    if mode not in ['train', 'predict', 'inference']:
        raise ValueError(
            f"æ— æ•ˆçš„modeå‚æ•°: {mode}\n"
            f"æ”¯æŒçš„å€¼: 'train', 'predict', 'inference'\n"
            f"  - 'train': è®­ç»ƒæ¨¡å¼ï¼Œè®¡ç®—targetå¹¶dropna\n"
            f"  - 'predict' æˆ– 'inference': é¢„æµ‹æ¨¡å¼ï¼Œä¸è®¡ç®—targetä¹Ÿä¸dropna"
        )

    # ç»Ÿä¸€ 'inference' å’Œ 'predict'
    if mode == 'inference':
        mode = 'predict'

    return mode


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2025-10-01', '2025-10-10', freq='D')
    tickers = ['AAPL', 'MSFT']

    data = []
    for ticker in tickers:
        for date in dates:
            data.append({
                'date': date,
                'ticker': ticker,
                'Close': 100 + np.random.randn(),
                'feature1': np.random.randn(),
                'feature2': np.random.randn(),
            })

    df = pd.DataFrame(data)
    df = df.set_index(['date', 'ticker'])

    print("\n" + "=" * 80)
    print("æµ‹è¯•1: è®­ç»ƒæ¨¡å¼")
    print("=" * 80)
    train_df = prepare_data_with_mode(df.copy(), mode='train', horizon=5)
    print(f"ç»“æœ: {len(train_df)} æ ·æœ¬, æœ‰target: {train_df['target'].notna().sum()}")

    print("\n" + "=" * 80)
    print("æµ‹è¯•2: é¢„æµ‹æ¨¡å¼")
    print("=" * 80)
    predict_df = prepare_data_with_mode(df.copy(), mode='predict', horizon=5)
    print(f"ç»“æœ: {len(predict_df)} æ ·æœ¬, æœ‰target: {predict_df['target'].notna().sum()}")

    print("\n" + "=" * 80)
    print("æµ‹è¯•3: end_dateè°ƒæ•´")
    print("=" * 80)
    train_end = get_end_date_for_mode('2025-10-10', mode='train', horizon=5)
    predict_end = get_end_date_for_mode('2025-10-10', mode='predict', horizon=5)
    print(f"è®­ç»ƒæ¨¡å¼end_date: {train_end}")
    print(f"é¢„æµ‹æ¨¡å¼end_date: {predict_end}")
