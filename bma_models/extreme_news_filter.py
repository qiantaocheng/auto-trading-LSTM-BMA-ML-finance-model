#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æç«¯æ–°é—»å› å­è¿‡æ»¤æ¨¡å— (Extreme News Filter with Purging Window)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è¯†åˆ«æç«¯æ–°é—»äº‹ä»¶ï¼ˆå•æ—¥æ¶¨è·Œå¹…>é˜ˆå€¼ æˆ– >3å€æ³¢åŠ¨ç‡ï¼‰
2. æ‰§è¡Œçª—å£å‡€åŒ–ï¼ˆPurgingï¼‰ï¼šå‰”é™¤æç«¯äº‹ä»¶å‰horizonå¤©çš„æ ·æœ¬
   åŸå› ï¼štargetæ˜¯ret_fwd_10dï¼Œå¦‚æœTæ—¥æœ‰æç«¯äº‹ä»¶ï¼ŒT-10åˆ°Tçš„targetéƒ½ä¼šå—å½±å“
3. è®­ç»ƒæ—¶è¿‡æ»¤ï¼Œé¢„æµ‹æ—¶æ ‡è®°ä½†ä¸è¿‡æ»¤
"""

import pandas as pd
import numpy as np
import logging
from typing import Optional, Tuple

logger = logging.getLogger(__name__)


class ExtremeNewsFilter:
    """
    æç«¯æ–°é—»å› å­è¿‡æ»¤å™¨ï¼ˆå¸¦çª—å£å‡€åŒ–ï¼‰
    
    è®¾è®¡ç†å¿µï¼š
    - è®­ç»ƒæ—¶ï¼šå‰”é™¤æç«¯äº‹ä»¶åŠå…¶å‰horizonå¤©çš„æ ·æœ¬ï¼ˆé˜²æ­¢targetæ±¡æŸ“ï¼‰
    - é¢„æµ‹æ—¶ï¼šæ ‡è®°æç«¯äº‹ä»¶ä½†ä¸å‰”é™¤ï¼ˆä¿ç•™æ‰€æœ‰é¢„æµ‹åœºæ™¯ï¼‰
    """
    
    def __init__(
        self,
        threshold: float = 0.10,
        volatility_multiplier: float = 3.0,
        volatility_window: int = 20,
        horizon: int = 10,
        enabled: bool = True,
    ):
        """
        åˆå§‹åŒ–æç«¯æ–°é—»è¿‡æ»¤å™¨
        
        Args:
            threshold: å›ºå®šé˜ˆå€¼ï¼ˆé»˜è®¤10%ï¼‰
            volatility_multiplier: æ³¢åŠ¨ç‡å€æ•°ï¼ˆé»˜è®¤3å€ï¼‰
            volatility_window: æ³¢åŠ¨ç‡è®¡ç®—çª—å£ï¼ˆé»˜è®¤20å¤©ï¼‰
            horizon: ç›®æ ‡é¢„æµ‹å‘¨æœŸï¼ˆé»˜è®¤10å¤©ï¼Œç”¨äºçª—å£å‡€åŒ–ï¼‰
            enabled: æ˜¯å¦å¯ç”¨è¿‡æ»¤ï¼ˆé»˜è®¤Trueï¼‰
        """
        self.threshold = threshold
        self.volatility_multiplier = volatility_multiplier
        self.volatility_window = volatility_window
        self.horizon = horizon
        self.enabled = enabled
        
        logger.info(f"âœ… ExtremeNewsFilter initialized:")
        logger.info(f"   threshold={threshold*100:.1f}%, volatility_multiplier={volatility_multiplier}x")
        logger.info(f"   volatility_window={volatility_window}d, horizon={horizon}d, enabled={enabled}")
    
    def _compute_daily_returns(self, df: pd.DataFrame, close_col: str = 'Close') -> pd.Series:
        """è®¡ç®—å•æ—¥æ”¶ç›Šç‡"""
        if close_col not in df.columns:
            raise ValueError(f"Column '{close_col}' not found in DataFrame")
        
        # æŒ‰tickeråˆ†ç»„è®¡ç®—æ”¶ç›Šç‡
        if isinstance(df.index, pd.MultiIndex) and 'ticker' in df.index.names:
            grouped = df.groupby(level='ticker')[close_col]
            daily_return = grouped.pct_change()
        elif 'ticker' in df.columns:
            grouped = df.groupby('ticker')[close_col]
            daily_return = grouped.pct_change()
        else:
            # å¦‚æœæ²¡æœ‰tickerä¿¡æ¯ï¼Œç›´æ¥è®¡ç®—ï¼ˆä¸æ¨èï¼‰
            daily_return = df[close_col].pct_change()
            logger.warning("âš ï¸ No ticker grouping found, computing returns without grouping")
        
        return daily_return
    
    def _compute_rolling_volatility(self, daily_return: pd.Series, ticker_grouped: bool = True) -> pd.Series:
        """è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡"""
        if ticker_grouped and isinstance(daily_return.index, pd.MultiIndex) and 'ticker' in daily_return.index.names:
            grouped = daily_return.groupby(level='ticker')
            rolling_std = grouped.transform(
                lambda s: s.rolling(self.volatility_window, min_periods=5).std()
            )
        elif ticker_grouped and hasattr(daily_return, 'groupby'):
            # å°è¯•æŒ‰tickeråˆ†ç»„
            try:
                grouped = daily_return.groupby(level='ticker')
                rolling_std = grouped.transform(
                    lambda s: s.rolling(self.volatility_window, min_periods=5).std()
                )
            except:
                rolling_std = daily_return.rolling(self.volatility_window, min_periods=5).std()
        else:
            # Fallback: ç›´æ¥è®¡ç®—ï¼ˆä¸æ¨èï¼‰
            rolling_std = daily_return.rolling(self.volatility_window, min_periods=5).std()
            logger.warning("âš ï¸ No ticker grouping found, computing volatility without grouping")
        
        return rolling_std.fillna(0.0)
    
    def _identify_extreme_events(
        self, 
        df: pd.DataFrame, 
        close_col: str = 'Close'
    ) -> pd.Series:
        """
        è¯†åˆ«æç«¯æ–°é—»äº‹ä»¶
        
        æ¡ä»¶ï¼šabs(daily_return) > threshold OR abs(daily_return) > volatility_multiplier * rolling_std
        
        Returns:
            is_extreme: Series of boolean values (Trueè¡¨ç¤ºæç«¯äº‹ä»¶)
        """
        # è®¡ç®—å•æ—¥æ”¶ç›Šç‡
        daily_return = self._compute_daily_returns(df, close_col)
        
        # è®¡ç®—æ»šåŠ¨æ³¢åŠ¨ç‡
        rolling_std = self._compute_rolling_volatility(daily_return)
        
        # å›ºå®šé˜ˆå€¼æ¡ä»¶
        threshold_condition = daily_return.abs() > self.threshold
        
        # æ³¢åŠ¨ç‡å€æ•°æ¡ä»¶
        volatility_condition = daily_return.abs() > (self.volatility_multiplier * rolling_std)
        
        # åˆå¹¶æ¡ä»¶ï¼ˆORï¼‰
        is_extreme = threshold_condition | volatility_condition
        
        # å¡«å……NaNä¸ºFalse
        is_extreme = is_extreme.fillna(False)
        
        return is_extreme
    
    def _apply_purging_window(
        self, 
        df: pd.DataFrame, 
        is_extreme: pd.Series
    ) -> pd.Series:
        """
        æ‰§è¡Œçª—å£å‡€åŒ–ï¼ˆPurging Windowï¼‰
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        - å¦‚æœTæ—¥æ˜¯æç«¯äº‹ä»¶ï¼Œé‚£ä¹ˆT-horizonåˆ°Tçš„æ‰€æœ‰æ ·æœ¬éƒ½åº”è¯¥è¢«å‰”é™¤
        - å› ä¸ºtargetæ˜¯ret_fwd_10dï¼ŒTæ—¥çš„æç«¯äº‹ä»¶ä¼šå½±å“T-horizonåˆ°Tçš„targetå€¼
        
        Args:
            df: åŸå§‹DataFrame
            is_extreme: æç«¯äº‹ä»¶æ ‡è®°Series
        
        Returns:
            is_polluted: Series of boolean values (Trueè¡¨ç¤ºè¢«æ±¡æŸ“çš„æ ·æœ¬ï¼Œåº”è¢«å‰”é™¤)
        """
        # ç¡®ä¿is_extremeä¸dfå¯¹é½
        if not is_extreme.index.equals(df.index):
            # å°è¯•é‡æ–°ç´¢å¼•å¯¹é½
            is_extreme = is_extreme.reindex(df.index, fill_value=False)
        
        # æŒ‰tickeråˆ†ç»„å¤„ç†
        is_polluted = pd.Series(False, index=df.index)
        
        if isinstance(df.index, pd.MultiIndex) and 'ticker' in df.index.names:
            # MultiIndexæƒ…å†µï¼šæŒ‰tickeråˆ†ç»„
            for ticker in df.index.get_level_values('ticker').unique():
                ticker_mask = df.index.get_level_values('ticker') == ticker
                ticker_extreme = is_extreme[ticker_mask]
                
                # å¯¹æ¯ä¸ªtickerï¼Œä½¿ç”¨rolling windowå‘åçœ‹horizon+1å¤©
                # å¦‚æœæœªæ¥horizonå¤©å†…æœ‰ä»»ä½•æç«¯äº‹ä»¶ï¼Œå½“å‰æ ·æœ¬è¢«æ±¡æŸ“
                ticker_polluted = (
                    ticker_extreme
                    .rolling(window=self.horizon + 1, min_periods=1)
                    .max()
                    .shift(-self.horizon)  # å‘åå¹³ç§»horizonå¤©
                    .fillna(False)
                )
                
                is_polluted[ticker_mask] = ticker_polluted.values
                
        elif 'ticker' in df.columns:
            # æ™®é€šDataFrameï¼Œæœ‰tickeråˆ—
            for ticker in df['ticker'].unique():
                ticker_mask = df['ticker'] == ticker
                ticker_extreme = is_extreme[ticker_mask]
                
                # å¯¹æ¯ä¸ªtickerï¼Œä½¿ç”¨rolling windowå‘åçœ‹horizon+1å¤©
                ticker_polluted = (
                    ticker_extreme
                    .rolling(window=self.horizon + 1, min_periods=1)
                    .max()
                    .shift(-self.horizon)
                    .fillna(False)
                )
                
                is_polluted[ticker_mask] = ticker_polluted.values
        else:
            # æ²¡æœ‰tickeråˆ†ç»„ï¼Œç›´æ¥å¤„ç†ï¼ˆä¸æ¨èï¼‰
            logger.warning("âš ï¸ No ticker grouping found, applying purging without grouping")
            is_polluted = (
                is_extreme
                .rolling(window=self.horizon + 1, min_periods=1)
                .max()
                .shift(-self.horizon)
                .fillna(False)
            )
        
        return is_polluted.fillna(False)
    
    def filter(
        self, 
        df: pd.DataFrame, 
        mode: str = 'train',
        close_col: str = 'Close'
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        æ‰§è¡Œæç«¯æ–°é—»è¿‡æ»¤
        
        Args:
            df: è¾“å…¥DataFrameï¼ˆåº”åŒ…å«Closeåˆ—å’ŒMultiIndexæˆ–tickeråˆ—ï¼‰
            mode: 'train' æˆ– 'predict'
            close_col: æ”¶ç›˜ä»·åˆ—åï¼ˆé»˜è®¤'Close'ï¼‰
        
        Returns:
            filtered_df: è¿‡æ»¤åçš„DataFrame
            is_extreme: æç«¯äº‹ä»¶æ ‡è®°Seriesï¼ˆç”¨äºåˆ†æï¼‰
        """
        if not self.enabled:
            logger.info("â­ï¸ ExtremeNewsFilter disabled, skipping filter")
            return df, pd.Series(False, index=df.index)
        
        mode = mode.lower()
        if mode not in ['train', 'predict']:
            raise ValueError(f"Invalid mode: {mode}. Must be 'train' or 'predict'")
        
        logger.info(f"ğŸ” Applying extreme news filter (mode={mode})...")
        
        # 1. è¯†åˆ«æç«¯äº‹ä»¶
        is_extreme = self._identify_extreme_events(df, close_col)
        extreme_count = is_extreme.sum()
        extreme_pct = extreme_count / len(df) * 100
        
        logger.info(f"   ğŸ“Š Extreme events identified: {extreme_count:,} ({extreme_pct:.2f}%)")
        
        # 2. æ‰§è¡Œçª—å£å‡€åŒ–ï¼ˆä»…åœ¨è®­ç»ƒæ¨¡å¼ï¼‰
        if mode == 'train':
            is_polluted = self._apply_purging_window(df, is_extreme)
            polluted_count = is_polluted.sum()
            polluted_pct = polluted_count / len(df) * 100
            
            logger.info(f"   ğŸ§¹ Purging window applied: {polluted_count:,} samples polluted ({polluted_pct:.2f}%)")
            
            # è¿‡æ»¤è¢«æ±¡æŸ“çš„æ ·æœ¬
            filtered_df = df[~is_polluted].copy()
            
            logger.info(f"   âœ… Filtered: {len(df):,} â†’ {len(filtered_df):,} samples ({len(df)-len(filtered_df):,} removed)")
        else:
            # é¢„æµ‹æ¨¡å¼ï¼šåªæ ‡è®°ï¼Œä¸è¿‡æ»¤
            filtered_df = df.copy()
            filtered_df['is_extreme_news'] = is_extreme
            logger.info(f"   âœ… Prediction mode: marked {extreme_count:,} extreme events (no filtering)")
        
        return filtered_df, is_extreme
    
    def get_filter_stats(self, df: pd.DataFrame, is_extreme: pd.Series) -> dict:
        """è·å–è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_samples': len(df),
            'extreme_events': int(is_extreme.sum()),
            'extreme_pct': float(is_extreme.sum() / len(df) * 100),
        }
        
        # è®¡ç®—æ­£è´Ÿæç«¯äº‹ä»¶
        daily_return = self._compute_daily_returns(df)
        stats['positive_extreme'] = int((daily_return > self.threshold).sum())
        stats['negative_extreme'] = int((daily_return < -self.threshold).sum())
        
        # å¦‚æœæœ‰targetåˆ—ï¼Œè®¡ç®—æç«¯äº‹ä»¶åçš„targetç»Ÿè®¡
        if 'target' in df.columns:
            extreme_targets = df[is_extreme]['target'].dropna()
            normal_targets = df[~is_extreme]['target'].dropna()
            
            stats['extreme_target_mean'] = float(extreme_targets.mean()) if len(extreme_targets) > 0 else np.nan
            stats['normal_target_mean'] = float(normal_targets.mean()) if len(normal_targets) > 0 else np.nan
            stats['target_diff'] = float(stats['extreme_target_mean'] - stats['normal_target_mean']) if not np.isnan(stats['extreme_target_mean']) else np.nan
        
        return stats
