#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€OOFé¢„æµ‹ç”Ÿæˆå™¨ - å•ä¸€çœŸç›¸æº
æ‰€æœ‰è®­ç»ƒå¤´å¿…é¡»é€šè¿‡æ­¤ç³»ç»Ÿç”ŸæˆOOFé¢„æµ‹ï¼Œç¡®ä¿ä¸€è‡´æ€§
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Callable, Tuple
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class UnifiedOOFGenerator:
    """
    ç»Ÿä¸€OOFé¢„æµ‹ç”Ÿæˆå™¨ - SSOT
    
    èŒè´£ï¼š
    1. æä¾›å”¯ä¸€çš„OOFé¢„æµ‹ç”Ÿæˆæ¥å£
    2. ç¡®ä¿æ‰€æœ‰è®­ç»ƒå¤´ä½¿ç”¨ç›¸åŒçš„CVç­–ç•¥
    3. ç»Ÿä¸€OOFé¢„æµ‹æ ¼å¼å’Œindexå¯¹é½
    4. é˜²æ­¢å„è®­ç»ƒå¤´ç‹¬ç«‹ç”Ÿæˆä¸ä¸€è‡´çš„OOF
    """
    
    def __init__(self, cv_factory: Callable):
        """
        åˆå§‹åŒ–ç»Ÿä¸€OOFç”Ÿæˆå™¨
        
        Args:
            cv_factory: ç»Ÿä¸€CVå·¥å‚å‡½æ•°
        """
        self.cv_factory = cv_factory
        self.generated_oof = {}  # ç¼“å­˜å·²ç”Ÿæˆçš„OOF
        self._validate_cv_factory()
        
        logger.info("âœ… ç»Ÿä¸€OOFç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _validate_cv_factory(self):
        """éªŒè¯CVå·¥å‚å¯ç”¨æ€§"""
        if not callable(self.cv_factory):
            raise ValueError("cv_factoryå¿…é¡»æ˜¯å¯è°ƒç”¨å¯¹è±¡")
        
        logger.debug("CVå·¥å‚éªŒè¯é€šè¿‡")
    
    def generate_oof_predictions(self, 
                                X: pd.DataFrame, 
                                y: pd.Series,
                                dates: pd.Series,
                                models: Dict[str, Any],
                                training_head_id: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»Ÿä¸€çš„OOFé¢„æµ‹
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            dates: æ—¥æœŸåºåˆ—
            models: è®­ç»ƒå¥½çš„æ¨¡å‹å­—å…¸
            training_head_id: è®­ç»ƒå¤´æ ‡è¯†
            
        Returns:
            ç»Ÿä¸€æ ¼å¼çš„OOFé¢„æµ‹ç»“æœ
        """
        logger.info(f"ğŸ¯ ç”Ÿæˆç»Ÿä¸€OOFé¢„æµ‹ - è®­ç»ƒå¤´: {training_head_id}")
        
        # éªŒè¯è¾“å…¥æ•°æ®ä¸€è‡´æ€§
        self._validate_input_consistency(X, y, dates)
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{training_head_id}_{len(X)}_{hash(tuple(X.columns))}"
        
        if cache_key in self.generated_oof:
            logger.info(f"ä½¿ç”¨ç¼“å­˜çš„OOFé¢„æµ‹: {cache_key}")
            return self.generated_oof[cache_key]
        
        # åˆ›å»ºç»Ÿä¸€CVåˆ†å‰²å™¨
        cv_splitter = self.cv_factory(dates)
        cv_splits = cv_splitter(X, y)
        
        logger.info(f"CVåˆ†å‰²: {len(cv_splits)}æŠ˜")
        
        # åˆå§‹åŒ–OOFé¢„æµ‹çŸ©é˜µ
        oof_results = {}
        
        for model_name, model in models.items():
            logger.info(f"ç”Ÿæˆ {model_name} çš„OOFé¢„æµ‹")
            
            # åˆ›å»ºOOFé¢„æµ‹å‘é‡
            oof_predictions = pd.Series(index=X.index, dtype=float, name=f"{model_name}_oof")
            oof_predictions.fillna(np.nan, inplace=True)
            
            # CVè®­ç»ƒå’Œé¢„æµ‹
            fold_scores = []
            
            for fold_idx, (train_idx, val_idx) in enumerate(cv_splits):
                try:
                    # è·å–è®­ç»ƒå’ŒéªŒè¯æ•°æ®
                    X_train = X.iloc[train_idx].fillna(0)
                    y_train = y.iloc[train_idx].fillna(0)
                    X_val = X.iloc[val_idx].fillna(0)
                    y_val = y.iloc[val_idx].fillna(0)
                    
                    # è®­ç»ƒæ¨¡å‹
                    model.fit(X_train, y_train)
                    
                    # ç”Ÿæˆé¢„æµ‹
                    val_pred = model.predict(X_val)
                    
                    # ä¿å­˜OOFé¢„æµ‹
                    oof_predictions.iloc[val_idx] = val_pred
                    
                    # è®¡ç®—foldå¾—åˆ†
                    from scipy.stats import spearmanr
                    fold_ic = spearmanr(y_val, val_pred)[0]
                    fold_scores.append(fold_ic)
                    
                    logger.debug(f"Fold {fold_idx+1}: IC={fold_ic:.4f}")
                    
                except Exception as e:
                    logger.warning(f"Fold {fold_idx+1} è®­ç»ƒå¤±è´¥: {e}")
                    continue
            
            # è®¡ç®—æ•´ä½“OOFæ€§èƒ½
            valid_mask = ~oof_predictions.isna()
            if valid_mask.sum() > 0:
                overall_ic = spearmanr(y[valid_mask], oof_predictions[valid_mask])[0]
                logger.info(f"{model_name} OOF IC: {overall_ic:.4f}")
            else:
                overall_ic = 0.0
                logger.warning(f"{model_name} æ²¡æœ‰æœ‰æ•ˆçš„OOFé¢„æµ‹")
            
            # ä¿å­˜ç»“æœ
            oof_results[model_name] = {
                'oof_predictions': oof_predictions,
                'oof_ic': overall_ic,
                'fold_scores': fold_scores,
                'coverage': valid_mask.sum() / len(oof_predictions)
            }
        
        # åˆ›å»ºç»Ÿä¸€ç»“æœæ ¼å¼
        unified_result = {
            'training_head_id': training_head_id,
            'oof_results': oof_results,
            'cv_info': {
                'n_splits': len(cv_splits),
                'total_samples': len(X),
                'unique_dates': dates.nunique()
            },
            'data_fingerprint': {
                'features': list(X.columns),
                'date_range': f"{dates.min()} to {dates.max()}",
                'generation_time': datetime.now().isoformat()
            }
        }
        
        # ç¼“å­˜ç»“æœ
        self.generated_oof[cache_key] = unified_result
        
        logger.info(f"âœ… ç»Ÿä¸€OOFé¢„æµ‹ç”Ÿæˆå®Œæˆ - {len(oof_results)}ä¸ªæ¨¡å‹")
        
        return unified_result
    
    def _validate_input_consistency(self, X: pd.DataFrame, y: pd.Series, dates: pd.Series):
        """éªŒè¯è¾“å…¥æ•°æ®ä¸€è‡´æ€§"""
        if len(X) != len(y) or len(X) != len(dates):
            raise ValueError(f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: X={len(X)}, y={len(y)}, dates={len(dates)}")
        
        if not X.index.equals(y.index):
            raise ValueError("Xå’Œyçš„indexä¸åŒ¹é…")
        
        logger.debug(f"è¾“å…¥æ•°æ®éªŒè¯é€šè¿‡: {len(X)}æ ·æœ¬, {len(X.columns)}ç‰¹å¾")
    
    def align_oof_predictions(self, oof_results_list: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        å¯¹é½å¤šä¸ªè®­ç»ƒå¤´çš„OOFé¢„æµ‹
        
        Args:
            oof_results_list: å¤šä¸ªè®­ç»ƒå¤´çš„OOFç»“æœåˆ—è¡¨
            
        Returns:
            å¯¹é½åçš„OOFé¢„æµ‹çŸ©é˜µ
        """
        logger.info(f"ğŸ”„ å¯¹é½ {len(oof_results_list)} ä¸ªè®­ç»ƒå¤´çš„OOFé¢„æµ‹")
        
        # æ”¶é›†æ‰€æœ‰OOFé¢„æµ‹
        all_oof_predictions = []
        
        for oof_result in oof_results_list:
            training_head = oof_result['training_head_id']
            oof_data = oof_result['oof_results']
            
            for model_name, model_result in oof_data.items():
                oof_pred = model_result['oof_predictions']
                oof_pred.name = f"{training_head}_{model_name}"
                all_oof_predictions.append(oof_pred)
        
        if not all_oof_predictions:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„OOFé¢„æµ‹å¯å¯¹é½")
            return pd.DataFrame()
        
        # åˆ›å»ºå¯¹é½çš„é¢„æµ‹çŸ©é˜µ
        aligned_matrix = pd.concat(all_oof_predictions, axis=1)
        
        # éªŒè¯å¯¹é½è´¨é‡
        coverage_stats = {}
        for col in aligned_matrix.columns:
            coverage = (~aligned_matrix[col].isna()).sum() / len(aligned_matrix)
            coverage_stats[col] = coverage
        
        logger.info(f"OOFå¯¹é½å®Œæˆ: {aligned_matrix.shape}, å¹³å‡è¦†ç›–ç‡: {np.mean(list(coverage_stats.values())):.2%}")
        
        return aligned_matrix
    
    def get_generation_report(self) -> Dict[str, Any]:
        """è·å–OOFç”ŸæˆæŠ¥å‘Š"""
        report = {
            'total_generated': len(self.generated_oof),
            'cache_keys': list(self.generated_oof.keys()),
            'generation_stats': {}
        }
        
        for cache_key, result in self.generated_oof.items():
            training_head = result['training_head_id']
            model_count = len(result['oof_results'])
            report['generation_stats'][training_head] = {
                'cache_key': cache_key,
                'model_count': model_count,
                'cv_splits': result['cv_info']['n_splits']
            }
        
        return report


# å…¨å±€ç»Ÿä¸€OOFç”Ÿæˆå™¨å®ä¾‹
_global_oof_generator = None

def get_unified_oof_generator(cv_factory: Callable = None) -> UnifiedOOFGenerator:
    """è·å–å…¨å±€ç»Ÿä¸€OOFç”Ÿæˆå™¨"""
    global _global_oof_generator
    
    if _global_oof_generator is None:
        if cv_factory is None:
            # ä½¿ç”¨é»˜è®¤çš„ç»Ÿä¸€CVå·¥å‚
            from .unified_cv_factory import get_unified_cv_factory
            factory = get_unified_cv_factory()
            cv_factory = factory.create_cv_factory()
        
        _global_oof_generator = UnifiedOOFGenerator(cv_factory)
    
    return _global_oof_generator

def generate_unified_oof(X: pd.DataFrame, 
                        y: pd.Series,
                        dates: pd.Series, 
                        models: Dict[str, Any],
                        training_head_id: str,
                        cv_factory: Callable = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆç»Ÿä¸€OOFé¢„æµ‹
    """
    generator = get_unified_oof_generator(cv_factory)
    return generator.generate_oof_predictions(X, y, dates, models, training_head_id)


if __name__ == "__main__":
    # æµ‹è¯•ç»Ÿä¸€OOFç”Ÿæˆå™¨
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    dates = pd.date_range('2020-01-01', periods=500, freq='D')
    X = pd.DataFrame(np.random.randn(500, 10), columns=[f'feature_{i}' for i in range(10)])
    y = pd.Series(np.random.randn(500), name='target')
    
    # æ¨¡æ‹Ÿæ¨¡å‹
    from sklearn.linear_model import LinearRegression
    models = {
        'linear_1': LinearRegression(),
        'linear_2': LinearRegression()
    }
    
    print("æµ‹è¯•ç»Ÿä¸€OOFç”Ÿæˆå™¨")
    
    # ç”ŸæˆOOFé¢„æµ‹
    result = generate_unified_oof(X, y, dates, models, 'test_head')
    
    print(f"ç”Ÿæˆç»“æœ: {result['training_head_id']}")
    print(f"æ¨¡å‹æ•°é‡: {len(result['oof_results'])}")
    
    # æµ‹è¯•æŠ¥å‘Š
    generator = get_unified_oof_generator()
    report = generator.get_generation_report()
    print(f"ç”ŸæˆæŠ¥å‘Š: {report}")