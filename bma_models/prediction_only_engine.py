#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Prediction-Only Engine
======================
Load trained models from snapshot and predict without retraining.

Workflow:
1. Load model snapshots (ElasticNet, XGBoost, CatBoost, LambdaRank, Ridge)
2. Fetch market data for input stocks
3. Calculate 17 alpha factors using Simple17FactorEngine
4. Generate predictions using all 5 models
5. Combine predictions using Ridge stacker
6. Return top recommendations

No training - only prediction using saved model weights.
"""

import os
import json
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class PredictionOnlyEngine:
    """é¢„æµ‹å¼•æ“ - ä»…ä½¿ç”¨å·²ä¿å­˜çš„æ¨¡å‹å¿«ç…§è¿›è¡Œé¢„æµ‹"""

    def __init__(self, snapshot_id: Optional[str] = None):
        """
        åˆå§‹åŒ–é¢„æµ‹å¼•æ“

        Args:
            snapshot_id: æ¨¡å‹å¿«ç…§IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æœ€æ–°å¿«ç…§
        """
        self.snapshot_id = snapshot_id
        self.manifest = None
        self.models = {}
        self.ridge_stacker = None
        self.lambda_rank_stacker = None
        self.lambda_percentile_transformer = None
        self.feature_names = None

        # Load models from snapshot
        self._load_models()

    def _load_models(self):
        """ä»å¿«ç…§åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        from bma_models.model_registry import load_manifest, load_models_from_snapshot

        logger.info("=" * 80)
        logger.info("ğŸ“¦ åŠ è½½æ¨¡å‹å¿«ç…§")
        logger.info("=" * 80)

        # Load manifest
        self.manifest = load_manifest(self.snapshot_id)
        self.snapshot_id = self.manifest['snapshot_id']
        self.feature_names = self.manifest.get('feature_names', [])

        logger.info(f"å¿«ç…§ID: {self.snapshot_id}")
        logger.info(f"åˆ›å»ºæ—¶é—´: {datetime.fromtimestamp(self.manifest['created_at']).strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"æ ‡ç­¾: {self.manifest.get('tag', 'N/A')}")

        # Load all models
        loaded = load_models_from_snapshot(self.snapshot_id)

        self.models = loaded['models']
        self.ridge_stacker = loaded.get('ridge_stacker')
        self.lambda_rank_stacker = loaded.get('lambda_rank_stacker')
        self.lambda_percentile_transformer = loaded.get('lambda_percentile_transformer')

        # Log loaded models
        loaded_model_names = []
        if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
            loaded_model_names.append("ElasticNet")
        if 'xgboost' in self.models and self.models['xgboost'] is not None:
            loaded_model_names.append("XGBoost")
        if 'catboost' in self.models and self.models['catboost'] is not None:
            loaded_model_names.append("CatBoost")
        if self.lambda_rank_stacker is not None:
            loaded_model_names.append("LambdaRank")
        if self.ridge_stacker is not None:
            loaded_model_names.append("Ridge")

        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(loaded_model_names)}/5 ä¸ªæ¨¡å‹: {', '.join(loaded_model_names)}")
        logger.info("=" * 80)


        manifest_horizon = self.manifest.get('prediction_horizon_days')
        if manifest_horizon is None:
            try:
                from bma_models.unified_config_loader import get_time_config
                manifest_horizon = getattr(get_time_config(), 'prediction_horizon_days', 10)
            except Exception:
                manifest_horizon = 10
        self.prediction_horizon_days = int(manifest_horizon)

    def predict(self,
                tickers: List[str],
                start_date: Optional[str] = None,
                end_date: Optional[str] = None,
                top_n: int = 10) -> Dict[str, Any]:
        """
        é¢„æµ‹è‚¡ç¥¨

        Args:
            tickers: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸º30å¤©å‰
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            top_n: è¿”å›å‰Nä¸ªæ¨è

        Returns:
            é¢„æµ‹ç»“æœå­—å…¸
        """
        logger.info("=" * 80)
        logger.info("ğŸ¯ å¼€å§‹é¢„æµ‹")
        logger.info("=" * 80)
        logger.info(f"è¾“å…¥è‚¡ç¥¨: {len(tickers)} åª")
        logger.info(f"è‚¡ç¥¨åˆ—è¡¨: {', '.join(tickers[:10])}{'...' if len(tickers) > 10 else ''}")

        # Set default dates
        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')

        logger.info(f"æ•°æ®æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")

        # Step 1: Fetch market data and calculate factors
        feature_data = self._get_features(tickers, start_date, end_date)

        if feature_data is None or len(feature_data) == 0:
            logger.error("âŒ æ— æ³•è·å–ç‰¹å¾æ•°æ®")
            return {'success': False, 'error': 'æ— æ³•è·å–ç‰¹å¾æ•°æ®'}

        logger.info(f"âœ… ç‰¹å¾æ•°æ®å‡†å¤‡å®Œæˆ: {feature_data.shape}")

        # Step 2: Generate predictions from all models
        predictions = self._generate_predictions(feature_data)

        if predictions is None:
            logger.error("âŒ é¢„æµ‹å¤±è´¥")
            return {'success': False, 'error': 'é¢„æµ‹å¤±è´¥'}

        logger.info(f"âœ… é¢„æµ‹å®Œæˆ: {len(predictions)} åªè‚¡ç¥¨")

        # Step 3: Get latest predictions (most recent date)
        latest_predictions = self._get_latest_predictions(predictions, tickers)

        # Step 4: Create recommendations
        recommendations = self._create_recommendations(latest_predictions, top_n)

        logger.info("=" * 80)
        logger.info(f"ğŸ† Top {len(recommendations)} æ¨è:")
        for i, rec in enumerate(recommendations, 1):
            logger.info(f"  {i}. {rec['ticker']}: {rec['score']:.6f}")
        logger.info("=" * 80)

        return {
            'success': True,
            'snapshot_id': self.snapshot_id,
            'predictions': predictions,
            'recommendations': recommendations,
            'tickers': tickers,
            'n_stocks': len(tickers),
            'date_range': f"{start_date} to {end_date}"
        }

    def _get_features(self,
                     tickers: List[str],
                     start_date: str,
                     end_date: str) -> Optional[pd.DataFrame]:
        """è·å–ç‰¹å¾æ•°æ®"""
        logger.info("ğŸ“¡ è·å–å¸‚åœºæ•°æ®å¹¶è®¡ç®—å› å­...")

        try:
            # Initialize Simple17FactorEngine
            from bma_models.simple_25_factor_engine import Simple17FactorEngine

            # Calculate lookback days
            start_dt = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)
            lookback_days = (end_dt - start_dt).days + 50

            # ğŸ”¥ FIX: Skip cross-sectional standardization for single/few stocks
            skip_cs_std = len(tickers) < 3
            if skip_cs_std:
                logger.info(f"âš ï¸ Only {len(tickers)} stock(s) - skipping cross-sectional standardization")

            # ğŸ”¥ NEW: ä½¿ç”¨predictæ¨¡å¼åˆå§‹åŒ–å¼•æ“
            logger.info("ğŸ”® åˆå§‹åŒ–Simple17FactorEngineä¸ºPREDICTæ¨¡å¼")
            engine = Simple17FactorEngine(
                lookback_days=lookback_days,
                skip_cross_sectional_standardization=skip_cs_std,  # Skip for <3 stocks
                mode='predict',  # ğŸ”¥ é¢„æµ‹æ¨¡å¼ï¼šä¸è®¡ç®—targetï¼Œä¸dropna
                horizon=getattr(self, 'prediction_horizon_days', 10)
            )

            # Fetch market data
            market_data = engine.fetch_market_data(
                symbols=tickers,
                use_optimized_downloader=True,
                start_date=start_date,
                end_date=end_date
            )

            if market_data.empty:
                logger.error("âŒ æ— æ³•è·å–å¸‚åœºæ•°æ®")
                return None

            logger.info(f"âœ… å¸‚åœºæ•°æ®: {market_data.shape}")

            # Calculate all 17 factors (with mode='predict' to skip target calculation)
            logger.info("ğŸ”® è®¡ç®—å› å­ï¼ˆé¢„æµ‹æ¨¡å¼ï¼‰...")
            feature_data = engine.compute_all_17_factors(market_data, mode='predict')

            if feature_data.empty:
                logger.error("âŒ å› å­è®¡ç®—å¤±è´¥")
                return None

            logger.info(f"âœ… å› å­è®¡ç®—å®Œæˆ: {feature_data.shape}")
            logger.info(f"   å› å­åˆ—: {list(feature_data.columns)}")

            # ğŸ”¥ é¢„æµ‹æ¨¡å¼ï¼štargetåˆ—å·²ç»æ˜¯NaNï¼Œæ— éœ€drop
            # ä¿ç•™æ‰€æœ‰æ ·æœ¬ï¼ˆåŒ…æ‹¬æœ€æ–°çš„æ•°æ®ï¼‰ç”¨äºé¢„æµ‹
            if 'target' in feature_data.columns:
                feature_data = feature_data.drop(columns=['target'])
                logger.info("   ç§»é™¤ç©ºtargetåˆ—")

            # Drop Close column (not a feature)
            if 'Close' in feature_data.columns:
                feature_data = feature_data.drop(columns=['Close'])
                logger.info("   ç§»é™¤Closeåˆ—ï¼ˆä»…ä¿ç•™å› å­ï¼‰")

            return feature_data

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def _generate_predictions(self, feature_data: pd.DataFrame) -> Optional[pd.Series]:
        """ä½¿ç”¨æ‰€æœ‰æ¨¡å‹ç”Ÿæˆé¢„æµ‹"""
        logger.info("ğŸ”® ç”Ÿæˆæ¨¡å‹é¢„æµ‹...")

        try:
            # Ensure feature_data has MultiIndex (date, ticker)
            if not isinstance(feature_data.index, pd.MultiIndex):
                logger.error("âŒ feature_dataå¿…é¡»æœ‰MultiIndex (date, ticker)")
                return None

            # Extract features (exclude metadata columns)
            metadata_cols = ['date', 'ticker', 'target', 'Close']
            feature_cols = [col for col in feature_data.columns if col not in metadata_cols]

            X = feature_data[feature_cols].copy()
            # Align to training-time feature names from snapshot manifest when available
            try:
                if self.feature_names:
                    cols = [c for c in self.feature_names if c in X.columns]
                    # Append any extra columns not seen in training to the end
                    cols += [c for c in X.columns if c not in cols]
                    if list(X.columns) != cols:
                        X = X[cols]
                        logger.info(f"ğŸ“ å¯¹é½æ¨ç†ç‰¹å¾åˆ°è®­ç»ƒç‰¹å¾åé¡ºåº: {len(cols)} åˆ—")
            except Exception:
                pass
            dates = feature_data.index.get_level_values('date')
            tickers = feature_data.index.get_level_values('ticker')

            logger.info(f"ç‰¹å¾çŸ©é˜µ: {X.shape}")
            logger.info(f"ä½¿ç”¨ç‰¹å¾: {feature_cols}")

            # Fill NaN with 0 (models were trained with this)
            X = X.fillna(0)

            # Generate first layer predictions
            first_layer_predictions = {}

            # ElasticNet
            if 'elastic_net' in self.models and self.models['elastic_net'] is not None:
                try:
                    enet_pred = self.models['elastic_net'].predict(X)
                    first_layer_predictions['elastic_net'] = pd.Series(enet_pred, index=feature_data.index)
                    logger.info(f"âœ… ElasticNeté¢„æµ‹: {len(enet_pred)}")
                except Exception as e:
                    logger.warning(f"ElasticNeté¢„æµ‹å¤±è´¥: {e}")

            # XGBoost
            if 'xgboost' in self.models and self.models['xgboost'] is not None:
                try:
                    xgb_pred = self.models['xgboost'].predict(X)
                    first_layer_predictions['xgboost'] = pd.Series(xgb_pred, index=feature_data.index)
                    logger.info(f"âœ… XGBoosté¢„æµ‹: {len(xgb_pred)}")
                except Exception as e:
                    logger.warning(f"XGBoosté¢„æµ‹å¤±è´¥: {e}")

            # CatBoost
            if 'catboost' in self.models and self.models['catboost'] is not None:
                try:
                    cat_pred = self.models['catboost'].predict(X)
                    first_layer_predictions['catboost'] = pd.Series(cat_pred, index=feature_data.index)
                    logger.info(f"âœ… CatBoosté¢„æµ‹: {len(cat_pred)}")
                except Exception as e:
                    logger.warning(f"CatBoosté¢„æµ‹å¤±è´¥: {e}")

            # LambdaRank
            if self.lambda_rank_stacker is not None:
                try:
                    # LambdaRank expects specific input format
                    lambda_input = X.copy()
                    lambda_input.index = feature_data.index
                    lambda_pred = self.lambda_rank_stacker.predict(lambda_input)

                    # Apply Lambda Percentile Transformer if available
                    if self.lambda_percentile_transformer is not None:
                        try:
                            lambda_pred = self.lambda_percentile_transformer.transform(lambda_pred)
                            logger.info("âœ… Lambda Percentile Transformeråº”ç”¨æˆåŠŸ")
                        except Exception as e:
                            logger.warning(f"Lambda Percentile Transformeråº”ç”¨å¤±è´¥: {e}")

                    first_layer_predictions['lambdarank'] = lambda_pred
                    logger.info(f"âœ… LambdaRanké¢„æµ‹: {len(lambda_pred)}")
                except Exception as e:
                    logger.warning(f"LambdaRanké¢„æµ‹å¤±è´¥: {e}")
                    import traceback
                    logger.debug(traceback.format_exc())

            if len(first_layer_predictions) == 0:
                logger.error("âŒ æ‰€æœ‰ç¬¬ä¸€å±‚æ¨¡å‹é¢„æµ‹å¤±è´¥")
                return None

            logger.info(f"âœ… ç¬¬ä¸€å±‚é¢„æµ‹å®Œæˆ: {len(first_layer_predictions)} ä¸ªæ¨¡å‹")

            # Combine using Ridge stacker
            if self.ridge_stacker is not None:
                try:
                    # Create stacking features
                    stacking_df = pd.DataFrame(index=feature_data.index)
                    for name, pred in first_layer_predictions.items():
                        stacking_df[name] = pred

                    # Ridge predict
                    final_predictions = self.ridge_stacker.predict(stacking_df)
                    logger.info(f"âœ… Ridge Stackerèåˆå®Œæˆ: {len(final_predictions)}")

                    return final_predictions

                except Exception as e:
                    logger.warning(f"Ridge Stackerèåˆå¤±è´¥: {e}")
                    logger.warning("ä½¿ç”¨ç®€å•å¹³å‡ä½œä¸ºåå¤‡")
                    import traceback
                    logger.debug(traceback.format_exc())

            # Fallback: simple average
            stacked = pd.DataFrame(first_layer_predictions)
            final_predictions = stacked.mean(axis=1)
            logger.info(f"âœ… ä½¿ç”¨ç®€å•å¹³å‡: {len(final_predictions)}")

            return final_predictions

        except Exception as e:
            logger.error(f"âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return None

    def _get_latest_predictions(self,
                               predictions: pd.Series,
                               tickers: List[str]) -> pd.DataFrame:
        """è·å–æœ€æ–°æ—¥æœŸçš„é¢„æµ‹"""
        # Get latest date
        if isinstance(predictions.index, pd.MultiIndex):
            dates = predictions.index.get_level_values('date')
            latest_date = dates.max()

            # Filter to latest date and requested tickers
            mask = predictions.index.get_level_values('date') == latest_date
            latest_pred = predictions[mask]

            # Create DataFrame
            pred_df = pd.DataFrame({
                'ticker': latest_pred.index.get_level_values('ticker'),
                'score': latest_pred.values
            })
        else:
            # If not MultiIndex, assume single date
            pred_df = pd.DataFrame({
                'ticker': predictions.index,
                'score': predictions.values
            })

        # Filter to requested tickers only
        pred_df = pred_df[pred_df['ticker'].isin(tickers)]

        # Sort by score descending
        pred_df = pred_df.sort_values('score', ascending=False)

        return pred_df

    def _create_recommendations(self,
                               pred_df: pd.DataFrame,
                               top_n: int) -> List[Dict[str, Any]]:
        """åˆ›å»ºæ¨èåˆ—è¡¨"""
        recommendations = []

        for i, (idx, row) in enumerate(pred_df.head(top_n).iterrows(), 1):
            recommendations.append({
                'rank': i,
                'ticker': row['ticker'],
                'score': float(row['score']),
                'prediction_signal': float(row['score']),
            })

        return recommendations


def create_prediction_engine(snapshot_id: Optional[str] = None) -> PredictionOnlyEngine:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé¢„æµ‹å¼•æ“"""
    return PredictionOnlyEngine(snapshot_id=snapshot_id)
