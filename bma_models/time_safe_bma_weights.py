"""
Time-Safe BMA Weight Calculation Module
======================================
ç¡®ä¿BMAæƒé‡è®¡ç®—ä¸¥æ ¼åŸºäºå†å²æ•°æ®ï¼Œé˜²æ­¢å‰ç»åå·®

å…³é”®åŸåˆ™ï¼š
1. æƒé‡è®¡ç®—åªèƒ½ä½¿ç”¨T-1åŠä¹‹å‰çš„å†å²æ•°æ®
2. ICè®¡ç®—å¿…é¡»åŸºäºå†å²out-of-sampleé¢„æµ‹
3. æ»šåŠ¨çª—å£æ›´æ–°æƒé‡ï¼Œç¡®ä¿æ—¶é—´ä¸€è‡´æ€§
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
import logging
from scipy.stats import spearmanr
from collections import defaultdict

logger = logging.getLogger(__name__)


class TimeSafeBMAWeightCalculator:
    """
    æ—¶é—´å®‰å…¨çš„BMAæƒé‡è®¡ç®—å™¨
    
    ç¡®ä¿æ‰€æœ‰æƒé‡è®¡ç®—ä¸¥æ ¼éµå¾ªæ—¶é—´åºåˆ—åŸåˆ™ï¼š
    - ä½¿ç”¨historical-onlyæ•°æ®è®¡ç®—IC
    - æ»šåŠ¨çª—å£æ›´æ–°æƒé‡
    - ä¸¥æ ¼çš„æ—¶é—´éªŒè¯
    """
    
    def __init__(self, 
                 lookback_days: int = 252,
                 min_history_days: int = 63,
                 rebalance_frequency: int = 21,
                 ic_shrinkage_factor: float = 0.8):
        """
        åˆå§‹åŒ–æ—¶é—´å®‰å…¨BMAæƒé‡è®¡ç®—å™¨
        
        Parameters:
        -----------
        lookback_days : int
            æƒé‡è®¡ç®—çš„å†å²å›æœ›å¤©æ•°ï¼ˆçº¦1å¹´ï¼‰
        min_history_days : int
            è®¡ç®—æƒé‡æ‰€éœ€çš„æœ€å°å†å²å¤©æ•°ï¼ˆçº¦3ä¸ªæœˆï¼‰
        rebalance_frequency : int
            æƒé‡é‡æ–°è®¡ç®—é¢‘ç‡ï¼ˆå¤©æ•°ï¼‰
        ic_shrinkage_factor : float
            ICæ”¶ç¼©å› å­ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
        """
        self.lookback_days = lookback_days
        self.min_history_days = min_history_days
        self.rebalance_frequency = rebalance_frequency
        self.ic_shrinkage_factor = ic_shrinkage_factor
        
        # æƒé‡å†å²è®°å½•
        self.weight_history = {}
        self.ic_history = {}
        self.last_rebalance_date = None
        
        logger.info(f"æ—¶é—´å®‰å…¨BMAæƒé‡è®¡ç®—å™¨åˆå§‹åŒ–: "
                   f"å›æœ›={lookback_days}å¤©, æœ€å°å†å²={min_history_days}å¤©, "
                   f"é‡å¹³è¡¡é¢‘ç‡={rebalance_frequency}å¤©")
    
    def calculate_time_safe_weights(self, 
                                   oof_predictions: Dict[str, pd.Series],
                                   targets: pd.Series,
                                   current_date: pd.Timestamp,
                                   force_rebalance: bool = False) -> Dict[str, float]:
        """
        è®¡ç®—æ—¶é—´å®‰å…¨çš„BMAæƒé‡
        
        Parameters:
        -----------
        oof_predictions : Dict[str, pd.Series]
            å„æ¨¡å‹çš„OOFé¢„æµ‹ï¼Œindexå¿…é¡»åŒ…å«dateä¿¡æ¯
        targets : pd.Series
            ç›®æ ‡å˜é‡ï¼Œindexå¿…é¡»åŒ…å«dateä¿¡æ¯
        current_date : pd.Timestamp
            å½“å‰æ—¥æœŸï¼ˆæƒé‡è®¡ç®—çš„æˆªæ­¢æ—¥æœŸï¼‰
        force_rebalance : bool
            æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—æƒé‡
            
        Returns:
        --------
        Dict[str, float] : æ—¶é—´å®‰å…¨çš„BMAæƒé‡
        """
        logger.info(f"ğŸ•’ å¼€å§‹è®¡ç®—æ—¶é—´å®‰å…¨BMAæƒé‡ (æˆªæ­¢æ—¥æœŸ: {current_date.strftime('%Y-%m-%d')})")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è®¡ç®—æƒé‡
        if not force_rebalance and self._should_use_cached_weights(current_date):
            logger.info("ä½¿ç”¨ç¼“å­˜çš„æƒé‡")
            return self.weight_history.get(current_date, {})
        
        # éªŒè¯è¾“å…¥æ•°æ®çš„æ—¶é—´å®‰å…¨æ€§
        self._validate_time_safety(oof_predictions, targets, current_date)
        
        # è¿‡æ»¤å†å²æ•°æ®ï¼ˆä¸¥æ ¼T-1æˆªæ­¢ï¼‰
        historical_predictions = self._filter_historical_data(oof_predictions, current_date)
        historical_targets = self._filter_historical_data({'targets': targets}, current_date)['targets']
        
        # æ£€æŸ¥æ•°æ®å……è¶³æ€§
        if not self._has_sufficient_history(historical_predictions, historical_targets):
            logger.warning("å†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å‡ç­‰æƒé‡")
            return self._get_equal_weights(list(oof_predictions.keys()))
        
        # è®¡ç®—å†å²ICæŒ‡æ ‡
        historical_metrics = self._calculate_historical_metrics(historical_predictions, historical_targets)
        
        # è®¡ç®—æ—¶é—´å®‰å…¨çš„BMAæƒé‡
        safe_weights = self._compute_safe_bma_weights(historical_metrics, current_date)
        
        # ç¼“å­˜æƒé‡
        self.weight_history[current_date] = safe_weights
        self.last_rebalance_date = current_date
        
        logger.info(f"æƒé‡è®¡ç®—å®Œæˆ: {dict(safe_weights)}")
        return safe_weights
    
    def _validate_time_safety(self, 
                             oof_predictions: Dict[str, pd.Series],
                             targets: pd.Series,
                             current_date: pd.Timestamp) -> None:
        """éªŒè¯è¾“å…¥æ•°æ®çš„æ—¶é—´å®‰å…¨æ€§"""
        
        # æ£€æŸ¥æ‰€æœ‰æ•°æ®éƒ½ä¸¥æ ¼æ—©äºcurrent_date
        for model_name, predictions in oof_predictions.items():
            if hasattr(predictions.index, 'get_level_values'):
                # MultiIndexæƒ…å†µ
                try:
                    dates = pd.to_datetime(predictions.index.get_level_values('date'))
                except:
                    dates = pd.to_datetime(predictions.index.get_level_values(0))  # å‡è®¾ç¬¬ä¸€å±‚æ˜¯æ—¥æœŸ
            else:
                dates = pd.to_datetime(predictions.index)
            
            latest_date = dates.max()
            if latest_date >= current_date:
                raise ValueError(f"æ¨¡å‹ {model_name} åŒ…å«å½“æœŸæˆ–æœªæ¥æ•°æ®: "
                               f"æœ€æ–°æ—¥æœŸ {latest_date} >= å½“å‰æ—¥æœŸ {current_date}")
        
        # æ£€æŸ¥ç›®æ ‡æ•°æ®
        if hasattr(targets.index, 'get_level_values'):
            try:
                target_dates = pd.to_datetime(targets.index.get_level_values('date'))
            except:
                target_dates = pd.to_datetime(targets.index.get_level_values(0))
        else:
            target_dates = pd.to_datetime(targets.index)
        
        latest_target_date = target_dates.max()
        if latest_target_date >= current_date:
            raise ValueError(f"ç›®æ ‡æ•°æ®åŒ…å«å½“æœŸæˆ–æœªæ¥ä¿¡æ¯: "
                           f"æœ€æ–°æ—¥æœŸ {latest_target_date} >= å½“å‰æ—¥æœŸ {current_date}")
        
        logger.info("âœ… æ—¶é—´å®‰å…¨æ€§éªŒè¯é€šè¿‡")
    
    def _filter_historical_data(self, 
                               data_dict: Dict[str, pd.Series],
                               current_date: pd.Timestamp) -> Dict[str, pd.Series]:
        """è¿‡æ»¤å‡ºä¸¥æ ¼çš„å†å²æ•°æ®ï¼ˆT-1æˆªæ­¢ï¼‰"""
        
        # è®¡ç®—å†å²æ•°æ®çš„æ—¶é—´çª—å£
        end_date = current_date - timedelta(days=1)  # T-1æˆªæ­¢
        start_date = end_date - timedelta(days=self.lookback_days)
        
        filtered_data = {}
        
        for key, series in data_dict.items():
            try:
                if hasattr(series.index, 'get_level_values'):
                    # MultiIndexå¤„ç†
                    try:
                        dates = pd.to_datetime(series.index.get_level_values('date'))
                    except:
                        dates = pd.to_datetime(series.index.get_level_values(0))
                    
                    # ç­›é€‰æ—¶é—´èŒƒå›´
                    mask = (dates >= start_date) & (dates <= end_date)
                    filtered_series = series[mask]
                else:
                    # æ™®é€šIndexå¤„ç†
                    dates = pd.to_datetime(series.index)
                    mask = (dates >= start_date) & (dates <= end_date)
                    filtered_series = series[mask]
                
                filtered_data[key] = filtered_series
                logger.info(f"{key}: è¿‡æ»¤åæ•°æ®é‡ {len(filtered_series)} "
                           f"(æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')})")
                
            except Exception as e:
                logger.error(f"è¿‡æ»¤å†å²æ•°æ®å¤±è´¥ {key}: {e}")
                filtered_data[key] = pd.Series(dtype=float)
        
        return filtered_data
    
    def _has_sufficient_history(self, 
                               predictions: Dict[str, pd.Series],
                               targets: pd.Series) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®"""
        
        if len(targets) < self.min_history_days:
            logger.warning(f"ç›®æ ‡æ•°æ®ä¸è¶³: {len(targets)} < {self.min_history_days}")
            return False
        
        for model_name, pred in predictions.items():
            if len(pred) < self.min_history_days:
                logger.warning(f"æ¨¡å‹ {model_name} å†å²æ•°æ®ä¸è¶³: {len(pred)} < {self.min_history_days}")
                return False
        
        return True
    
    def _calculate_historical_metrics(self, 
                                    predictions: Dict[str, pd.Series],
                                    targets: pd.Series) -> Dict[str, Dict]:
        """è®¡ç®—åŸºäºå†å²æ•°æ®çš„ICæŒ‡æ ‡"""
        
        metrics = {}
        
        for model_name, pred in predictions.items():
            try:
                # å¯¹é½é¢„æµ‹å’Œç›®æ ‡æ•°æ®
                aligned_pred, aligned_target = self._align_series(pred, targets)
                
                if len(aligned_pred) < 10:
                    logger.warning(f"æ¨¡å‹ {model_name} å¯¹é½åæ•°æ®ä¸è¶³")
                    metrics[model_name] = self._get_default_metrics()
                    continue
                
                # è®¡ç®—IC (ä½¿ç”¨Spearmanç›¸å…³ç³»æ•°)
                ic_corr, ic_pvalue = spearmanr(aligned_target, aligned_pred)
                ic = ic_corr if not np.isnan(ic_corr) else 0.0
                
                # è®¡ç®—tç»Ÿè®¡é‡
                n = len(aligned_pred)
                t_stat = ic * np.sqrt((n - 2) / (1 - ic**2 + 1e-8)) if abs(ic) < 0.99 else 0
                
                # è®¡ç®—æ»šåŠ¨ICçš„ç¨³å®šæ€§ (ICIRè¿‘ä¼¼)
                ic_std = self._calculate_rolling_ic_std(aligned_pred, aligned_target)
                icir = ic / (ic_std + 1e-8)
                
                # åº”ç”¨ICæ”¶ç¼©
                ic_shrunk = ic * self.ic_shrinkage_factor
                
                metrics[model_name] = {
                    'ic_raw': ic,
                    'ic_shrunk': ic_shrunk,
                    'ic_pvalue': ic_pvalue,
                    't_stat': t_stat,
                    'icir': icir,
                    'sample_count': len(aligned_pred)
                }
                
                logger.info(f"{model_name} å†å²æŒ‡æ ‡: IC={ic:.4f}â†’{ic_shrunk:.4f}, "
                           f"t={t_stat:.2f}, ICIR={icir:.4f}")
                
            except Exception as e:
                logger.error(f"è®¡ç®— {model_name} å†å²æŒ‡æ ‡å¤±è´¥: {e}")
                metrics[model_name] = self._get_default_metrics()
        
        return metrics
    
    def _align_series(self, pred: pd.Series, target: pd.Series) -> Tuple[pd.Series, pd.Series]:
        """å¯¹é½ä¸¤ä¸ªSeriesï¼ˆå¤„ç†MultiIndexï¼‰"""
        
        try:
            # å°è¯•ç›´æ¥å¯¹é½
            if hasattr(pred.index, 'names') and hasattr(target.index, 'names'):
                # éƒ½æ˜¯MultiIndex
                common_index = pred.index.intersection(target.index)
                if len(common_index) > 0:
                    aligned_pred = pred.reindex(common_index).dropna()
                    aligned_target = target.reindex(common_index).dropna()
                    
                    # å†æ¬¡å¯¹é½ä»¥ç¡®ä¿æ— ç¼ºå¤±å€¼
                    final_index = aligned_pred.index.intersection(aligned_target.index)
                    return aligned_pred.reindex(final_index), aligned_target.reindex(final_index)
            
            # ç®€å•å¯¹é½ï¼ˆå¦‚æœIndexç»“æ„ä¸åŒ¹é…ï¼‰
            min_len = min(len(pred), len(target))
            aligned_pred = pred.iloc[:min_len].dropna()
            aligned_target = target.iloc[:min_len].dropna()
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            final_len = min(len(aligned_pred), len(aligned_target))
            return aligned_pred.iloc[:final_len], aligned_target.iloc[:final_len]
            
        except Exception as e:
            logger.error(f"åºåˆ—å¯¹é½å¤±è´¥: {e}")
            return pd.Series(dtype=float), pd.Series(dtype=float)
    
    def _calculate_rolling_ic_std(self, pred: pd.Series, target: pd.Series, window: int = 63) -> float:
        """è®¡ç®—æ»šåŠ¨ICçš„æ ‡å‡†å·®ï¼ˆç”¨äºICIRè®¡ç®—ï¼‰"""
        try:
            if len(pred) < window:
                return 1.0  # é»˜è®¤å€¼
            
            rolling_ics = []
            for i in range(window, len(pred)):
                window_pred = pred.iloc[i-window:i]
                window_target = target.iloc[i-window:i]
                
                if len(window_pred) == len(window_target) and len(window_pred) > 5:
                    ic_corr, _ = spearmanr(window_target, window_pred)
                    if not np.isnan(ic_corr):
                        rolling_ics.append(ic_corr)
            
            return np.std(rolling_ics) if len(rolling_ics) > 1 else 1.0
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ»šåŠ¨ICæ ‡å‡†å·®å¤±è´¥: {e}")
            return 1.0
    
    def _compute_safe_bma_weights(self, 
                                 metrics: Dict[str, Dict],
                                 current_date: pd.Timestamp) -> Dict[str, float]:
        """è®¡ç®—å®‰å…¨çš„BMAæƒé‡"""
        
        # è¿‡æ»¤æ‰æ— æ•ˆæ¨¡å‹
        valid_models = {name: m for name, m in metrics.items() 
                       if m['sample_count'] >= 10 and abs(m['t_stat']) >= 1.0}
        
        if not valid_models:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆæ¨¡å‹ï¼Œä½¿ç”¨å‡ç­‰æƒé‡")
            return self._get_equal_weights(list(metrics.keys()))
        
        # è®¡ç®—åŸå§‹æƒé‡ï¼ˆåŸºäºæ”¶ç¼©åçš„ICå’ŒICIRï¼‰
        raw_weights = {}
        for model_name, m in valid_models.items():
            # æƒé‡ = IC_shrunk Ã— ICIR Ã— max(0, IC_shrunk)
            weight = m['ic_shrunk'] * m['icir'] * max(0, m['ic_shrunk'])
            raw_weights[model_name] = weight
        
        # æ ‡å‡†åŒ–æƒé‡
        total_weight = sum(raw_weights.values())
        if total_weight <= 0:
            logger.warning("æ€»æƒé‡éæ­£ï¼Œä½¿ç”¨å‡ç­‰æƒé‡")
            return self._get_equal_weights(list(valid_models.keys()))
        
        normalized_weights = {name: w / total_weight for name, w in raw_weights.items()}
        
        # åº”ç”¨æƒé‡çº¦æŸï¼ˆå•æ¨¡å‹ä¸è¶…è¿‡50%ï¼‰
        constrained_weights = self._apply_weight_constraints(normalized_weights)
        
        # EMAå¹³æ»‘ï¼ˆå¦‚æœæœ‰å†å²æƒé‡ï¼‰
        smoothed_weights = self._apply_ema_smoothing(constrained_weights, current_date)
        
        return smoothed_weights
    
    def _apply_weight_constraints(self, weights: Dict[str, float]) -> Dict[str, float]:
        """åº”ç”¨æƒé‡çº¦æŸ"""
        max_weight = 0.5  # å•æ¨¡å‹æœ€å¤§æƒé‡50%
        
        # æˆªæ–­è¿‡å¤§æƒé‡
        constrained = {}
        total_excess = 0
        
        for name, weight in weights.items():
            if weight > max_weight:
                constrained[name] = max_weight
                total_excess += weight - max_weight
            else:
                constrained[name] = weight
        
        # é‡æ–°åˆ†é…è¶…é¢æƒé‡
        if total_excess > 0:
            eligible_models = [name for name, w in constrained.items() if w < max_weight]
            if eligible_models:
                redistribution = total_excess / len(eligible_models)
                for name in eligible_models:
                    constrained[name] = min(constrained[name] + redistribution, max_weight)
        
        # é‡æ–°æ ‡å‡†åŒ–
        total = sum(constrained.values())
        if total > 0:
            constrained = {name: w / total for name, w in constrained.items()}
        
        return constrained
    
    def _apply_ema_smoothing(self, 
                            current_weights: Dict[str, float],
                            current_date: pd.Timestamp,
                            alpha: float = 0.3) -> Dict[str, float]:
        """åº”ç”¨EMAå¹³æ»‘åˆ°æƒé‡åºåˆ—"""
        
        if not self.weight_history:
            return current_weights
        
        # å¯»æ‰¾æœ€è¿‘çš„å†å²æƒé‡
        previous_weights = {}
        for date in sorted(self.weight_history.keys(), reverse=True):
            if date < current_date:
                previous_weights = self.weight_history[date]
                break
        
        if not previous_weights:
            return current_weights
        
        # EMAå¹³æ»‘: w_new = Î± Ã— w_current + (1-Î±) Ã— w_previous
        smoothed = {}
        all_models = set(current_weights.keys()) | set(previous_weights.keys())
        
        for model in all_models:
            current = current_weights.get(model, 0.0)
            previous = previous_weights.get(model, 0.0)
            smoothed[model] = alpha * current + (1 - alpha) * previous
        
        # æ ‡å‡†åŒ–å¹¶è¿‡æ»¤å°æƒé‡
        total = sum(smoothed.values())
        if total > 0:
            smoothed = {name: w / total for name, w in smoothed.items() if w / total >= 0.01}
        
        logger.info(f"EMAå¹³æ»‘åº”ç”¨: Î±={alpha}")
        return smoothed
    
    def _should_use_cached_weights(self, current_date: pd.Timestamp) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜æƒé‡"""
        if self.last_rebalance_date is None:
            return False
        
        days_since_rebalance = (current_date - self.last_rebalance_date).days
        return days_since_rebalance < self.rebalance_frequency
    
    def _get_equal_weights(self, model_names: List[str]) -> Dict[str, float]:
        """è·å–å‡ç­‰æƒé‡"""
        if not model_names:
            return {}
        
        weight = 1.0 / len(model_names)
        return {name: weight for name in model_names}
    
    def _get_default_metrics(self) -> Dict[str, float]:
        """è·å–é»˜è®¤æŒ‡æ ‡"""
        return {
            'ic_raw': 0.0,
            'ic_shrunk': 0.0,
            'ic_pvalue': 1.0,
            't_stat': 0.0,
            'icir': 0.0,
            'sample_count': 0
        }
    
    def get_weight_statistics(self) -> Dict[str, Any]:
        """è·å–æƒé‡ç»Ÿè®¡ä¿¡æ¯"""
        if not self.weight_history:
            return {}
        
        latest_date = max(self.weight_history.keys())
        latest_weights = self.weight_history[latest_date]
        
        return {
            'latest_date': latest_date,
            'latest_weights': latest_weights,
            'total_rebalances': len(self.weight_history),
            'weight_concentration': max(latest_weights.values()) if latest_weights else 0,
            'active_models': len([w for w in latest_weights.values() if w > 0.01])
        }


def create_time_safe_bma_calculator(lookback_days: int = 252,
                                   min_history_days: int = 63,
                                   rebalance_frequency: int = 21) -> TimeSafeBMAWeightCalculator:
    """
    åˆ›å»ºæ—¶é—´å®‰å…¨çš„BMAæƒé‡è®¡ç®—å™¨
    
    Returns:
    --------
    TimeSafeBMAWeightCalculator : é…ç½®å¥½çš„æƒé‡è®¡ç®—å™¨
    """
    return TimeSafeBMAWeightCalculator(
        lookback_days=lookback_days,
        min_history_days=min_history_days,
        rebalance_frequency=rebalance_frequency
    )