#!/usr/bin/env python3
"""
ä¿®å¤çš„ Purged Group Time Series Cross Validation
è§£å†³æ•°æ®æ³„éœ²ã€æ ·æœ¬ä¸è¶³ã€æ—¶é—´é—´éš”ç­‰é—®é¢˜
"""

import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import Iterator, Tuple, Optional
from sklearn.model_selection import BaseCrossValidator
import logging

logger = logging.getLogger(__name__)

@dataclass
class ValidationConfig:
    """éªŒè¯é…ç½® - ä¸Ultra Enhancedæ¨¡å‹ä¿æŒä¸€è‡´"""
    n_splits: int = 5
    test_size: int = 63  # æµ‹è¯•é›†å¤§å°ï¼ˆäº¤æ˜“æ—¥ï¼‰
    gap: int = 10        # âœ… FIX: ç»Ÿä¸€ä¸º10å¤©ï¼Œä¸isolation_daysä¸€è‡´
    embargo: int = 0     # âœ… FIX: é¿å…åŒé‡éš”ç¦»ï¼ŒV6ä½¿ç”¨å•ä¸€éš”ç¦»æ–¹æ³•
    min_train_size: int = 252  # æœ€å°è®­ç»ƒé›†å¤§å°
    group_freq: str = 'W'      # åˆ†ç»„é¢‘ç‡
    strict_validation: bool = True  # ä¸¥æ ¼éªŒè¯æ¨¡å¼
    
@dataclass
class CVResults:
    """äº¤å‰éªŒè¯ç»“æœ"""
    oof_predictions: pd.Series
    oof_ic: float
    oof_rank_ic: float
    oof_ndcg: float
    fold_metrics: list
    feature_importance: dict
    uncertainty_estimates: pd.Series

class FixedPurgedGroupTimeSeriesSplit(BaseCrossValidator):
    """
    ä¿®å¤çš„ Purged Group Time Series Split with Embargo
    
    ä¸»è¦ä¿®å¤:
    1. ä¸¥æ ¼çš„æ—¶é—´é¡ºåºéªŒè¯
    2. æ•°æ®æ³„éœ²é˜²æŠ¤
    3. åˆç†çš„æ ·æœ¬æ•°è¦æ±‚
    4. æ¸…æ™°çš„Gapå’ŒEmbargoé€»è¾‘
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
        
    def split(self, X, y=None, groups=None):
        """
        ç”Ÿæˆè®­ç»ƒ/æµ‹è¯•ç´¢å¼•å¯¹ï¼ˆä¿®å¤ç‰ˆï¼‰
        """
        if groups is None:
            raise ValueError("groupså‚æ•°æ˜¯å¿…é¡»çš„")
        
        # ç¡®ä¿ç´¢å¼•å¯¹é½
        if hasattr(X, 'index'):
            data_index = X.index
        else:
            data_index = np.arange(len(X))
        
        if hasattr(groups, 'index'):
            groups = groups.reindex(data_index)
        
        unique_groups = sorted(groups.unique())
        n_groups = len(unique_groups)
        
        logger.info(f"æ€»å…±{n_groups}ä¸ªæ—¶é—´ç»„ï¼Œé…ç½®{self.config.n_splits}æŠ˜éªŒè¯")
        
        # âœ… FIX: æ›´æ–°æ•°æ®å……è¶³æ€§æ£€æŸ¥ï¼ˆV6å•ä¸€éš”ç¦»ï¼‰
        min_required_groups = self.config.n_splits + self.config.gap + 2  # ç§»é™¤embargo
        if n_groups < min_required_groups:
            logger.warning(f"æ•°æ®è¾ƒå°‘: æ¨èè‡³å°‘{min_required_groups}ç»„ï¼Œå®é™…åªæœ‰{n_groups}ç»„")
            # V6: å¯¹å°æ•°æ®é›†æ›´å®½æ¾ï¼Œä¸ç›´æ¥è¿”å›ç©º
            if n_groups < (self.config.n_splits + 2):  # æœ€ä½è¦æ±‚
                logger.error(f"æ•°æ®æå°‘: è‡³å°‘éœ€è¦{self.config.n_splits + 2}ç»„è¿›è¡ŒCV")
                if self.config.strict_validation:
                    return  # ä¸¥æ ¼æ¨¡å¼ä¸‹ç›´æ¥è¿”å›ç©º
        
        # è®¡ç®—æ¯æŠ˜çš„æµ‹è¯•ç»„æ•°é‡
        groups_per_fold = max(1, self.config.test_size // 20)  # å‡è®¾æ¯ç»„~20ä¸ªæ ·æœ¬
        
        valid_folds = 0
        for i in range(self.config.n_splits):
            # è®¡ç®—æµ‹è¯•ç»„çš„èµ·å§‹ä½ç½®
            test_start_idx = min(
                n_groups - groups_per_fold,
                int(n_groups * (i + 1) / (self.config.n_splits + 1))
            )
            test_end_idx = min(n_groups, test_start_idx + groups_per_fold)
            
            # âœ… FIX: V6å•ä¸€éš”ç¦»æ–¹æ³• - åªä½¿ç”¨gapï¼Œé¿å…åŒé‡éš”ç¦»
            # Gapå·²ç»åŒ…å«äº†æ‰€æœ‰éœ€è¦çš„éš”ç¦»æœŸé—´
            # Embargoè®¾ä¸º0ä»¥é¿å…ä¸Enhanced Temporal Validationé‡å¤
            total_buffer = self.config.gap  # V6: ä½¿ç”¨å•ä¸€gapï¼Œä¸å†å åŠ embargo
            train_end_idx = max(0, test_start_idx - total_buffer)
            
            logger.debug(f"ç¬¬{i+1}æŠ˜: ä½¿ç”¨å•ä¸€éš”ç¦»gap={self.config.gap}å¤©ï¼Œé¿å…åŒé‡éš”ç¦»")
            
            # ã€ä¿®å¤3ã€‘ä¸¥æ ¼æ£€æŸ¥æœ€å°è®­ç»ƒé›†è¦æ±‚
            if self.config.strict_validation:
                if train_end_idx < (self.config.min_train_size // 20):  # è½¬æ¢ä¸ºç»„æ•°
                    logger.warning(f"ç¬¬{i+1}æŠ˜è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                    continue
            else:
                # éä¸¥æ ¼æ¨¡å¼ä¸‹çš„æœ€ä½è¦æ±‚
                min_train_groups = max(2, n_groups // 10)
                if train_end_idx < min_train_groups:
                    logger.warning(f"ç¬¬{i+1}æŠ˜è®­ç»ƒæ•°æ®è¿‡å°‘ï¼Œè·³è¿‡")
                    continue
            
            # é€‰æ‹©è®­ç»ƒå’Œæµ‹è¯•ç»„
            train_groups = unique_groups[:train_end_idx]
            test_groups = unique_groups[test_start_idx:test_end_idx]
            
            if not train_groups or not test_groups:
                continue
            
            # è½¬æ¢ä¸ºç´¢å¼•
            train_mask = groups.isin(train_groups)
            test_mask = groups.isin(test_groups)
            
            train_indices = data_index[train_mask].tolist()
            test_indices = data_index[test_mask].tolist()
            
            if len(train_indices) == 0 or len(test_indices) == 0:
                continue
            
            # ã€ä¿®å¤4ã€‘ä¸¥æ ¼éªŒè¯æ—¶é—´é¡ºåº
            if hasattr(groups, 'dtype') and 'datetime' in str(groups.dtype):
                train_max_date = groups[train_mask].max()
                test_min_date = groups[test_mask].min()
                time_gap_days = int((test_min_date - train_max_date) / pd.Timedelta(days=1))
                
                required_gap = self.config.gap  # V6: åªéœ€è¦gapï¼Œä¸éœ€è¦embargo
                if time_gap_days < required_gap:
                    if self.config.strict_validation:
                        logger.error(f"ç¬¬{i+1}æŠ˜æ—¶é—´é—´éš”ä¸è¶³: {time_gap_days}å¤© < {required_gap}å¤©ï¼Œè·³è¿‡")
                        continue
                    else:
                        logger.warning(f"ç¬¬{i+1}æŠ˜æ—¶é—´é—´éš”ä¸è¶³: {time_gap_days}å¤© < {required_gap}å¤©")
                
                logger.info(f"ç¬¬{i+1}æŠ˜æ—¶é—´éªŒè¯é€šè¿‡: Gap={time_gap_days}å¤©")
            
            # ã€ä¿®å¤5ã€‘é¢å¤–çš„é‡å æ£€æŸ¥
            train_date_range = set(groups[train_mask])
            test_date_range = set(groups[test_mask])
            overlap = train_date_range & test_date_range
            
            if overlap:
                logger.error(f"ç¬¬{i+1}æŠ˜å‘ç°æ•°æ®é‡å : {len(overlap)}ä¸ªç»„")
                if self.config.strict_validation:
                    continue
            
            valid_folds += 1
            
            # ğŸ”¥ è¯¦ç»†çš„è®­ç»ƒ/éªŒè¯æ—¶é—´èŒƒå›´æ—¥å¿—
            train_start_date = train_groups[0]
            train_end_date = train_groups[-1]
            valid_start_date = test_groups[0]  
            valid_end_date = test_groups[-1]
            
            # è®¡ç®—å®é™…æ—¶é—´é—´éš”
            if hasattr(train_groups[0], 'strftime'):
                # datetimeç±»å‹
                train_start_str = train_start_date.strftime('%Y-%m-%d')
                train_end_str = train_end_date.strftime('%Y-%m-%d')
                valid_start_str = valid_start_date.strftime('%Y-%m-%d')
                valid_end_str = valid_end_date.strftime('%Y-%m-%d')
            else:
                # å…¶ä»–ç±»å‹
                train_start_str = str(train_start_date)
                train_end_str = str(train_end_date)
                valid_start_str = str(valid_start_date)
                valid_end_str = str(valid_end_date)
            
            logger.info(f"ç¬¬{valid_folds}æŠ˜: è®­ç»ƒ{len(train_indices)}æ ·æœ¬, æµ‹è¯•{len(test_indices)}æ ·æœ¬")
            logger.info(f"è®­ç»ƒæœŸé—´: {train_start_str} to {train_end_str}")
            logger.info(f"æµ‹è¯•æœŸé—´: {valid_start_str} to {valid_end_str}")
            logger.info(f"æ—¶é—´ç¼“å†²: {total_buffer}ç»„ (Gap:{self.config.gap} + Embargo:{self.config.embargo})")
            
            # ğŸ”¥ éªŒè¯æ— é‡å ï¼šç¡®ä¿ train_end < valid_start
            if hasattr(train_end_date, 'strftime') and hasattr(valid_start_date, 'strftime'):
                gap_days = int((valid_start_date - train_end_date) / pd.Timedelta(days=1))
                if gap_days < 0:
                    logger.error(f"ğŸš¨ ç¬¬{valid_folds}æŠ˜å‘ç°é‡å : train_end({train_end_str}) >= valid_start({valid_start_str})")
                else:
                    logger.info(f"âœ… ç¬¬{valid_folds}æŠ˜æ—¶é—´æ— é‡å : é—´éš”{gap_days}å¤©")
            
            # ğŸ”¥ éªŒè¯embargo>=æŒæœ‰æœŸ+1 (å‡è®¾æŒæœ‰æœŸH=1å¤©)
            H = 1  # æŒæœ‰æœŸ
            required_embargo = H + 1
            if self.config.embargo >= required_embargo:
                logger.info(f"âœ… EmbargoéªŒè¯é€šè¿‡: {self.config.embargo}å¤© >= {required_embargo}å¤©(H+1)")
            else:
                logger.warning(f"âš ï¸ Embargoä¸è¶³: {self.config.embargo}å¤© < {required_embargo}å¤©(H+1)")
            
            yield train_indices, test_indices
        
        if valid_folds == 0:
            logger.warning("æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„äº¤å‰éªŒè¯æŠ˜")
        else:
            logger.info(f"æˆåŠŸç”Ÿæˆ{valid_folds}ä¸ªæœ‰æ•ˆäº¤å‰éªŒè¯æŠ˜")

    def get_n_splits(self, X=None, y=None, groups=None):
        """è¿”å›åˆ†å‰²æ•°é‡"""
        return self.config.n_splits


def create_time_groups(dates: pd.Series, freq: str = 'W') -> pd.Series:
    """åˆ›å»ºæ—¶é—´åˆ†ç»„ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    if not isinstance(dates, pd.Series):
        dates = pd.Series(dates)
    
    # ç¡®ä¿æ˜¯datetimeç±»å‹
    if not pd.api.types.is_datetime64_any_dtype(dates):
        try:
            dates = pd.to_datetime(dates)
        except Exception as e:
            logger.error(f"æ—¥æœŸè½¬æ¢å¤±è´¥: {e}")
            raise
    
    if freq == 'D':
        return dates.dt.date
    elif freq == 'W':
        # ä¿®å¤ï¼šä½¿ç”¨å‘¨çš„å¼€å§‹æ—¥æœŸè€ŒéPeriodå¯¹è±¡ï¼Œé¿å…ä¸Timedeltaçš„è¿ç®—é”™è¯¯
        return dates.dt.to_period('W').dt.start_time
    elif freq == '7D':
        # 7å¤©åˆ†ç»„ï¼šä½¿ç”¨æ¯å‘¨èµ·å§‹æ—¥æœŸä½œä¸ºåˆ†ç»„æ ‡è¯†
        # ä¿®å¤ï¼šä½¿ç”¨å‘¨çš„å¼€å§‹æ—¥æœŸè€ŒéPeriodå¯¹è±¡ï¼Œé¿å…ä¸Timedeltaçš„è¿ç®—é”™è¯¯
        return dates.dt.to_period('W').dt.start_time
    elif freq == 'M':
        return dates.dt.to_period('M')
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é¢‘ç‡: {freq}")


def validate_timesplit_integrity(cv_splitter, X, groups):
    """éªŒè¯æ—¶é—´åˆ†å‰²çš„å®Œæ•´æ€§"""
    logger.info("å¼€å§‹æ—¶é—´åˆ†å‰²å®Œæ•´æ€§éªŒè¯...")
    
    issues_found = []
    fold_count = 0
    
    for train_idx, test_idx in cv_splitter.split(X, groups=groups):
        fold_count += 1
        
        # æ£€æŸ¥é‡å 
        overlap = set(train_idx) & set(test_idx)
        if overlap:
            issues_found.append(f"ç¬¬{fold_count}æŠ˜: å‘ç°{len(overlap)}ä¸ªé‡å æ ·æœ¬")
        
        # æ£€æŸ¥æ—¶é—´é¡ºåº
        if hasattr(groups, 'iloc'):
            train_dates = groups.iloc[train_idx]
            test_dates = groups.iloc[test_idx]
            
            train_max = train_dates.max()
            test_min = test_dates.min()
            
            if train_max >= test_min:
                issues_found.append(f"ç¬¬{fold_count}æŠ˜: æ—¶é—´é¡ºåºé”™è¯¯ (è®­ç»ƒæœ€å¤§={train_max}, æµ‹è¯•æœ€å°={test_min})")
    
    if issues_found:
        logger.error(f"å‘ç°{len(issues_found)}ä¸ªé—®é¢˜:")
        for issue in issues_found:
            logger.error(f"  - {issue}")
        return False
    else:
        logger.info(f"æ—¶é—´åˆ†å‰²éªŒè¯é€šè¿‡ ({fold_count}æŠ˜)")
        return True


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import sys
    sys.path.append('.')
    
    logging.basicConfig(level=logging.INFO)
    
    print("=== ä¿®å¤çš„ Purged Time Series CV æµ‹è¯• ===")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    # np.random.seed removed
    n_samples = 1000
    dates = pd.date_range('2020-01-01', periods=n_samples, freq='D')
    X = pd.DataFrame(
        np.zeros(n_samples),
        columns=[f'feature_{i}' for i in range(5)],
        index=dates
    )
    
    # åˆ›å»ºæ—¶é—´ç»„
    groups = create_time_groups(dates, freq='7D')
    
    # æµ‹è¯•ä¸¥æ ¼æ¨¡å¼
    config_strict = ValidationConfig(
        n_splits=5,
        test_size=63,
        gap=5,
        embargo=2,
        strict_validation=True
    )
    
    cv_strict = FixedPurgedGroupTimeSeriesSplit(config_strict)
    print(f"\n=== ä¸¥æ ¼æ¨¡å¼æµ‹è¯• ===")
    print(f"æ•°æ®: {len(X)}æ ·æœ¬, {len(groups.unique())}ä¸ªæ—¶é—´ç»„")
    
    # éªŒè¯å®Œæ•´æ€§
    integrity_ok = validate_timesplit_integrity(cv_strict, X, groups)
    print(f"å®Œæ•´æ€§éªŒè¯: {'é€šè¿‡' if integrity_ok else 'å¤±è´¥'}")
    
    # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
    fold_count = 0
    for train_idx, test_idx in cv_strict.split(X, groups=groups):
        fold_count += 1
        print(f"ç¬¬{fold_count}æŠ˜: è®­ç»ƒ{len(train_idx)}æ ·æœ¬, æµ‹è¯•{len(test_idx)}æ ·æœ¬")
        if fold_count >= 3:  # åªæ˜¾ç¤ºå‰3æŠ˜
            break
    
    print("ä¿®å¤çš„æ—¶é—´åˆ†å‰²æµ‹è¯•å®Œæˆ")