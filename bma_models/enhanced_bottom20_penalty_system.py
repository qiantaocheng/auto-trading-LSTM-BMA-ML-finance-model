#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºåº•éƒ¨20%æƒ©ç½šç³»ç»Ÿ - ä½åˆå§‹æƒ©ç½šï¼ŒåŠ é€Ÿå¢é•¿
===============================================
ä¸“é—¨é’ˆå¯¹åº•éƒ¨20%è‚¡ç¥¨ï¼Œåˆå§‹æƒ©ç½šå¾ˆä½ï¼Œä½†å¢é€Ÿå¿«é€Ÿä¸Šå‡
é¿å…å¯¹æ‰€æœ‰è‚¡ç¥¨é€ æˆæŸå®³ï¼Œåªèšç„¦äºæœ€å·®çš„è‚¡ç¥¨
"""

import numpy as np
import pandas as pd
from typing import Optional, Dict, Any, Tuple
import logging

logger = logging.getLogger(__name__)


class EnhancedBottom20PenaltySystem:
    """
    å¢å¼ºåº•éƒ¨20%æƒ©ç½šç³»ç»Ÿ

    æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š
    1. åªå¯¹åº•éƒ¨20%è‚¡ç¥¨åº”ç”¨æƒ©ç½š
    2. åˆå§‹æƒ©ç½šéå¸¸ä½ï¼ˆæ¥è¿‘0ï¼‰
    3. éšç€æ’åä¸‹é™ï¼Œæƒ©ç½šåŠ é€Ÿå¢é•¿
    4. ä½¿ç”¨ä¸‰æ¬¡å‡½æ•°å®ç°ä½åˆå§‹+å¿«é€ŸåŠ é€Ÿ
    5. å¯¹æåº•éƒ¨ï¼ˆæœ€å·®5%ï¼‰è‚¡ç¥¨åº”ç”¨æœ€å¼ºæƒ©ç½š
    """

    def __init__(self,
                 penalty_threshold: float = 0.08,      # æƒ©ç½šé˜ˆå€¼ï¼šåº•éƒ¨8% (å¤§å¹…é™ä½)
                 initial_penalty_factor: float = 0.005, # åˆå§‹æƒ©ç½šå› å­ï¼šæ›´ä½
                 max_penalty: float = 0.08,            # æœ€å¤§æƒ©ç½šï¼š8% (é™ä½)
                 acceleration_power: float = 2.5,      # åŠ é€Ÿå› å­ï¼šæ›´æ¸©å’Œ
                 market_cap_weight: float = 0.4,       # å¸‚å€¼æƒé‡
                 liquidity_weight: float = 0.6,        # æµåŠ¨æ€§æƒé‡
                 extreme_bottom_boost: float = 1.3,    # æåº•éƒ¨é¢å¤–æƒ©ç½šå€æ•° (é™ä½)
                 illiq_lookback: int = 20):             # AmihudæŒ‡æ ‡å›çœ‹å¤©æ•°
        """
        åˆå§‹åŒ–å¢å¼ºåº•éƒ¨8%æƒ©ç½šç³»ç»Ÿ (å¤§å¹…ä¿æŠ¤å°ç›˜è‚¡)

        Args:
            penalty_threshold: å¼€å§‹æƒ©ç½šçš„é˜ˆå€¼ï¼ˆåº•éƒ¨8%ï¼Œå¤§å¹…é™ä½ï¼‰
            initial_penalty_factor: åˆå§‹æƒ©ç½šå› å­ï¼ˆåœ¨é˜ˆå€¼å¤„çš„æƒ©ç½šå¼ºåº¦ï¼Œå·²é™ä½ï¼‰
            max_penalty: æœ€å¤§æƒ©ç½šå¹…åº¦ï¼ˆæœ€åº•éƒ¨è‚¡ç¥¨çš„æƒ©ç½šï¼Œå·²é™ä½è‡³8%ï¼‰
            acceleration_power: æƒ©ç½šåŠ é€Ÿåº¦ï¼ˆå·²é™ä½è‡³2.5ï¼Œæ›´æ¸©å’Œï¼‰
            market_cap_weight: å¸‚å€¼æƒé‡
            liquidity_weight: æµåŠ¨æ€§æƒé‡
            extreme_bottom_boost: æåº•éƒ¨5%çš„é¢å¤–æƒ©ç½šå€æ•°ï¼ˆå·²é™ä½ï¼‰
            illiq_lookback: AmihudæŒ‡æ ‡å›çœ‹å¤©æ•°
        """
        self.penalty_threshold = penalty_threshold
        self.initial_penalty_factor = initial_penalty_factor
        self.max_penalty = max_penalty
        self.acceleration_power = acceleration_power
        self.market_cap_weight = market_cap_weight
        self.liquidity_weight = liquidity_weight
        self.extreme_bottom_boost = extreme_bottom_boost
        self.illiq_lookback = illiq_lookback

        # å½’ä¸€åŒ–æƒé‡
        total_weight = market_cap_weight + liquidity_weight
        self.market_cap_weight = market_cap_weight / total_weight
        self.liquidity_weight = liquidity_weight / total_weight

        logger.info(f"å¢å¼ºåº•éƒ¨8%æƒ©ç½šç³»ç»Ÿåˆå§‹åŒ– (ä¿æŠ¤å°ç›˜è‚¡):")
        logger.info(f"  æƒ©ç½šé˜ˆå€¼: åº•éƒ¨{penalty_threshold*100:.0f}%")
        logger.info(f"  åˆå§‹æƒ©ç½šå› å­: {initial_penalty_factor:.3f}")
        logger.info(f"  æœ€å¤§æƒ©ç½š: {max_penalty*100:.1f}%")
        logger.info(f"  åŠ é€Ÿåº¦: {acceleration_power:.1f}æ¬¡æ–¹")
        logger.info(f"  æƒé‡: å¸‚å€¼={self.market_cap_weight:.2f}, æµåŠ¨æ€§={self.liquidity_weight:.2f}")
        logger.info(f"  æåº•éƒ¨å¢å¼º: {extreme_bottom_boost:.1f}x")

    def calculate_amihud_score(self,
                              returns: pd.Series,
                              volumes: pd.Series,
                              prices: Optional[pd.Series] = None) -> pd.Series:
        """è®¡ç®—AmihudæµåŠ¨æ€§è¯„åˆ†"""
        try:
            # è®¡ç®—æˆäº¤é¢
            if prices is not None:
                dollar_volume = volumes * prices
            else:
                dollar_volume = volumes

            # é¿å…é™¤é›¶
            dollar_volume = dollar_volume.replace(0, np.nan)

            # è®¡ç®—AmihudéæµåŠ¨æ€§æŒ‡æ ‡
            price_impact = np.abs(returns) / (dollar_volume + 1e-10)
            price_impact = price_impact.replace([np.inf, -np.inf], np.nan)

            # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—ä¸­ä½æ•°
            if isinstance(price_impact.index, pd.MultiIndex) and 'ticker' in price_impact.index.names:
                amihud_illiq = price_impact.groupby(level='ticker').apply(
                    lambda x: x.tail(self.illiq_lookback).median()
                )
            else:
                amihud_illiq = pd.Series(price_impact.median(), index=returns.index)

            # è½¬æ¢ä¸ºæµåŠ¨æ€§è¯„åˆ†ï¼ˆåè½¬å¹¶å½’ä¸€åŒ–ï¼‰
            amihud_illiq = np.log1p(amihud_illiq * 1e6)
            liquidity_score = 1 / (1 + amihud_illiq)

            # å½’ä¸€åŒ–åˆ°[0, 1]
            min_score = liquidity_score.min()
            max_score = liquidity_score.max()
            if max_score > min_score:
                liquidity_score = (liquidity_score - min_score) / (max_score - min_score)

            return liquidity_score

        except Exception as e:
            logger.error(f"è®¡ç®—Amihudè¯„åˆ†å¤±è´¥: {e}")
            return pd.Series(0.5, index=returns.index.get_level_values('ticker').unique()
                          if isinstance(returns.index, pd.MultiIndex) else returns.index)

    def calculate_market_cap_score(self, market_caps: pd.Series) -> pd.Series:
        """è®¡ç®—å¸‚å€¼è¯„åˆ†"""
        market_caps = market_caps.clip(lower=1e6)
        log_caps = np.log(market_caps)

        min_cap = log_caps.min()
        max_cap = log_caps.max()
        if max_cap > min_cap:
            cap_score = (log_caps - min_cap) / (max_cap - min_cap)
        else:
            cap_score = pd.Series(0.5, index=market_caps.index)

        return cap_score

    def calculate_enhanced_penalty_amount(self, percentile: float) -> float:
        """
        è®¡ç®—å¢å¼ºæƒ©ç½šé‡ï¼šä½åˆå§‹ + å¿«é€ŸåŠ é€Ÿ

        Args:
            percentile: è‚¡ç¥¨çš„ç™¾åˆ†ä½ï¼ˆ0=æœ€å·®ï¼Œ1=æœ€å¥½ï¼‰

        Returns:
            æƒ©ç½šé‡ï¼ˆ0åˆ°max_penaltyä¹‹é—´ï¼‰
        """
        # åªå¯¹åº•éƒ¨8%åº”ç”¨æƒ©ç½š (å¤§å¹…ä¿æŠ¤å°ç›˜è‚¡)
        if percentile >= self.penalty_threshold:
            return 0.0

        # è®¡ç®—åœ¨æƒ©ç½šåŒºé—´å†…çš„ç›¸å¯¹ä½ç½®ï¼ˆ0=æœ€å·®ï¼Œ1=é˜ˆå€¼å¤„ï¼‰
        relative_pos = percentile / self.penalty_threshold

        # åè½¬ï¼špenalty_intensity = 0ï¼ˆé˜ˆå€¼å¤„ï¼‰åˆ° 1ï¼ˆæœ€å·®ï¼‰
        penalty_intensity = 1.0 - relative_pos

        # === æ–°çš„æƒ©ç½šå…¬å¼ï¼šä½åˆå§‹ + å¿«é€ŸåŠ é€Ÿ ===
        # ä½¿ç”¨æ”¹è¿›çš„å¤šé˜¶æ®µå‡½æ•°

        # é˜¶æ®µ1ï¼šåœ¨é˜ˆå€¼å¤„ï¼ˆpenalty_intensity = 0ï¼‰ï¼Œæƒ©ç½šä¸ºåˆå§‹å› å­
        # é˜¶æ®µ2ï¼šéšç€penalty_intensityå¢åŠ ï¼Œæƒ©ç½šæŒ‰åŠ é€Ÿåº¦å¢é•¿

        # åŸºç¡€æƒ©ç½šï¼šä¸‰æ¬¡å‡½æ•°å®ç°ä½å¼€å§‹+å¿«é€Ÿå¢é•¿
        base_penalty = (self.initial_penalty_factor +
                       (1 - self.initial_penalty_factor) * (penalty_intensity ** self.acceleration_power))

        # æåº•éƒ¨å¢å¼ºï¼šå¯¹æœ€å·®5%è‚¡ç¥¨é¢å¤–æƒ©ç½š
        if percentile < 0.05:  # æœ€å·®5%
            extreme_factor = self.extreme_bottom_boost
            # åœ¨æœ€å·®5%å†…éƒ¨ï¼Œæƒ©ç½šæ›´å¿«å¢é•¿
            extreme_intensity = (0.05 - percentile) / 0.05
            extreme_penalty = extreme_factor * (extreme_intensity ** 2)
            base_penalty += extreme_penalty * 0.3  # é¢å¤–30%æƒ©ç½š
        elif percentile < 0.10:  # æ¬¡å·®5%ï¼ˆ5%-10%ï¼‰
            # è½»å¾®å¢å¼º
            mild_factor = 1.2
            base_penalty *= mild_factor

        # åº”ç”¨æœ€å¤§æƒ©ç½šé™åˆ¶
        final_penalty = min(base_penalty * self.max_penalty, self.max_penalty)

        return final_penalty

    def apply_enhanced_bottom8_penalty(self,
                                      predictions: pd.Series,
                                      feature_data: pd.DataFrame) -> Tuple[pd.Series, Dict[str, Any]]:
        """
        åº”ç”¨å¢å¼ºåº•éƒ¨8%æƒ©ç½šç³»ç»Ÿ (å¤§å¹…ä¿æŠ¤å°ç›˜è‚¡)
        """
        try:
            if predictions is None or len(predictions) == 0:
                return predictions, {}

            adjusted = predictions.copy()
            diagnostics = {
                'total_stocks': len(predictions),
                'penalized_stocks': 0,
                'avg_penalty': 0,
                'max_penalty_applied': 0,
                'min_penalty_applied': 0,
                'bottom_5_penalty': 0,
                'bottom_10_penalty': 0,
                'bottom_20_penalty': 0,
                'threshold_penalty': 0,
                'acceleration_effect': 0,
                'missing_features': [],
                'feature_availability': {}
            }

            # Check feature availability
            required_features = ['market_cap', 'Volume', 'Close', 'returns']
            available_features = []
            for feature in required_features:
                if feature in feature_data.columns:
                    available_features.append(feature)
                    diagnostics['feature_availability'][feature] = True
                else:
                    diagnostics['missing_features'].append(feature)
                    diagnostics['feature_availability'][feature] = False

            if len(available_features) == 0:
                logger.warning("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¿…éœ€çš„ç‰¹å¾æ•°æ®ï¼Œæ— æ³•è®¡ç®—æƒ©ç½š")
                logger.warning(f"  éœ€è¦çš„ç‰¹å¾: {required_features}")
                logger.warning(f"  å¯ç”¨çš„åˆ—: {list(feature_data.columns)[:10]}")
                return predictions, diagnostics

            # === 1. è®¡ç®—ç»¼åˆè¯„åˆ† ===
            composite_scores = pd.Series(0.5, index=predictions.index)

            # å¸‚å€¼è¯„åˆ†
            if 'market_cap' in feature_data.columns:
                market_caps = feature_data['market_cap'].reindex(predictions.index)
                cap_scores = self.calculate_market_cap_score(market_caps.fillna(market_caps.median()))

                for ticker in predictions.index.get_level_values('ticker').unique():
                    ticker_mask = predictions.index.get_level_values('ticker') == ticker
                    if ticker in cap_scores.index:
                        composite_scores[ticker_mask] += self.market_cap_weight * cap_scores[ticker]
            else:
                # ä½¿ç”¨ä»·æ ¼Ã—æˆäº¤é‡ä¼°ç®—
                if 'Close' in feature_data.columns and 'Volume' in feature_data.columns:
                    estimated_caps = feature_data['Close'] * feature_data['Volume'] * 1000
                    cap_scores = self.calculate_market_cap_score(estimated_caps.reindex(predictions.index).fillna(estimated_caps.median()))
                    composite_scores += self.market_cap_weight * cap_scores

            # æµåŠ¨æ€§è¯„åˆ†
            if 'returns' in feature_data.columns and 'Volume' in feature_data.columns:
                returns = feature_data['returns'].reindex(predictions.index)
                volumes = feature_data['Volume'].reindex(predictions.index)
                prices = feature_data.get('Close', pd.Series()).reindex(predictions.index)

                liquidity_scores = self.calculate_amihud_score(returns, volumes, prices)

                for ticker in predictions.index.get_level_values('ticker').unique():
                    ticker_mask = predictions.index.get_level_values('ticker') == ticker
                    if ticker in liquidity_scores.index:
                        composite_scores[ticker_mask] += self.liquidity_weight * liquidity_scores[ticker]

            # === 2. æŒ‰æ—¥æœŸè®¡ç®—ç™¾åˆ†ä½å¹¶åº”ç”¨å¢å¼ºæƒ©ç½š ===
            penalties = pd.Series(0.0, index=predictions.index, dtype=float)

            for date in predictions.index.get_level_values('date').unique():
                date_mask = predictions.index.get_level_values('date') == date
                date_scores = composite_scores[date_mask]

                # è®¡ç®—ç™¾åˆ†ä½
                percentiles = date_scores.rank(pct=True)

                # åº”ç”¨å¢å¼ºæƒ©ç½š
                for idx, percentile in percentiles.items():
                    penalty = self.calculate_enhanced_penalty_amount(percentile)
                    penalties.loc[idx] = penalty

            # === 3. åº”ç”¨æƒ©ç½šåˆ°é¢„æµ‹ ===
            adjusted = predictions - penalties

            # === 4. è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ ===
            penalized_mask = penalties > 0.001
            diagnostics['penalized_stocks'] = penalized_mask.sum()
            diagnostics['penalized_ratio'] = penalized_mask.mean()

            if penalized_mask.any():
                diagnostics['avg_penalty'] = penalties[penalized_mask].mean()
                diagnostics['max_penalty_applied'] = penalties.max()
                diagnostics['min_penalty_applied'] = penalties[penalized_mask].min()

            # åˆ†å±‚ç»Ÿè®¡ (è°ƒæ•´ä¸º8%é˜ˆå€¼)
            bottom_5_mask = composite_scores <= composite_scores.quantile(0.05)
            bottom_8_mask = composite_scores <= composite_scores.quantile(0.08)
            bottom_10_mask = composite_scores <= composite_scores.quantile(0.10)
            threshold_mask = (composite_scores > composite_scores.quantile(0.07)) & (composite_scores <= composite_scores.quantile(0.08))

            diagnostics['bottom_5_penalty'] = penalties[bottom_5_mask].mean() if bottom_5_mask.any() else 0
            diagnostics['bottom_8_penalty'] = penalties[bottom_8_mask].mean() if bottom_8_mask.any() else 0
            diagnostics['bottom_10_penalty'] = penalties[bottom_10_mask].mean() if bottom_10_mask.any() else 0
            diagnostics['threshold_penalty'] = penalties[threshold_mask].mean() if threshold_mask.any() else 0

            # åŠ é€Ÿæ•ˆæœç»Ÿè®¡
            if diagnostics['bottom_5_penalty'] > 0 and diagnostics['threshold_penalty'] > 0:
                diagnostics['acceleration_effect'] = diagnostics['bottom_5_penalty'] / max(diagnostics['threshold_penalty'], 0.001)

            # è¾“å‡ºæ—¥å¿—
            logger.info("=" * 80)
            logger.info("å¢å¼ºåº•éƒ¨8%æƒ©ç½šç³»ç»Ÿåº”ç”¨å®Œæˆ (å¤§å¹…ä¿æŠ¤å°ç›˜è‚¡):")
            logger.info(f"  æ€»è‚¡ç¥¨æ•°: {diagnostics['total_stocks']}")
            logger.info(f"  å—æƒ©ç½šè‚¡ç¥¨: {diagnostics['penalized_stocks']} ({diagnostics['penalized_ratio']*100:.1f}%)")
            logger.info(f"  å¹³å‡æƒ©ç½š: {diagnostics['avg_penalty']*100:.2f}%")
            logger.info(f"  æœ€å¤§æƒ©ç½š: {diagnostics['max_penalty_applied']*100:.2f}%")
            logger.info(f"  æœ€å°æƒ©ç½š: {diagnostics['min_penalty_applied']*100:.4f}%")
            logger.info("")
            logger.info("åˆ†å±‚æƒ©ç½šç»Ÿè®¡ (ä½“ç°ä½åˆå§‹+å¿«é€ŸåŠ é€Ÿ):")
            logger.info(f"  8%é˜ˆå€¼å¤„æƒ©ç½š: {diagnostics['threshold_penalty']*100:.4f}% (æä½åˆå§‹)")
            logger.info(f"  åº•éƒ¨8%å¹³å‡: {diagnostics['bottom_8_penalty']*100:.2f}%")
            logger.info(f"  åº•éƒ¨5%å¹³å‡: {diagnostics['bottom_5_penalty']*100:.2f}% (å¿«é€ŸåŠ é€Ÿ)")
            logger.info(f"  åŠ é€Ÿå€æ•°: {diagnostics['acceleration_effect']:.1f}x")
            logger.info("")
            logger.info("é¢„æµ‹è°ƒæ•´æ•ˆæœ:")
            logger.info(f"  è°ƒæ•´å‰å‡å€¼: {predictions.mean():.4f}")
            logger.info(f"  è°ƒæ•´åå‡å€¼: {adjusted.mean():.4f}")
            logger.info(f"  ç›¸å…³æ€§: {predictions.corr(adjusted):.4f}")
            logger.info(f"  åªå½±å“åº•éƒ¨8%ï¼Œä¿æŠ¤92%è‚¡ç¥¨ä¸å—æŸå®³")
            logger.info("=" * 80)

            return adjusted, diagnostics

        except Exception as e:
            logger.error(f"å¢å¼ºåº•éƒ¨8%æƒ©ç½šç³»ç»Ÿåº”ç”¨å¤±è´¥: {e}")
            return predictions, {}


def test_enhanced_penalty_curves():
    """æµ‹è¯•å¢å¼ºæƒ©ç½šæ›²çº¿æ•ˆæœ"""
    import matplotlib.pyplot as plt

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    percentiles = np.linspace(0, 0.25, 1000)  # åªæµ‹è¯•åº•éƒ¨25%

    # åˆ›å»ºä¸åŒé…ç½®çš„æƒ©ç½šç³»ç»Ÿ
    configs = [
        ('New Default (Reduced Penalty)', 0.005, 2.5),
        ('Very Low Initial, Ultra Fast', 0.005, 4.0),
        ('Medium Initial, Normal Speed', 0.03, 2.0)
    ]

    plt.figure(figsize=(15, 10))

    # ä¸»å›¾ï¼šæƒ©ç½šæ›²çº¿å¯¹æ¯”
    plt.subplot(2, 2, 1)

    for name, initial, power in configs:
        penalty_system = EnhancedBottom20PenaltySystem(
            initial_penalty_factor=initial,
            acceleration_power=power,
            max_penalty=0.08
        )

        penalties = [penalty_system.calculate_enhanced_penalty_amount(p) for p in percentiles]
        plt.plot(percentiles * 100, np.array(penalties) * 100, label=name, linewidth=2)

    plt.axvline(x=20, color='red', linestyle='--', alpha=0.5, label='Penalty Threshold (20%)')
    plt.axvline(x=5, color='orange', linestyle='--', alpha=0.3, label='Extreme Bottom (5%)')
    plt.axvline(x=10, color='orange', linestyle=':', alpha=0.3, label='Very Bottom (10%)')

    plt.xlabel('Stock Percentile (%)')
    plt.ylabel('Penalty Amount (%)')
    plt.title('Enhanced Bottom 20% Penalty Curves')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xlim(0, 25)

    # å±€éƒ¨å›¾ï¼šåº•éƒ¨5%ç»†èŠ‚
    plt.subplot(2, 2, 2)

    bottom_percentiles = np.linspace(0, 0.05, 200)
    for name, initial, power in configs:
        penalty_system = EnhancedBottom20PenaltySystem(
            initial_penalty_factor=initial,
            acceleration_power=power,
            max_penalty=0.08
        )

        penalties = [penalty_system.calculate_enhanced_penalty_amount(p) for p in bottom_percentiles]
        plt.plot(bottom_percentiles * 100, np.array(penalties) * 100, label=name, linewidth=2)

    plt.xlabel('Stock Percentile (%)')
    plt.ylabel('Penalty Amount (%)')
    plt.title('Bottom 5% Detail (Extreme Penalty Zone)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xlim(0, 5)

    # åŠ é€Ÿåº¦åˆ†æ
    plt.subplot(2, 2, 3)

    # è®¡ç®—ä¸åŒåŒºé—´çš„æƒ©ç½šå¢é•¿ç‡
    intervals = ['0-1%', '1-5%', '5-10%', '10-15%', '15-20%']

    for name, initial, power in configs:
        penalty_system = EnhancedBottom20PenaltySystem(
            initial_penalty_factor=initial,
            acceleration_power=power,
            max_penalty=0.08
        )

        growth_rates = []
        test_points = [0.005, 0.03, 0.075, 0.125, 0.175]  # å„åŒºé—´ä¸­ç‚¹

        for i, point in enumerate(test_points):
            current_penalty = penalty_system.calculate_enhanced_penalty_amount(point)
            if i == 0:
                growth_rate = current_penalty / 0.001  # ç›¸å¯¹äºæå°å€¼çš„å¢é•¿
            else:
                prev_penalty = penalty_system.calculate_enhanced_penalty_amount(test_points[i-1])
                growth_rate = (current_penalty - prev_penalty) / prev_penalty if prev_penalty > 0 else 0
            growth_rates.append(growth_rate)

        plt.plot(intervals, growth_rates, marker='o', label=name, linewidth=2)

    plt.xlabel('Percentile Intervals')
    plt.ylabel('Penalty Growth Rate')
    plt.title('Penalty Acceleration by Interval')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(rotation=45)

    # å¯¹æ¯”è¡¨æ ¼
    plt.subplot(2, 2, 4)
    plt.axis('off')

    # åˆ›å»ºå¯¹æ¯”æ•°æ®
    comparison_data = []
    test_percentiles = [0.20, 0.15, 0.10, 0.05, 0.01]  # 20%, 15%, 10%, 5%, 1%

    for name, initial, power in configs:
        penalty_system = EnhancedBottom20PenaltySystem(
            initial_penalty_factor=initial,
            acceleration_power=power,
            max_penalty=0.08
        )

        penalties = [penalty_system.calculate_enhanced_penalty_amount(p) for p in test_percentiles]
        comparison_data.append([name] + [f'{p*100:.3f}%' for p in penalties])

    # åˆ›å»ºè¡¨æ ¼
    headers = ['System', '20%', '15%', '10%', '5%', '1%']

    table_text = []
    table_text.append(' | '.join(f'{h:^12}' for h in headers))
    table_text.append('-' * (13 * len(headers) + len(headers) - 1))

    for row in comparison_data:
        table_text.append(' | '.join(f'{cell:^12}' for cell in row))

    plt.text(0.1, 0.8, '\n'.join(table_text), fontfamily='monospace', fontsize=9,
             verticalalignment='top', transform=plt.gca().transAxes)

    plt.title('Penalty Comparison Table', pad=20)

    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    output_path = 'D:/trade/enhanced_bottom20_penalty_curves.png'
    plt.savefig(output_path, dpi=100, bbox_inches='tight')
    print(f"å¢å¼ºæƒ©ç½šæ›²çº¿å›¾å·²ä¿å­˜: {output_path}")

    # éªŒè¯å…³é”®ç‰¹æ€§
    print("\n" + "=" * 80)
    print("ğŸ¯ å¢å¼ºæƒ©ç½šç³»ç»Ÿå…³é”®ç‰¹æ€§éªŒè¯")
    print("=" * 80)

    optimal_system = EnhancedBottom20PenaltySystem(
        initial_penalty_factor=0.005,
        acceleration_power=2.5,
        max_penalty=0.08
    )

    # éªŒè¯ä½åˆå§‹æƒ©ç½š
    threshold_penalty = optimal_system.calculate_enhanced_penalty_amount(0.20)
    print(f"âœ… ä½åˆå§‹æƒ©ç½š: 20%é˜ˆå€¼å¤„æƒ©ç½š = {threshold_penalty*100:.4f}%")

    # éªŒè¯å¿«é€ŸåŠ é€Ÿ
    bottom5_penalty = optimal_system.calculate_enhanced_penalty_amount(0.05)
    bottom1_penalty = optimal_system.calculate_enhanced_penalty_amount(0.01)

    acceleration_5 = bottom5_penalty / max(threshold_penalty, 0.001)
    acceleration_1 = bottom1_penalty / max(threshold_penalty, 0.001)

    print(f"âœ… å¿«é€ŸåŠ é€Ÿæ•ˆæœ:")
    print(f"   - åº•éƒ¨5%ç›¸å¯¹é˜ˆå€¼: {acceleration_5:.1f}x")
    print(f"   - åº•éƒ¨1%ç›¸å¯¹é˜ˆå€¼: {acceleration_1:.1f}x")

    # éªŒè¯ä¿æŠ¤80%è‚¡ç¥¨
    protected_penalty = optimal_system.calculate_enhanced_penalty_amount(0.25)  # 25%å¤„
    print(f"âœ… ä¿æŠ¤80%è‚¡ç¥¨: 25%å¤„æƒ©ç½š = {protected_penalty*100:.4f}% (åº”ä¸º0)")

    print(f"âœ… ç³»ç»Ÿç¬¦åˆè®¾è®¡è¦æ±‚ï¼šä½åˆå§‹ + å¿«é€ŸåŠ é€Ÿ + ä¿æŠ¤80%")


if __name__ == "__main__":
    test_enhanced_penalty_curves()