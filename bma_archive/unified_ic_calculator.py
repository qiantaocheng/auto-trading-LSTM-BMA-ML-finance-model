#!/usr/bin/env python3
"""
ç»Ÿä¸€IC/RankICè®¡ç®—å™¨ - æ¨ªæˆªé¢-æ—¶é—´ä¸¤é˜¶æ®µæ ‡å‡†å®ç°
===========================================================
ä¿®å¤çºµå‘æ—¶é—´åºåˆ—ç›¸å…³æ€§è¢«è¯¯åˆ¤ä¸ºé€‰è‚¡åŠ›çš„é—®é¢˜
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
import logging
from scipy import stats
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

@dataclass
class ICCalculationConfig:
    """ICè®¡ç®—é…ç½®"""
    # è®¡ç®—æ–¹æ³•é…ç½®
    use_rank_ic: bool = True                   # ä¼˜å…ˆä½¿ç”¨RankICï¼ˆSpearmanï¼‰
    use_pearson_ic: bool = False               # å¯é€‰Pearson IC
    
    # æ—¶é—´èšåˆé…ç½®
    temporal_aggregation: str = "mean"         # æ—¶é—´èšåˆæ–¹æ³•: mean, ewm, median
    decay_halflife: int = 30                   # æŒ‡æ•°åŠ æƒåŠè¡°æœŸ(å¤©)
    min_cross_sectional_samples: int = 5      # æ¨ªæˆªé¢æœ€å°‘æ ·æœ¬æ•°(è‡ªé€‚åº”)
    
    # æ»šåŠ¨çª—å£é…ç½®
    ic_lookback_days: int = 252                # ICè®¡ç®—å›æœ›å¤©æ•°
    rolling_window: bool = True                # æ˜¯å¦ä½¿ç”¨æ»šåŠ¨çª—å£
    min_temporal_samples: int = 30             # æ—¶é—´ç»´åº¦æœ€å°‘æ ·æœ¬æ•°(è‡ªé€‚åº”)
    adaptive_min_samples: bool = True          # å¯ç”¨è‡ªé€‚åº”æ ·æœ¬æ•°
    
    # è´¨é‡æ§åˆ¶
    outlier_method: str = "winsorize"          # å¼‚å¸¸å€¼å¤„ç†ï¼šwinsorize/clip/none
    winsorize_limits: Tuple[float, float] = (0.01, 0.99)  # Winsorizeé™åˆ¶
    handle_missing: str = "drop"               # ç¼ºå¤±å€¼å¤„ç†ï¼šdrop/fill/ignore
    
    # ç¨³å¥æ€§é…ç½®
    bootstrap_samples: int = 0                 # Bootstrapæ ·æœ¬æ•°ï¼ˆ0=ä¸ä½¿ç”¨ï¼‰
    confidence_level: float = 0.95             # ç½®ä¿¡åŒºé—´
    stability_threshold: float = 0.6           # ICç¨³å®šæ€§é˜ˆå€¼

class UnifiedICCalculator:
    """ç»Ÿä¸€ICè®¡ç®—å™¨ - æœºæ„çº§æ ‡å‡†å®ç°"""
    
    def __init__(self, config: ICCalculationConfig = None):
        """åˆå§‹åŒ–ICè®¡ç®—å™¨"""
        self.config = config or ICCalculationConfig()
        self.cache = {}  # ç¼“å­˜å†å²è®¡ç®—ç»“æœ
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'cross_sectional_calculations': 0,
            'temporal_aggregations': 0,
            'cache_hits': 0,
            'invalid_dates': 0,
            'insufficient_samples': 0
        }
        
        logger.info(f"ç»Ÿä¸€ICè®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ - æ¨ªæˆªé¢->æ—¶é—´ä¸¤é˜¶æ®µæ–¹æ³•")
    
    def calculate_cross_sectional_ic(self, factors: pd.Series, returns: pd.Series,
                                   method: str = "spearman") -> float:
        """
        è®¡ç®—å•æ—¥æ¨ªæˆªé¢IC
        
        Args:
            factors: å› å­å€¼åºåˆ—(åŒæ—¥ä¸åŒæ ‡çš„)
            returns: å¯¹åº”çš„å‰å‘æ”¶ç›Šåºåˆ—
            method: è®¡ç®—æ–¹æ³• spearman/pearson
            
        Returns:
            æ¨ªæˆªé¢ICå€¼
        """
        if len(factors) != len(returns):
            return np.nan
            
        # å¯¹é½éç©ºå€¼
        valid_mask = ~(factors.isna() | returns.isna() | 
                      np.isinf(factors) | np.isinf(returns))
        
        # è‡ªé€‚åº”æ¨ªæˆªé¢æ ·æœ¬æ•°æ£€æŸ¥
        valid_samples = valid_mask.sum()
        effective_min_cross_samples = self.config.min_cross_sectional_samples
        
        # è‡ªé€‚åº”é™ä½è¦æ±‚
        if valid_samples >= 5:
            effective_min_cross_samples = 5
        elif valid_samples >= 3:
            effective_min_cross_samples = 3  # æœ€ä½è¦æ±‚3ä¸ªæ ·æœ¬
            
        if valid_samples < effective_min_cross_samples:
            self.stats['insufficient_samples'] += 1
            return np.nan
        
        factors_clean = factors[valid_mask]
        returns_clean = returns[valid_mask]
        
        # å¼‚å¸¸å€¼å¤„ç†
        if self.config.outlier_method == "winsorize":
            factors_clean = self._winsorize_series(factors_clean)
            returns_clean = self._winsorize_series(returns_clean)
        elif self.config.outlier_method == "clip":
            factors_clean = factors_clean.clip(
                factors_clean.quantile(0.01), 
                factors_clean.quantile(0.99)
            )
            returns_clean = returns_clean.clip(
                returns_clean.quantile(0.01),
                returns_clean.quantile(0.99)
            )
        
        try:
            if method.lower() == "spearman":
                ic_value, p_value = stats.spearmanr(factors_clean, returns_clean)
            elif method.lower() == "pearson":
                ic_value, p_value = stats.pearsonr(factors_clean, returns_clean)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")
            
            self.stats['cross_sectional_calculations'] += 1
            # ğŸ”§ ä¿®å¤: NaNå’Œ0.0å«ä¹‰ä¸åŒï¼ŒNaNè¡¨ç¤ºæ— æ³•è®¡ç®—ï¼Œ0.0è¡¨ç¤ºé›¶ç›¸å…³
            return ic_value if not np.isnan(ic_value) else np.nan
            
        except Exception as e:
            logger.debug(f"æ¨ªæˆªé¢ICè®¡ç®—å¤±è´¥: {e}")
            return np.nan
    
    def calculate_temporal_ic_series(self, factor_data: pd.DataFrame, 
                                   return_data: pd.DataFrame,
                                   factor_name: str) -> pd.Series:
        """
        è®¡ç®—æ—¶é—´åºåˆ—ICï¼ˆé€æ—¥æ¨ªæˆªé¢->æ—¶é—´èšåˆï¼‰
        
        Args:
            factor_data: å› å­æ•°æ® (index=date, columns=tickers)
            return_data: æ”¶ç›Šæ•°æ® (index=date, columns=tickers)  
            factor_name: å› å­åç§°
            
        Returns:
            æ—¶é—´åºåˆ—IC
        """
        # å¯¹é½æ—¶é—´ç´¢å¼•
        common_dates = factor_data.index.intersection(return_data.index)
        
        # è‡ªé€‚åº”æ ·æœ¬æ•°è°ƒæ•´ (ğŸ”§ ä¿®å¤ï¼šæé«˜æœ€ä½é˜ˆå€¼ç¡®ä¿ç»Ÿè®¡æ˜¾è‘—æ€§)
        effective_min_samples = self.config.min_temporal_samples
        if self.config.adaptive_min_samples:
            if len(common_dates) >= 30:
                effective_min_samples = 30  # ç†æƒ³30å¤©
            elif len(common_dates) >= 25:
                effective_min_samples = 25  # é™çº§åˆ°25å¤©
            elif len(common_dates) >= 20:
                effective_min_samples = 20  # æœ€ä½20å¤©ï¼ˆä¿®å¤ï¼šä»10å¤©æé«˜åˆ°20å¤©ï¼‰
                logger.warning(f"ä½¿ç”¨æœ€ä½æ ·æœ¬æ•°é˜ˆå€¼: {len(common_dates)}å¤©ï¼Œç»Ÿè®¡å¯é æ€§å¯èƒ½é™ä½")
        
        if len(common_dates) < effective_min_samples:
            logger.warning(f"æ—¶é—´æ ·æœ¬ä¸¥é‡ä¸è¶³: {len(common_dates)} < {effective_min_samples}")
            self.stats['insufficient_samples'] += 1
            return pd.Series(dtype=float)
        
        if len(common_dates) < self.config.min_temporal_samples:
            logger.info(f"ä½¿ç”¨è‡ªé€‚åº”æ ·æœ¬æ•°: {len(common_dates)} (æ ‡å‡†:{self.config.min_temporal_samples})")
        
        # æŒ‰æ—¶é—´æ’åº
        common_dates = sorted(common_dates)
        
        daily_ics = []
        valid_dates = []
        
        for date in common_dates:
            try:
                # è·å–å½“æ—¥æ¨ªæˆªé¢æ•°æ®
                factors_cross = factor_data.loc[date]
                returns_cross = return_data.loc[date]
                
                # è®¡ç®—æ¨ªæˆªé¢IC
                method = "spearman" if self.config.use_rank_ic else "pearson"
                daily_ic = self.calculate_cross_sectional_ic(
                    factors_cross, returns_cross, method
                )
                
                if not np.isnan(daily_ic):
                    daily_ics.append(daily_ic)
                    valid_dates.append(date)
                else:
                    self.stats['invalid_dates'] += 1
                    
            except Exception as e:
                logger.debug(f"æ—¥æœŸ {date} ICè®¡ç®—å¤±è´¥: {e}")
                self.stats['invalid_dates'] += 1
                continue
        
        if not daily_ics:
            return pd.Series(dtype=float)
        
        ic_series = pd.Series(daily_ics, index=valid_dates)
        return ic_series
    
    def aggregate_temporal_ic(self, ic_series: pd.Series) -> Dict[str, float]:
        """
        æ—¶é—´ç»´åº¦ICèšåˆç»Ÿè®¡
        
        Args:
            ic_series: æ—¥åº¦ICåºåˆ—
            
        Returns:
            ICç»Ÿè®¡æŒ‡æ ‡å­—å…¸
        """
        if ic_series.empty:
            return self._get_empty_ic_stats()
        
        # åŸºç¡€ç»Ÿè®¡
        mean_ic = ic_series.mean()
        std_ic = ic_series.std()
        
        # ICä¿¡æ¯æ¯”ç‡
        ir = mean_ic / std_ic if std_ic > 0 else 0.0
        
        # æ­£ICå æ¯”
        hit_rate = (ic_series > 0).mean()
        
        # ICç¨³å®šæ€§ï¼ˆç»å¯¹å€¼ICçš„å‡å€¼ï¼‰
        ic_stability = ic_series.abs().mean()
        
        # æ—¶é—´è¡°å‡åŠ æƒIC
        if self.config.temporal_aggregation == "ewm":
            ewm_ic = ic_series.ewm(halflife=self.config.decay_halflife).mean().iloc[-1]
        else:
            ewm_ic = mean_ic
        
        # ICåˆ†å¸ƒç»Ÿè®¡
        ic_quantiles = ic_series.quantile([0.1, 0.25, 0.5, 0.75, 0.9])
        
        self.stats['temporal_aggregations'] += 1
        
        return {
            'ic_mean': float(mean_ic),
            'ic_std': float(std_ic),
            'ic_ir': float(ir),
            'ic_hit_rate': float(hit_rate),
            'ic_stability': float(ic_stability),
            'ic_ewm': float(ewm_ic),
            'ic_sharpe': float(ir * np.sqrt(252)),  # å¹´åŒ–ICå¤æ™®
            'ic_count': len(ic_series),
            'ic_q10': float(ic_quantiles[0.1]),
            'ic_q25': float(ic_quantiles[0.25]),
            'ic_median': float(ic_quantiles[0.5]),
            'ic_q75': float(ic_quantiles[0.75]),
            'ic_q90': float(ic_quantiles[0.9]),
            'ic_skew': float(ic_series.skew()),
            'ic_kurt': float(ic_series.kurtosis())
        }
    
    def calculate_factor_ic_comprehensive(self, factor_data: pd.DataFrame,
                                        return_data: pd.DataFrame,
                                        factor_name: str) -> Dict[str, Any]:
        """
        å…¨é¢è®¡ç®—å› å­ICæŒ‡æ ‡ï¼ˆä¸»æ¥å£ï¼‰
        
        Args:
            factor_data: å› å­æ•°æ®
            return_data: æ”¶ç›Šæ•°æ®  
            factor_name: å› å­åç§°
            
        Returns:
            å®Œæ•´ICåˆ†æç»“æœ
        """
        cache_key = f"{factor_name}_{hash(str(factor_data.shape))}"
        if cache_key in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        # æ­¥éª¤1: è®¡ç®—æ—¥åº¦æ¨ªæˆªé¢ICåºåˆ—
        ic_series = self.calculate_temporal_ic_series(
            factor_data, return_data, factor_name
        )
        
        if ic_series.empty:
            logger.warning(f"å› å­ {factor_name} ICè®¡ç®—å¤±è´¥ - æ— æœ‰æ•ˆæ•°æ®")
            return self._get_empty_comprehensive_result(factor_name)
        
        # æ­¥éª¤2: æ—¶é—´èšåˆç»Ÿè®¡
        ic_stats = self.aggregate_temporal_ic(ic_series)
        
        # æ­¥éª¤3: æ»šåŠ¨çª—å£ICï¼ˆå¦‚æœå¯ç”¨ï¼‰
        rolling_ic_stats = {}
        if self.config.rolling_window and len(ic_series) >= self.config.ic_lookback_days:
            rolling_ic = ic_series.rolling(self.config.ic_lookback_days).apply(
                lambda x: x.mean() if len(x) >= 30 else np.nan
            )
            rolling_ic_stats = {
                'rolling_ic_mean': float(rolling_ic.mean()),
                'rolling_ic_std': float(rolling_ic.std()),
                'rolling_ic_last': float(rolling_ic.iloc[-1]) if not rolling_ic.empty else np.nan
            }
        
        # æ­¥éª¤4: Bootstrapç½®ä¿¡åŒºé—´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        bootstrap_stats = {}
        if self.config.bootstrap_samples > 0:
            bootstrap_ics = self._bootstrap_ic(ic_series, self.config.bootstrap_samples)
            alpha = 1 - self.config.confidence_level
            bootstrap_stats = {
                'ic_bootstrap_mean': float(np.mean(bootstrap_ics)),
                'ic_confidence_lower': float(np.percentile(bootstrap_ics, 100*alpha/2)),
                'ic_confidence_upper': float(np.percentile(bootstrap_ics, 100*(1-alpha/2))),
                'ic_bootstrap_std': float(np.std(bootstrap_ics))
            }
        
        # ç»¼åˆç»“æœ
        comprehensive_result = {
            'factor_name': factor_name,
            'calculation_method': 'cross_sectional_temporal_aggregation',
            'ic_stats': ic_stats,
            'rolling_stats': rolling_ic_stats,
            'bootstrap_stats': bootstrap_stats,
            'ic_series': ic_series,  # åŸå§‹æ—¥åº¦ICåºåˆ—
            'data_quality': {
                'total_dates': len(factor_data.index),
                'valid_ic_dates': len(ic_series),
                'coverage_rate': len(ic_series) / len(factor_data.index) if len(factor_data.index) > 0 else 0,
                'avg_cross_sectional_samples': factor_data.count(axis=1).mean()
            },
            'timestamp': datetime.now().isoformat(),
            'config': self.config.__dict__
        }
        
        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = comprehensive_result
        
        logger.info(f"å› å­ {factor_name} ICè®¡ç®—å®Œæˆ: IC={ic_stats['ic_mean']:.4f}, "
                   f"IR={ic_stats['ic_ir']:.4f}, ç¨³å®šæ€§={ic_stats['ic_stability']:.4f}")
        
        return comprehensive_result
    
    def calculate_multi_factor_ic_matrix(self, factor_data_dict: Dict[str, pd.DataFrame],
                                       return_data: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—å¤šå› å­ICçŸ©é˜µ
        
        Args:
            factor_data_dict: å¤šä¸ªå› å­æ•°æ®å­—å…¸
            return_data: æ”¶ç›Šæ•°æ®
            
        Returns:
            å› å­ICçŸ©é˜µ (rows=factors, cols=ic_metrics)
        """
        ic_matrix_data = []
        
        for factor_name, factor_data in factor_data_dict.items():
            ic_result = self.calculate_factor_ic_comprehensive(
                factor_data, return_data, factor_name
            )
            
            # æå–å…³é”®æŒ‡æ ‡
            ic_stats = ic_result['ic_stats']
            row_data = {
                'factor_name': factor_name,
                'ic_mean': ic_stats['ic_mean'],
                'ic_std': ic_stats['ic_std'],
                'ic_ir': ic_stats['ic_ir'],
                'ic_hit_rate': ic_stats['ic_hit_rate'],
                'ic_stability': ic_stats['ic_stability'],
                'ic_sharpe_annual': ic_stats['ic_sharpe'],
                'valid_dates': ic_result['data_quality']['valid_ic_dates'],
                'coverage_rate': ic_result['data_quality']['coverage_rate']
            }
            ic_matrix_data.append(row_data)
        
        ic_matrix_df = pd.DataFrame(ic_matrix_data)
        ic_matrix_df = ic_matrix_df.set_index('factor_name')
        
        logger.info(f"å¤šå› å­ICçŸ©é˜µè®¡ç®—å®Œæˆ: {len(factor_data_dict)} ä¸ªå› å­")
        return ic_matrix_df
    
    def _winsorize_series(self, series: pd.Series) -> pd.Series:
        """Winsorizeåºåˆ—"""
        lower_limit, upper_limit = self.config.winsorize_limits
        lower_val = series.quantile(lower_limit)
        upper_val = series.quantile(upper_limit)
        return series.clip(lower_val, upper_val)
    
    def _bootstrap_ic(self, ic_series: pd.Series, n_bootstrap: int) -> List[float]:
        """Bootstrapé‡é‡‡æ ·IC"""
        bootstrap_ics = []
        for _ in range(n_bootstrap):
            sample_ic = ic_series.sample(len(ic_series), replace=True)
            bootstrap_ics.append(sample_ic.mean())
        return bootstrap_ics
    
    def _get_empty_ic_stats(self) -> Dict[str, float]:
        """è·å–ç©ºICç»Ÿè®¡"""
        return {
            'ic_mean': 0.0, 'ic_std': 0.0, 'ic_ir': 0.0, 'ic_hit_rate': 0.0,
            'ic_stability': 0.0, 'ic_ewm': 0.0, 'ic_sharpe': 0.0, 'ic_count': 0,
            'ic_q10': 0.0, 'ic_q25': 0.0, 'ic_median': 0.0, 'ic_q75': 0.0, 'ic_q90': 0.0,
            'ic_skew': 0.0, 'ic_kurt': 0.0
        }
    
    def _get_empty_comprehensive_result(self, factor_name: str) -> Dict[str, Any]:
        """è·å–ç©ºçš„ç»¼åˆç»“æœ"""
        return {
            'factor_name': factor_name,
            'calculation_method': 'cross_sectional_temporal_aggregation',
            'ic_stats': self._get_empty_ic_stats(),
            'rolling_stats': {},
            'bootstrap_stats': {},
            'ic_series': pd.Series(dtype=float),
            'data_quality': {
                'total_dates': 0,
                'valid_ic_dates': 0,
                'coverage_rate': 0.0,
                'avg_cross_sectional_samples': 0.0
            },
            'timestamp': datetime.now().isoformat(),
            'config': self.config.__dict__
        }
    
    def get_calculation_stats(self) -> Dict[str, Any]:
        """è·å–è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'stats': self.stats,
            'cache_size': len(self.cache),
            'config': self.config.__dict__,
            'calculation_summary': {
                'cross_sectional_rate': (
                    self.stats['cross_sectional_calculations'] / 
                    max(1, self.stats['cross_sectional_calculations'] + self.stats['invalid_dates'])
                ),
                'temporal_aggregation_count': self.stats['temporal_aggregations'],
                'cache_hit_rate': (
                    self.stats['cache_hits'] / 
                    max(1, self.stats['cache_hits'] + self.stats['temporal_aggregations'])
                )
            }
        }

# å…¨å±€ICè®¡ç®—å™¨å®ä¾‹
GLOBAL_IC_CALCULATOR = UnifiedICCalculator()

def get_global_ic_calculator() -> UnifiedICCalculator:
    """è·å–å…¨å±€ICè®¡ç®—å™¨"""
    return GLOBAL_IC_CALCULATOR

if __name__ == "__main__":
    # æµ‹è¯•ICè®¡ç®—å™¨
    calculator = UnifiedICCalculator()
    
    # æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•
    dates = pd.date_range('2023-01-01', periods=100, freq='D')
    tickers = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']
    
    # åˆ›å»ºæ¨¡æ‹Ÿå› å­å’Œæ”¶ç›Šæ•°æ®
    # np.random.seed removed
    factor_data = pd.DataFrame(
        np.zeros(100), index=dates, columns=tickers
    )
    return_data = pd.DataFrame(
        np.zeros(100) * 0.02, index=dates, columns=tickers
    )
    
    # æµ‹è¯•å•å› å­ICè®¡ç®—
    result = calculator.calculate_factor_ic_comprehensive(
        factor_data, return_data, 'test_factor'
    )
    
    print("=== æ¨ªæˆªé¢-æ—¶é—´ä¸¤é˜¶æ®µICè®¡ç®—æµ‹è¯• ===")
    print(f"ICå‡å€¼: {result['ic_stats']['ic_mean']:.4f}")
    print(f"IC IR: {result['ic_stats']['ic_ir']:.4f}")
    print(f"ICç¨³å®šæ€§: {result['ic_stats']['ic_stability']:.4f}")
    print(f"æœ‰æ•ˆæ—¥æœŸæ•°: {result['data_quality']['valid_ic_dates']}")
    print(f"è¦†ç›–ç‡: {result['data_quality']['coverage_rate']:.2%}")