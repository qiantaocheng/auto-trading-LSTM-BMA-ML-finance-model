#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨ - æ›¿ä»£å¤æ‚çš„å¤šè®­ç»ƒå¤´ç³»ç»Ÿ
å•ä¸€æ¥å£åè°ƒæ‰€æœ‰MLè®­ç»ƒï¼Œç¡®ä¿SSOTåŸåˆ™
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any, Callable
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class UnifiedTrainingCoordinator:
    """
    ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨ - å•ä¸€çœŸç›¸æº
    
    èŒè´£ï¼š
    1. åè°ƒæ‰€æœ‰MLè®­ç»ƒå¤´ï¼ˆTraditional ML, Learning-to-Rankç­‰ï¼‰
    2. ç¡®ä¿ç»Ÿä¸€ä½¿ç”¨RobustFeatureSelectorå’ŒUnifiedCVFactory  
    3. ç»Ÿä¸€OOFé¢„æµ‹ç”Ÿæˆå’Œå¯¹é½
    4. é˜²æ­¢è®­ç»ƒå¤´ä¹‹é—´çš„å†²çªå’Œé‡å¤
    """
    
    def __init__(self, cv_factory: Callable):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨
        
        Args:
            cv_factory: ç»Ÿä¸€CVå·¥å‚
        """
        self.cv_factory = cv_factory
        self.training_results = {}
        self.unified_oof_results = {}
        
        logger.info("âœ… ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def coordinate_all_training(self, 
                               X: pd.DataFrame,
                               y: pd.Series, 
                               dates: pd.Series,
                               tickers: Optional[pd.Series] = None) -> Dict[str, Any]:
        """
        åè°ƒæ‰€æœ‰è®­ç»ƒå¤´çš„è®­ç»ƒè¿‡ç¨‹
        
        Args:
            X: å·²é€šè¿‡RobustFeatureSelectorçš„ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            dates: æ—¥æœŸåºåˆ—
            tickers: è‚¡ç¥¨ä»£ç ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç»Ÿä¸€çš„è®­ç»ƒç»“æœ
        """
        logger.info("ğŸš€ å¯åŠ¨ç»Ÿä¸€è®­ç»ƒåè°ƒ...")
        logger.info(f"è¾“å…¥æ•°æ®: {len(X)} æ ·æœ¬, {len(X.columns)} ç‰¹å¾")
        
        coordinated_results = {
            'training_heads': {},
            'unified_oof_matrix': None,
            'final_ensemble': None,
            'coordination_metadata': {
                'coordinator_version': '1.0',
                'training_timestamp': datetime.now().isoformat(),
                'data_fingerprint': {
                    'samples': len(X),
                    'features': len(X.columns),
                    'feature_names': list(X.columns),
                    'date_range': f"{dates.min()} to {dates.max()}"
                }
            }
        }
        
        # 1. ä¼ ç»ŸMLè®­ç»ƒå¤´
        logger.info("ğŸ¯ è®­ç»ƒå¤´1: Traditional ML")
        traditional_result = self._train_traditional_ml_head(X, y, dates, tickers)
        coordinated_results['training_heads']['traditional_ml'] = traditional_result
        
        # 2. Learning-to-Rankè®­ç»ƒå¤´ï¼ˆç®€åŒ–ç‰ˆï¼‰
        logger.info("ğŸ¯ è®­ç»ƒå¤´2: Learning-to-Rank (ç®€åŒ–)")
        ltr_result = self._train_learning_to_rank_head(X, y, dates, tickers)
        coordinated_results['training_heads']['learning_to_rank'] = ltr_result
        
        # 3. ç»Ÿä¸€OOFçŸ©é˜µç”Ÿæˆ
        logger.info("ğŸ”„ ç”Ÿæˆç»Ÿä¸€OOFçŸ©é˜µ...")
        unified_oof_matrix = self._create_unified_oof_matrix(coordinated_results['training_heads'])
        coordinated_results['unified_oof_matrix'] = unified_oof_matrix
        
        # 4. æœ€ç»ˆé›†æˆ
        logger.info("ğŸ† ç”Ÿæˆæœ€ç»ˆé›†æˆé¢„æµ‹...")
        final_ensemble = self._create_final_ensemble(unified_oof_matrix, y)
        coordinated_results['final_ensemble'] = final_ensemble
        
        logger.info("âœ… ç»Ÿä¸€è®­ç»ƒåè°ƒå®Œæˆ")
        
        return coordinated_results
    
    def _train_traditional_ml_head(self, X: pd.DataFrame, y: pd.Series, 
                                 dates: pd.Series, tickers: pd.Series) -> Dict[str, Any]:
        """è®­ç»ƒä¼ ç»ŸMLå¤´"""
        try:
            from .traditional_ml_head import TraditionalMLHead
            
            # åˆ›å»ºä¼ ç»ŸMLè®­ç»ƒå™¨
            trainer = TraditionalMLHead(enable_hyperparam_opt=True)
            
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£è®­ç»ƒ
            result = trainer.fit(X, y, dates, tickers or pd.Series(['DUMMY'] * len(X)), self.cv_factory)
            
            logger.info(f"ä¼ ç»ŸMLè®­ç»ƒå®Œæˆ: {len(result.get('models', {}))} ä¸ªæ¨¡å‹")
            
            return {
                'success': True,
                'models': result.get('models', {}),
                'oof_predictions': result.get('oof', pd.Series()),
                'metadata': result.get('metadata', {}),
                'training_head_id': 'traditional_ml'
            }
            
        except Exception as e:
            logger.error(f"ä¼ ç»ŸMLè®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'training_head_id': 'traditional_ml'
            }
    
    def _train_learning_to_rank_head(self, X: pd.DataFrame, y: pd.Series,
                                   dates: pd.Series, tickers: pd.Series) -> Dict[str, Any]:
        """è®­ç»ƒLearning-to-Rankå¤´ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            from .unified_oof_generator import generate_unified_oof
            from sklearn.ensemble import RandomForestRegressor
            
            # åˆ›å»ºç®€åŒ–çš„æ’åºæ¨¡å‹
            ranking_models = {
                'rf_ranker': RandomForestRegressor(n_estimators=100, random_state=42),
                'simple_ranker': RandomForestRegressor(n_estimators=50, random_state=42)
            }
            
            # ç”Ÿæˆç»Ÿä¸€OOFé¢„æµ‹
            unified_result = generate_unified_oof(
                X=X, y=y, dates=dates,
                models=ranking_models,
                training_head_id='learning_to_rank',
                cv_factory=self.cv_factory
            )
            
            # é€‰æ‹©æœ€ä½³é¢„æµ‹
            oof_results = unified_result['oof_results']
            if oof_results:
                best_model = max(oof_results.keys(), key=lambda k: oof_results[k]['oof_ic'])
                primary_oof = oof_results[best_model]['oof_predictions']
                best_ic = oof_results[best_model]['oof_ic']
            else:
                primary_oof = pd.Series(index=X.index, dtype=float).fillna(0.0)
                best_ic = 0.0
            
            logger.info(f"Learning-to-Rankè®­ç»ƒå®Œæˆ: æœ€ä½³IC={best_ic:.4f}")
            
            return {
                'success': True,
                'models': ranking_models,
                'oof_predictions': primary_oof,
                'unified_oof_result': unified_result,
                'best_ic': best_ic,
                'training_head_id': 'learning_to_rank'
            }
            
        except Exception as e:
            logger.error(f"Learning-to-Rankè®­ç»ƒå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'training_head_id': 'learning_to_rank'
            }
    
    def _create_unified_oof_matrix(self, training_heads: Dict[str, Any]) -> pd.DataFrame:
        """åˆ›å»ºç»Ÿä¸€çš„OOFé¢„æµ‹çŸ©é˜µ"""
        oof_predictions = []
        
        for head_name, head_result in training_heads.items():
            if head_result.get('success', False) and 'oof_predictions' in head_result:
                oof_pred = head_result['oof_predictions']
                if isinstance(oof_pred, pd.Series):
                    oof_pred.name = f"{head_name}_oof"
                    oof_predictions.append(oof_pred)
        
        if not oof_predictions:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„OOFé¢„æµ‹")
            return pd.DataFrame()
        
        # å¯¹é½é¢„æµ‹çŸ©é˜µ
        unified_matrix = pd.concat(oof_predictions, axis=1)
        
        logger.info(f"ç»Ÿä¸€OOFçŸ©é˜µ: {unified_matrix.shape}")
        
        return unified_matrix
    
    def _create_final_ensemble(self, oof_matrix: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:
        """åˆ›å»ºæœ€ç»ˆé›†æˆé¢„æµ‹"""
        if oof_matrix.empty:
            logger.warning("OOFçŸ©é˜µä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºé›†æˆ")
            return {
                'ensemble_prediction': pd.Series(index=y.index, dtype=float).fillna(0.0),
                'ensemble_weights': {},
                'ensemble_ic': 0.0
            }
        
        try:
            # è®¡ç®—å„é¢„æµ‹çš„ICæƒé‡
            from scipy.stats import spearmanr
            
            weights = {}
            total_ic = 0
            
            for col in oof_matrix.columns:
                valid_mask = ~(oof_matrix[col].isna() | y.isna())
                if valid_mask.sum() > 10:  # è‡³å°‘10ä¸ªæœ‰æ•ˆæ ·æœ¬
                    ic = spearmanr(y[valid_mask], oof_matrix[col][valid_mask])[0]
                    ic = max(ic, 0.01)  # æœ€å°æƒé‡
                    weights[col] = ic
                    total_ic += ic
                else:
                    weights[col] = 0.01
            
            # å½’ä¸€åŒ–æƒé‡
            if total_ic > 0:
                weights = {k: v/total_ic for k, v in weights.items()}
            else:
                equal_weight = 1.0 / len(oof_matrix.columns)
                weights = {k: equal_weight for k in oof_matrix.columns}
            
            # ç”ŸæˆåŠ æƒé›†æˆé¢„æµ‹
            ensemble_pred = pd.Series(index=oof_matrix.index, dtype=float).fillna(0.0)
            
            for col, weight in weights.items():
                pred_values = oof_matrix[col].fillna(0.0)
                ensemble_pred += weight * pred_values
            
            # è®¡ç®—é›†æˆIC
            valid_mask = ~(ensemble_pred.isna() | y.isna())
            if valid_mask.sum() > 10:
                ensemble_ic = spearmanr(y[valid_mask], ensemble_pred[valid_mask])[0]
            else:
                ensemble_ic = 0.0
            
            logger.info(f"æœ€ç»ˆé›†æˆIC: {ensemble_ic:.4f}")
            
            return {
                'ensemble_prediction': ensemble_pred,
                'ensemble_weights': weights,
                'ensemble_ic': ensemble_ic,
                'component_count': len(weights)
            }
            
        except Exception as e:
            logger.error(f"é›†æˆåˆ›å»ºå¤±è´¥: {e}")
            return {
                'ensemble_prediction': pd.Series(index=y.index, dtype=float).fillna(0.0),
                'ensemble_weights': {},
                'ensemble_ic': 0.0
            }
    
    def get_coordination_report(self) -> Dict[str, Any]:
        """è·å–åè°ƒæŠ¥å‘Š"""
        return {
            'coordinator_status': 'active',
            'training_results_count': len(self.training_results),
            'unified_oof_count': len(self.unified_oof_results),
            'cv_factory_type': type(self.cv_factory).__name__
        }


# å…¨å±€ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨
_global_coordinator = None

def get_unified_training_coordinator(cv_factory: Callable = None) -> UnifiedTrainingCoordinator:
    """è·å–å…¨å±€ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨"""
    global _global_coordinator
    
    if _global_coordinator is None:
        if cv_factory is None:
            from .unified_cv_factory import get_unified_cv_factory
            factory = get_unified_cv_factory()
            cv_factory = factory.create_cv_factory()
        
        _global_coordinator = UnifiedTrainingCoordinator(cv_factory)
    
    return _global_coordinator

def coordinate_unified_training(X: pd.DataFrame, 
                              y: pd.Series,
                              dates: pd.Series, 
                              tickers: Optional[pd.Series] = None,
                              cv_factory: Callable = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåè°ƒç»Ÿä¸€è®­ç»ƒ
    """
    coordinator = get_unified_training_coordinator(cv_factory)
    return coordinator.coordinate_all_training(X, y, dates, tickers)


if __name__ == "__main__":
    # æµ‹è¯•ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    dates = pd.date_range('2020-01-01', periods=200, freq='D')
    X = pd.DataFrame(np.random.randn(200, 8), columns=[f'feature_{i}' for i in range(8)])
    y = pd.Series(np.random.randn(200), name='target')
    tickers = pd.Series(['AAPL'] * 100 + ['MSFT'] * 100, name='ticker')
    
    print("æµ‹è¯•ç»Ÿä¸€è®­ç»ƒåè°ƒå™¨")
    
    # åè°ƒè®­ç»ƒ
    result = coordinate_unified_training(X, y, dates, tickers)
    
    print(f"åè°ƒç»“æœ: {list(result.keys())}")
    print(f"è®­ç»ƒå¤´æ•°é‡: {len(result['training_heads'])}")
    if result['final_ensemble']:
        print(f"æœ€ç»ˆé›†æˆIC: {result['final_ensemble']['ensemble_ic']:.4f}")