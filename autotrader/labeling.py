"""
Triple-Barrier + Meta-Label + OOF Isotonic æ ‡ç­¾å·¥ç¨‹
==================================================

å®Œå…¨æ›¿æ¢æ—§æ ‡ç­¾äº§çº¿ï¼Œè¾“å‡ºæ ¡å‡†åçš„expected_alpha_bpså’Œconfidence
ä¸‹æ¸¸ibkr_auto_trader.plan_and_place_with_rr()æ— éœ€ä¿®æ”¹
"""

import numpy as np
import pandas as pd
from sklearn.isotonic import IsotonicRegression
# ğŸš« å·²åˆ é™¤TimeSeriesSplitå¯¼å…¥ - ä½¿ç”¨ç»Ÿä¸€CVå·¥å‚
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
import logging
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import warnings

logger = logging.getLogger(__name__)

class TripleBarrierLabeling:
    """ä¸‰é‡éšœç¢æ ‡ç­¾ç”Ÿæˆå™¨"""
    
    def __init__(self, tp_sigma: float = 2.0, sl_sigma: float = 2.0, 
                 max_holding_days: int = 5, min_ret_threshold: float = 0.0001):
        self.tp_sigma = tp_sigma          # æ­¢ç›ˆå€æ•°
        self.sl_sigma = sl_sigma          # æ­¢æŸå€æ•°  
        self.max_holding_days = max_holding_days  # æœ€å¤§æŒæœ‰æœŸ
        self.min_ret_threshold = min_ret_threshold  # æœ€å°æ”¶ç›Šé˜ˆå€¼
        
    def compute_daily_volatility(self, adj_close: pd.Series, lookback: int = 20) -> pd.Series:
        """è®¡ç®—æ¯æ—¥æ³¢åŠ¨ç‡"""
        returns = adj_close.pct_change()
        return returns.rolling(window=lookback, min_periods=10).std()
        
    def triple_barrier(self, adj_close: pd.Series, vol: pd.Series, 
                      base_signal: Optional[pd.Series] = None) -> pd.DataFrame:
        """
        ä¸‰é‡éšœç¢æ ‡ç­¾ç”Ÿæˆ
        
        Args:
            adj_close: å¤æƒæ”¶ç›˜ä»·åºåˆ—
            vol: æ—¥æ³¢åŠ¨ç‡åºåˆ—
            base_signal: åŸºç¡€ä¿¡å·æ–¹å‘(+1/-1/0)ï¼Œå¯é€‰
            
        Returns:
            DataFrame with columns: ['event_end', 'actual_ret', 'label_dir', 'barrier_type']
        """
        results = []
        
        for i in range(len(adj_close) - self.max_holding_days):
            t_start = adj_close.index[i]
            px_start = adj_close.iloc[i]
            vol_t = vol.iloc[i]
            
            if pd.isna(px_start) or pd.isna(vol_t) or vol_t <= 0:
                continue
                
            # è®¾ç½®éšœç¢
            tp_threshold = self.tp_sigma * vol_t  # æ­¢ç›ˆé˜ˆå€¼
            sl_threshold = -self.sl_sigma * vol_t  # æ­¢æŸé˜ˆå€¼
            
            # å¯»æ‰¾é¦–æ¬¡è§¦å‘çš„éšœç¢
            event_end = None
            actual_ret = 0.0
            barrier_type = 'time'  # é»˜è®¤æ—¶é—´åˆ°æœŸ
            
            for j in range(1, min(self.max_holding_days + 1, len(adj_close) - i)):
                t_current = adj_close.index[i + j]
                px_current = adj_close.iloc[i + j]
                
                if pd.isna(px_current):
                    continue
                    
                ret = (px_current - px_start) / px_start
                
                # æ£€æŸ¥æ­¢ç›ˆ
                if ret >= tp_threshold:
                    event_end = t_current
                    actual_ret = ret
                    barrier_type = 'tp'
                    break
                    
                # æ£€æŸ¥æ­¢æŸ
                if ret <= sl_threshold:
                    event_end = t_current  
                    actual_ret = ret
                    barrier_type = 'sl'
                    break
            
            # å¦‚æœæ²¡æœ‰è§¦å‘ï¼Œä½¿ç”¨æ—¶é—´åˆ°æœŸ
            if event_end is None:
                end_idx = min(i + self.max_holding_days, len(adj_close) - 1)
                event_end = adj_close.index[end_idx]
                px_end = adj_close.iloc[end_idx]
                if not pd.isna(px_end):
                    actual_ret = (px_end - px_start) / px_start
                    
            # ç”Ÿæˆæ–¹å‘æ ‡ç­¾
            if abs(actual_ret) < self.min_ret_threshold:
                label_dir = 0  # æ— æ˜¾è‘—æ”¶ç›Š
            elif actual_ret > 0:
                label_dir = 1  # ä¸Šæ¶¨
            else:
                label_dir = -1  # ä¸‹è·Œ
                
            # å¦‚æœæœ‰åŸºç¡€ä¿¡å·ï¼Œè€ƒè™‘ä¿¡å·æ–¹å‘
            if base_signal is not None and not pd.isna(base_signal.iloc[i]):
                signal_dir = base_signal.iloc[i]
                # åªæœ‰ä¿¡å·æ–¹å‘ä¸å®é™…æ–¹å‘ä¸€è‡´æ—¶æ‰æ ‡è®°ä¸ºæ­£ç¡®
                if signal_dir != 0 and np.sign(signal_dir) != np.sign(actual_ret):
                    label_dir = 0  # æ–¹å‘é”™è¯¯
                    
            results.append({
                'start_date': t_start,
                'event_end': event_end,
                'actual_ret': actual_ret,
                'label_dir': label_dir,
                'barrier_type': barrier_type,
                'vol_used': vol_t
            })
            
        return pd.DataFrame(results).set_index('start_date')

class MetaLabelGenerator:
    """Meta-Labelç”Ÿæˆå™¨ - "è¯¥ä¸è¯¥æ‰§è¡Œ"çš„äºŒåˆ†ç±»"""
    
    def __init__(self, min_ret_for_exec: float = 0.0005):
        self.min_ret_for_exec = min_ret_for_exec
        
    def make_meta_label(self, base_signal: pd.Series, barrier_labels: pd.DataFrame,
                       strategy_type: str = 'directional') -> pd.Series:
        """
        ç”ŸæˆMeta-Label
        
        Args:
            base_signal: åŸºç¡€ä¿¡å·å¼ºåº¦/æ–¹å‘
            barrier_labels: ä¸‰é‡éšœç¢æ ‡ç­¾ç»“æœ
            strategy_type: ç­–ç•¥ç±»å‹ ('directional', 'mean_reverting', 'momentum')
            
        Returns:
            Series: 1è¡¨ç¤ºåº”è¯¥æ‰§è¡Œï¼Œ0è¡¨ç¤ºä¸åº”è¯¥æ‰§è¡Œ
        """
        meta_labels = pd.Series(0, index=base_signal.index, name='meta_label')
        
        for date in barrier_labels.index:
            if date not in base_signal.index:
                continue
                
            signal = base_signal.loc[date]
            barrier_info = barrier_labels.loc[date]
            
            actual_ret = barrier_info['actual_ret']
            label_dir = barrier_info['label_dir']
            
            # åŸºæœ¬æ¡ä»¶ï¼šæœ‰æ˜¾è‘—ä¿¡å·
            if pd.isna(signal) or abs(signal) < 0.001:
                continue
                
            should_execute = False
            
            if strategy_type == 'directional':
                # æ–¹å‘æ€§ç­–ç•¥ï¼šä¿¡å·æ–¹å‘ä¸å®é™…æ”¶ç›Šæ–¹å‘ä¸€è‡´ä¸”æ”¶ç›Šè¶³å¤Ÿ
                if (np.sign(signal) == np.sign(actual_ret) and 
                    abs(actual_ret) >= self.min_ret_for_exec):
                    should_execute = True
                    
            elif strategy_type == 'mean_reverting':
                # å‡å€¼å›å½’ï¼šä¿¡å·ä¸å®é™…æ”¶ç›Šåå‘ä¸”æ”¶ç›Šè¶³å¤Ÿ
                if (np.sign(signal) == -np.sign(actual_ret) and 
                    abs(actual_ret) >= self.min_ret_for_exec):
                    should_execute = True
                    
            elif strategy_type == 'momentum':
                # åŠ¨é‡ç­–ç•¥ï¼šè€ƒè™‘ä¿¡å·å¼ºåº¦ä¸æ”¶ç›Šå¹…åº¦
                signal_strength = abs(signal)
                if (np.sign(signal) == np.sign(actual_ret) and 
                    actual_ret * signal_strength > self.min_ret_for_exec):
                    should_execute = True
                    
            meta_labels.loc[date] = 1 if should_execute else 0
            
        return meta_labels

class OOFIsotonicCalibrator:
    """OOF Isotonicæ ¡å‡†å™¨ - ä»…ç”¨OOFæ•°æ®æ‹Ÿåˆ"""
    
    def __init__(self, n_splits: int = 5, test_size_days: int = 63):
        self.n_splits = n_splits
        self.test_size_days = test_size_days
        self.iso_meta = IsotonicRegression(out_of_bounds='clip')
        self.iso_ret = IsotonicRegression(out_of_bounds='clip') 
        self.oof_metrics = {}
        
    def time_series_oof_split(self, X: pd.DataFrame, gap_days: int = 2) -> List[Tuple]:
        """æ—¶é—´åºåˆ—OOFåˆ†å‰²"""
        dates = X.index.get_level_values(0).unique().sort_values()
        
        splits = []
        total_days = len(dates)
        fold_size = total_days // self.n_splits
        
        for i in range(self.n_splits):
            test_start_idx = i * fold_size
            test_end_idx = min((i + 1) * fold_size, total_days)
            
            # è®­ç»ƒé›†ï¼šæµ‹è¯•é›†ä¹‹å‰çš„æ•°æ®ï¼Œç•™gapé¿å…æ³„éœ²
            train_end_idx = max(0, test_start_idx - gap_days)
            
            if train_end_idx > 0:
                train_dates = dates[:train_end_idx]
                test_dates = dates[test_start_idx:test_end_idx]
                
                train_mask = X.index.get_level_values(0).isin(train_dates)
                test_mask = X.index.get_level_values(0).isin(test_dates)
                
                splits.append((train_mask, test_mask))
                
        return splits
        
    def fit_and_calibrate(self, X: pd.DataFrame, y_ret: pd.Series, y_meta: pd.Series,
                         base_model_ret=None, base_model_meta=None) -> Dict:
        """
        OOFè®­ç»ƒå’Œæ ¡å‡†
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ (MultiIndex: date, symbol)
            y_ret: æ”¶ç›Šç›®æ ‡
            y_meta: Meta-Labelç›®æ ‡
            base_model_ret: æ”¶ç›Šé¢„æµ‹æ¨¡å‹
            base_model_meta: Meta-Labelåˆ†ç±»æ¨¡å‹
            
        Returns:
            Dict: æ ¡å‡†ç»“æœå’ŒOOFé¢„æµ‹
        """
        if base_model_ret is None:
            base_model_ret = LinearRegression()
        if base_model_meta is None:
            base_model_meta = RandomForestClassifier(
                n_estimators=100, max_depth=5, random_state=42
            )
            
        # å¯¹é½æ•°æ®
        common_idx = X.index.intersection(y_ret.index).intersection(y_meta.index)
        X_aligned = X.loc[common_idx]
        y_ret_aligned = y_ret.loc[common_idx]
        y_meta_aligned = y_meta.loc[common_idx]
        
        # å­˜å‚¨OOFé¢„æµ‹
        oof_ret_pred = pd.Series(np.nan, index=common_idx)
        oof_meta_pred = pd.Series(np.nan, index=common_idx)
        
        splits = self.time_series_oof_split(X_aligned)
        
        logger.info(f"å¼€å§‹OOFè®­ç»ƒï¼Œ{len(splits)}ä¸ªfold")
        
        for fold_idx, (train_mask, test_mask) in enumerate(splits):
            try:
                X_train, X_test = X_aligned[train_mask], X_aligned[test_mask]
                y_ret_train, y_ret_test = y_ret_aligned[train_mask], y_ret_aligned[test_mask]
                y_meta_train, y_meta_test = y_meta_aligned[train_mask], y_meta_aligned[test_mask]
                
                # ç§»é™¤NaN
                valid_train = ~(pd.isna(y_ret_train) | pd.isna(y_meta_train))
                valid_test = ~(pd.isna(y_ret_test) | pd.isna(y_meta_test))
                
                if valid_train.sum() < 10 or valid_test.sum() < 5:
                    continue
                    
                X_train_clean = X_train[valid_train].fillna(0)
                X_test_clean = X_test[valid_test].fillna(0)
                
                # è®­ç»ƒæ”¶ç›Šæ¨¡å‹
                base_model_ret.fit(X_train_clean, y_ret_train[valid_train])
                ret_pred = base_model_ret.predict(X_test_clean)
                oof_ret_pred[y_ret_test[valid_test].index] = ret_pred
                
                # è®­ç»ƒMetaæ¨¡å‹
                base_model_meta.fit(X_train_clean, y_meta_train[valid_train])
                if hasattr(base_model_meta, 'predict_proba'):
                    meta_pred = base_model_meta.predict_proba(X_test_clean)[:, 1]
                else:
                    meta_pred = base_model_meta.predict(X_test_clean)
                oof_meta_pred[y_meta_test[valid_test].index] = meta_pred
                
                logger.info(f"Fold {fold_idx+1}/{len(splits)} å®Œæˆ")
                
            except Exception as e:
                logger.warning(f"Fold {fold_idx+1} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        # ä»…ç”¨OOFé¢„æµ‹æ‹ŸåˆIsotonicå›å½’
        valid_oof = ~(pd.isna(oof_ret_pred) | pd.isna(oof_meta_pred) | 
                      pd.isna(y_ret_aligned) | pd.isna(y_meta_aligned))
        
        if valid_oof.sum() < 50:
            logger.warning("OOFæœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨ç®€å•æ ¡å‡†")
            # ä½¿ç”¨ç®€å•çº¿æ€§æ ¡å‡†ä½œä¸ºå›é€€
            self.iso_meta = lambda x: np.clip(x, 0, 1)
            self.iso_ret = lambda x: x
        else:
            oof_ret_clean = oof_ret_pred[valid_oof]
            oof_meta_clean = oof_meta_pred[valid_oof] 
            y_ret_clean = y_ret_aligned[valid_oof]
            y_meta_clean = y_meta_aligned[valid_oof]
            
            # æ‹ŸåˆIsotonic - ä»…ç”¨OOFæ•°æ®ï¼
            self.iso_meta.fit(oof_meta_clean, y_meta_clean)
            self.iso_ret.fit(oof_ret_clean, y_ret_clean)
            
            # è®¡ç®—æ ¡å‡†æŒ‡æ ‡
            meta_calibrated = self.iso_meta.predict(oof_meta_clean)
            ret_calibrated = self.iso_ret.predict(oof_ret_clean)
            
            from sklearn.metrics import roc_auc_score, mean_squared_error
            try:
                meta_auc = roc_auc_score(y_meta_clean, meta_calibrated)
                ret_mse = mean_squared_error(y_ret_clean, ret_calibrated)
                
                self.oof_metrics = {
                    'meta_auc_calibrated': meta_auc,
                    'ret_mse_calibrated': ret_mse,
                    'n_oof_samples': valid_oof.sum(),
                    'calibration_r2_meta': np.corrcoef(meta_calibrated, y_meta_clean)[0,1]**2,
                    'calibration_r2_ret': np.corrcoef(ret_calibrated, y_ret_clean)[0,1]**2
                }
                logger.info(f"OOFæ ¡å‡†å®Œæˆ: Meta AUC={meta_auc:.3f}, Ret MSE={ret_mse:.4f}")
            except Exception as e:
                logger.warning(f"æ ¡å‡†æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        
        return {
            'oof_ret_pred': oof_ret_pred,
            'oof_meta_pred': oof_meta_pred,
            'iso_meta': self.iso_meta,
            'iso_ret': self.iso_ret,
            'oof_metrics': self.oof_metrics
        }
    
    def predict_calibrated(self, ret_pred: np.ndarray, meta_pred: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ä½¿ç”¨æ ¡å‡†å™¨é¢„æµ‹"""
        ret_calibrated = self.iso_ret.predict(ret_pred)
        meta_calibrated = self.iso_meta.predict(meta_pred)
        return ret_calibrated, meta_calibrated

class EnhancedLabelingPipeline:
    """å¢å¼ºæ ‡ç­¾äº§çº¿ - é›†æˆä¸‰é‡éšœç¢ + Meta + OOFæ ¡å‡†"""
    
    def __init__(self, config: Optional[Dict] = None):
        default_config = {
            'tp_sigma': 2.0,
            'sl_sigma': 2.0, 
            'max_holding_days': 5,
            'min_ret_threshold': 0.0005,
            'min_ret_for_exec': 0.001,
            'strategy_type': 'directional',
            'vol_lookback': 20,
            'oof_n_splits': 5,
            'require_oof_validation': True
        }
        
        self.config = {**default_config, **(config or {})}
        
        self.barrier_labeler = TripleBarrierLabeling(
            tp_sigma=self.config['tp_sigma'],
            sl_sigma=self.config['sl_sigma'],
            max_holding_days=self.config['max_holding_days'],
            min_ret_threshold=self.config['min_ret_threshold']
        )
        
        self.meta_labeler = MetaLabelGenerator(
            min_ret_for_exec=self.config['min_ret_for_exec']
        )
        
        self.oof_calibrator = OOFIsotonicCalibrator(
            n_splits=self.config['oof_n_splits']
        )
        
    def generate_labels_and_train(self, adj_close: pd.DataFrame, features: pd.DataFrame,
                                 base_signals: Optional[pd.DataFrame] = None) -> Dict:
        """
        ç”Ÿæˆæ ‡ç­¾å¹¶è®­ç»ƒæ ¡å‡†å™¨
        
        Args:
            adj_close: å¤æƒä»·æ ¼ (DataFrame: date x symbol)
            features: ç‰¹å¾çŸ©é˜µ (MultiIndex: (date, symbol) x features)
            base_signals: åŸºç¡€ä¿¡å· (DataFrame: date x symbol)
            
        Returns:
            Dict: è®­ç»ƒç»“æœå’Œæ ¡å‡†å™¨
        """
        logger.info("å¼€å§‹å¢å¼ºæ ‡ç­¾ç”Ÿæˆæµç¨‹")
        
        all_labels = []
        all_meta_labels = []
        
        for symbol in adj_close.columns:
            try:
                # å•ä¸ªè‚¡ç¥¨çš„ä»·æ ¼å’Œä¿¡å·
                symbol_prices = adj_close[symbol].dropna()
                symbol_signal = base_signals[symbol].dropna() if base_signals is not None else None
                
                if len(symbol_prices) < 100:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
                    continue
                    
                # è®¡ç®—æ³¢åŠ¨ç‡
                vol = self.barrier_labeler.compute_daily_volatility(
                    symbol_prices, self.config['vol_lookback']
                )
                
                # ç”Ÿæˆä¸‰é‡éšœç¢æ ‡ç­¾
                barrier_labels = self.barrier_labeler.triple_barrier(
                    symbol_prices, vol, symbol_signal
                )
                
                if len(barrier_labels) == 0:
                    continue
                    
                # ç”ŸæˆMetaæ ‡ç­¾
                if symbol_signal is not None:
                    meta_labels = self.meta_labeler.make_meta_label(
                        symbol_signal, barrier_labels, self.config['strategy_type']
                    )
                else:
                    # å¦‚æœæ²¡æœ‰åŸºç¡€ä¿¡å·ï¼Œç”¨æ”¶ç›Šç»å¯¹å€¼ä½œä¸ºæ‰§è¡Œæ ‡å‡†
                    meta_labels = (barrier_labels['actual_ret'].abs() >= 
                                 self.config['min_ret_for_exec']).astype(int)
                
                # æ·»åŠ symbolä¿¡æ¯
                barrier_labels['symbol'] = symbol
                meta_labels_df = pd.DataFrame({
                    'symbol': symbol,
                    'meta_label': meta_labels
                }, index=meta_labels.index)
                
                all_labels.append(barrier_labels)
                all_meta_labels.append(meta_labels_df)
                
                logger.info(f"{symbol}: ç”Ÿæˆ{len(barrier_labels)}ä¸ªæ ‡ç­¾")
                
            except Exception as e:
                logger.warning(f"å¤„ç†{symbol}æ—¶å‡ºé”™: {e}")
                continue
        
        if not all_labels:
            raise ValueError("æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆæ ‡ç­¾")
            
        # åˆå¹¶æ‰€æœ‰æ ‡ç­¾
        combined_labels = pd.concat(all_labels, ignore_index=False)
        combined_meta = pd.concat(all_meta_labels, ignore_index=False)
        
        # é‡å»ºMultiIndexç”¨äºä¸ç‰¹å¾å¯¹é½
        label_index = pd.MultiIndex.from_arrays([
            combined_labels.index, combined_labels['symbol']
        ], names=['date', 'symbol'])
        
        meta_index = pd.MultiIndex.from_arrays([
            combined_meta.index, combined_meta['symbol']  
        ], names=['date', 'symbol'])
        
        y_ret = pd.Series(combined_labels['actual_ret'].values, index=label_index)
        y_meta = pd.Series(combined_meta['meta_label'].values, index=meta_index)
        
        # OOFè®­ç»ƒå’Œæ ¡å‡†
        logger.info("å¼€å§‹OOFè®­ç»ƒå’Œæ ¡å‡†")
        calibration_result = self.oof_calibrator.fit_and_calibrate(
            features, y_ret, y_meta
        )
        
        # éªŒè¯æ ¡å‡†è´¨é‡
        if self.config['require_oof_validation']:
            metrics = calibration_result['oof_metrics']
            if (metrics.get('meta_auc_calibrated', 0) < 0.52 or 
                metrics.get('n_oof_samples', 0) < 100):
                logger.warning("OOFæ ¡å‡†è´¨é‡ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–æ¨¡å‹")
        
        return {
            'barrier_labels': combined_labels,
            'y_ret': y_ret,
            'y_meta': y_meta,
            'calibration_result': calibration_result,
            'config': self.config,
            'pipeline': self
        }
    
    def make_signal_payload(self, symbol: str, ret_pred: float, meta_pred: float,
                           px_ref: float) -> Dict:
        """
        ç”Ÿæˆä¿¡å·è½½è·ï¼Œè¾“å‡ºåˆ°ä¸‹æ¸¸æ¥å£
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            ret_pred: åŸå§‹æ”¶ç›Šé¢„æµ‹
            meta_pred: åŸå§‹Metaé¢„æµ‹
            px_ref: å‚è€ƒä»·æ ¼
            
        Returns:
            Dict: ç¬¦åˆplan_and_place_with_rræ¥å£çš„ä¿¡å·è½½è·
        """
        # ä½¿ç”¨æ ¡å‡†å™¨æ ¡å‡†é¢„æµ‹
        ret_calibrated, meta_calibrated = self.oof_calibrator.predict_calibrated(
            np.array([ret_pred]), np.array([meta_pred])
        )
        
        expected_alpha_bps = float(ret_calibrated[0] * 10000)  # è½¬æ¢ä¸ºbps
        confidence = float(np.clip(meta_calibrated[0], 0.01, 0.99))  # æ ¡å‡†åçš„æ‰§è¡Œæ¦‚ç‡
        
        # ç¡®å®šäº¤æ˜“æ–¹å‘
        side = "BUY" if expected_alpha_bps > 0 else "SELL"
        
        return {
            "symbol": symbol,
            "side": side,
            "expected_alpha_bps": abs(expected_alpha_bps),  # ä¸‹æ¸¸æœŸæœ›æ­£å€¼
            "confidence": confidence,
            "reference_price": px_ref,
            "signal_timestamp": datetime.now(),
            "calibration_source": "oof_isotonic"
        }

# å·¥å‚å‡½æ•°
def create_enhanced_labeling_pipeline(config: Optional[Dict] = None) -> EnhancedLabelingPipeline:
    """åˆ›å»ºå¢å¼ºæ ‡ç­¾äº§çº¿"""
    return EnhancedLabelingPipeline(config)

# ä½¿ç”¨ç¤ºä¾‹
def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    # é…ç½®
    config = {
        'tp_sigma': 2.5,
        'sl_sigma': 2.0,
        'max_holding_days': 5,
        'strategy_type': 'directional',
        'require_oof_validation': True
    }
    
    # åˆ›å»ºäº§çº¿
    pipeline = create_enhanced_labeling_pipeline(config)
    
    # å‡è®¾æœ‰æ•°æ®
    # adj_close: DataFrame (date x symbol)
    # features: MultiIndex DataFrame ((date, symbol) x features)
    # base_signals: DataFrame (date x symbol) - å¯é€‰
    
    # è®­ç»ƒ
    # result = pipeline.generate_labels_and_train(adj_close, features, base_signals)
    
    # å®æ—¶é¢„æµ‹
    # signal_payload = pipeline.make_signal_payload("AAPL", 0.015, 0.75, 150.0)
    # ç„¶åä¼ ç»™: trader.plan_and_place_with_rr(**signal_payload)
    
    return pipeline