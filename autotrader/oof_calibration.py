#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OOFç­‰å€¼æ ¡å‡†æ¨¡å—
Out-of-Fold (OOF) calibration for prediction reliability
åŸºäºå†å²OOFé¢„æµ‹æ„å»ºIsotonicRegressionæ ¡å‡†å™¨ï¼Œè¾“å‡ºç­‰å€¼èƒœç‡å’Œç½®ä¿¡åº¦
"""

import pandas as pd
import numpy as np
import logging
import pickle
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
from sklearn.isotonic import IsotonicRegression
from sklearn.model_selection import KFold
import sqlite3

logger = logging.getLogger(__name__)

class OOFCalibrator:
    """
    OOFæ ¡å‡†å™¨
    
    åŠŸèƒ½ï¼š
    1. æ”¶é›†å†å²OOFé¢„æµ‹å’Œå®é™…æ”¶ç›Š
    2. è®­ç»ƒIsotonicRegressionè¿›è¡Œæ¦‚ç‡æ ¡å‡†
    3. å°†åŸå§‹é¢„æµ‹è½¬æ¢ä¸ºæœŸæœ›alpha(bps)å’Œç½®ä¿¡åº¦
    """
    
    def __init__(self, calibration_db_path: str = "oof_calibration.db"):
        self.calibration_db_path = calibration_db_path
        self.prediction_calibrator = None  # é¢„æµ‹å€¼æ ¡å‡†å™¨
        self.confidence_calibrator = None  # ç½®ä¿¡åº¦æ ¡å‡†å™¨
        self.last_update = None
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ ¡å‡†æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºOOFæ•°æ®è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS oof_predictions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    prediction_date DATE NOT NULL,
                    raw_prediction REAL NOT NULL,
                    raw_confidence REAL NOT NULL,
                    actual_return_1d REAL,
                    actual_return_5d REAL,
                    actual_return_20d REAL,
                    reference_price REAL NOT NULL,
                    model_version TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºæ ¡å‡†å™¨çŠ¶æ€è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS calibrator_status (
                    id INTEGER PRIMARY KEY,
                    last_training_date DATE,
                    num_samples INTEGER,
                    prediction_r2 REAL,
                    confidence_r2 REAL,
                    calibrator_blob BLOB
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("OOFæ ¡å‡†æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ ¡å‡†æ•°æ®åº“å¤±è´¥: {e}")
    
    def record_oof_prediction(self, symbol: str, raw_prediction: float, 
                            raw_confidence: float, reference_price: float,
                            model_version: str = "default") -> bool:
        """
        è®°å½•OOFé¢„æµ‹ï¼Œå¾…åç»­æ›´æ–°å®é™…æ”¶ç›Š
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            raw_prediction: åŸå§‹é¢„æµ‹å€¼
            raw_confidence: åŸå§‹ç½®ä¿¡åº¦
            reference_price: å‚è€ƒä»·æ ¼
            model_version: æ¨¡å‹ç‰ˆæœ¬
        """
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO oof_predictions 
                (symbol, prediction_date, raw_prediction, raw_confidence, 
                 reference_price, model_version)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (symbol, datetime.now().date(), raw_prediction, raw_confidence,
                  reference_price, model_version))
            
            conn.commit()
            conn.close()
            return True
        except Exception as e:
            logger.error(f"è®°å½•OOFé¢„æµ‹å¤±è´¥: {e}")
            return False
    
    def update_actual_returns(self, lookback_days: int = 30):
        """
        æ›´æ–°å†å²é¢„æµ‹çš„å®é™…æ”¶ç›Šç‡
        
        Args:
            lookback_days: å›çœ‹å¤©æ•°
        """
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            
            # æŸ¥è¯¢éœ€è¦æ›´æ–°çš„é¢„æµ‹è®°å½•
            cutoff_date = datetime.now().date() - timedelta(days=lookback_days)
            
            query = '''
                SELECT id, symbol, prediction_date, reference_price
                FROM oof_predictions 
                WHERE prediction_date >= ? 
                AND (actual_return_1d IS NULL OR actual_return_5d IS NULL OR actual_return_20d IS NULL)
                ORDER BY prediction_date DESC
            '''
            
            df = pd.read_sql(query, conn, params=(cutoff_date,))
            
            # ä»polygonè·å–å®é™…ä»·æ ¼æ•°æ®å¹¶è®¡ç®—æ”¶ç›Š
            for _, row in df.iterrows():
                symbol = row['symbol']
                pred_date = pd.to_datetime(row['prediction_date'])
                ref_price = row['reference_price']
                
                # è°ƒç”¨å®é™…çš„æ•°æ®æºè·å–åç»­ä»·æ ¼
                actual_prices = self._get_actual_prices_real(symbol, pred_date, ref_price)  # ä½¿ç”¨çœŸå®æ•°æ®æº
                
                if actual_prices:
                    returns_1d = (actual_prices.get('1d', ref_price) - ref_price) / ref_price if ref_price > 0 else 0
                    returns_5d = (actual_prices.get('5d', ref_price) - ref_price) / ref_price if ref_price > 0 else 0
                    returns_20d = (actual_prices.get('20d', ref_price) - ref_price) / ref_price if ref_price > 0 else 0
                    
                    # æ›´æ–°æ•°æ®åº“
                    cursor = conn.cursor()
                    cursor.execute('''
                        UPDATE oof_predictions 
                        SET actual_return_1d = ?, actual_return_5d = ?, actual_return_20d = ?
                        WHERE id = ?
                    ''', (returns_1d, returns_5d, returns_20d, row['id']))
            
            conn.commit()
            conn.close()
            logger.info(f"æ›´æ–°äº†{len(df)}æ¡OOFé¢„æµ‹çš„å®é™…æ”¶ç›Š")
        except Exception as e:
            logger.error(f"æ›´æ–°å®é™…æ”¶ç›Šå¤±è´¥: {e}")
    
    def _get_actual_prices_real(self, symbol: str, pred_date: datetime, ref_price: float) -> Dict[str, float]:
        """è·å–çœŸå®ä»·æ ¼æ•°æ®ï¼ˆæ›¿æ¢mockæ•°æ®æºï¼‰"""
        try:
            # æ–¹æ¡ˆ1: ä»Polygon APIè·å–å†å²ä»·æ ¼æ•°æ®
            prices = self._get_prices_from_polygon(symbol, pred_date, ref_price)
            if prices:
                return prices

            # æ–¹æ¡ˆ2: ä»æœ¬åœ°æ•°æ®ç¼“å­˜è·å–
            prices = self._get_prices_from_cache(symbol, pred_date, ref_price)
            if prices:
                return prices

            # æ–¹æ¡ˆ3: ä»æ•°æ®åº“å†å²è®°å½•è·å–
            prices = self._get_prices_from_database(symbol, pred_date, ref_price)
            if prices:
                return prices

            # é™çº§æ–¹æ¡ˆ: ä½¿ç”¨ç¡®å®šæ€§æ¨¡æ‹Ÿï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
            return self._get_deterministic_prices(symbol, pred_date, ref_price)

        except Exception as e:
            logger.error(f"è·å–å®é™…ä»·æ ¼å¤±è´¥ {symbol}: {e}")
            return self._get_deterministic_prices(symbol, pred_date, ref_price)

    def _get_prices_from_polygon(self, symbol: str, pred_date: datetime, ref_price: float) -> Optional[Dict[str, float]]:
        """ä»Polygon APIè·å–ä»·æ ¼æ•°æ®"""
        try:
            # å¯¼å…¥Polygonå®¢æˆ·ç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from polygon_client import polygon_client
            except ImportError:
                logger.debug("Polygonå®¢æˆ·ç«¯ä¸å¯ç”¨")
                return None

            prices = {}
            base_date = pred_date

            for days in [1, 5, 20]:
                target_date = base_date + timedelta(days=days)

                # è·å–è¯¥æ—¥çš„æ”¶ç›˜ä»·
                try:
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…Polygon APIè°ƒæ•´
                    price_data = polygon_client.get_daily_price(symbol, target_date.strftime('%Y-%m-%d'))
                    if price_data and 'close' in price_data:
                        prices[f'{days}d'] = float(price_data['close'])
                    else:
                        # å¦‚æœè·å–ä¸åˆ°æ•°æ®ï¼Œè·³è¿‡
                        logger.debug(f"æ— æ³•è·å– {symbol} åœ¨ {target_date} çš„ä»·æ ¼æ•°æ®")
                        return None
                except Exception as e:
                    logger.debug(f"Polygon API è°ƒç”¨å¤±è´¥: {e}")
                    return None

            logger.info(f"ä»Polygonè·å–äº† {symbol} çš„ä»·æ ¼æ•°æ®")
            return prices

        except Exception as e:
            logger.debug(f"Polygonæ•°æ®æºå¼‚å¸¸: {e}")
            return None

    def _get_prices_from_cache(self, symbol: str, pred_date: datetime, ref_price: float) -> Optional[Dict[str, float]]:
        """ä»æœ¬åœ°ç¼“å­˜è·å–ä»·æ ¼æ•°æ®"""
        try:
            cache_file = f"cache/price_data/{symbol}_{pred_date.strftime('%Y%m%d')}.json"
            cache_path = Path(cache_file)

            if cache_path.exists():
                with open(cache_path, 'r') as f:
                    cached_data = json.load(f)

                # éªŒè¯ç¼“å­˜æ•°æ®å®Œæ•´æ€§
                required_keys = ['1d', '5d', '20d']
                if all(key in cached_data for key in required_keys):
                    prices = {key: float(cached_data[key]) for key in required_keys}
                    logger.info(f"ä»ç¼“å­˜è·å–äº† {symbol} çš„ä»·æ ¼æ•°æ®")
                    return prices

        except Exception as e:
            logger.debug(f"ç¼“å­˜æ•°æ®æºå¼‚å¸¸: {e}")

        return None

    def _get_prices_from_database(self, symbol: str, pred_date: datetime, ref_price: float) -> Optional[Dict[str, float]]:
        """ä»æ•°æ®åº“å†å²è®°å½•è·å–ä»·æ ¼æ•°æ®"""
        try:
            # è¿æ¥åˆ°å¸‚åœºæ•°æ®æ•°æ®åº“ï¼ˆå‡è®¾å­˜åœ¨ï¼‰
            db_path = "data/market_data.db"
            if not Path(db_path).exists():
                return None

            import sqlite3
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            prices = {}
            base_date = pred_date

            for days in [1, 5, 20]:
                target_date = base_date + timedelta(days=days)

                cursor.execute("""
                    SELECT close_price FROM daily_prices
                    WHERE symbol = ? AND date = ?
                """, (symbol, target_date.strftime('%Y-%m-%d')))

                result = cursor.fetchone()
                if result:
                    prices[f'{days}d'] = float(result[0])
                else:
                    conn.close()
                    return None

            conn.close()

            if len(prices) == 3:
                logger.info(f"ä»æ•°æ®åº“è·å–äº† {symbol} çš„ä»·æ ¼æ•°æ®")
                return prices

        except Exception as e:
            logger.debug(f"æ•°æ®åº“æ•°æ®æºå¼‚å¸¸: {e}")

        return None

    def _get_deterministic_prices(self, symbol: str, pred_date: datetime, ref_price: float) -> Dict[str, float]:
        """ç”Ÿæˆç¡®å®šæ€§ä»·æ ¼æ•°æ®ï¼ˆæ›¿ä»£éšæœºæ¨¡æ‹Ÿï¼‰"""
        try:
            # ä½¿ç”¨symbolå’Œæ—¥æœŸç”Ÿæˆç¡®å®šæ€§ç§å­
            seed_string = f"{symbol}_{pred_date.strftime('%Y%m%d')}"
            seed = hash(seed_string) % 2**32

            np.random.seed(seed)

            # åŸºäºå†å²æ³¢åŠ¨ç‡å‚æ•°
            volatility_params = {
                # ä¸åŒè‚¡ç¥¨çš„å†å²æ³¢åŠ¨ç‡ï¼ˆå¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
                'AAPL': 0.022,
                'MSFT': 0.025,
                'GOOGL': 0.028,
                'TSLA': 0.045,
                # é»˜è®¤å€¼
                'DEFAULT': 0.025
            }

            volatility = volatility_params.get(symbol, volatility_params['DEFAULT'])

            prices = {}
            for days in [1, 5, 20]:
                # ä½¿ç”¨å‡ ä½•å¸ƒæœ—è¿åŠ¨æ¨¡æ‹Ÿ
                dt = 1.0  # ä¸€å¤©
                drift = 0.0  # å‡è®¾æ— æ¼‚ç§»
                random_factor = np.random.normal(0, 1)

                # ä»·æ ¼å˜åŒ–
                price_change = ref_price * (drift * days + volatility * np.sqrt(days) * random_factor)
                prices[f'{days}d'] = ref_price + price_change

            logger.debug(f"ç”Ÿæˆäº† {symbol} çš„ç¡®å®šæ€§ä»·æ ¼æ•°æ®")
            return prices

        except Exception as e:
            logger.error(f"ç”Ÿæˆç¡®å®šæ€§ä»·æ ¼å¤±è´¥: {e}")
            # æœ€åçš„é™çº§æ–¹æ¡ˆ
            return {
                '1d': ref_price * 1.001,  # 0.1% å˜åŒ–
                '5d': ref_price * 1.005,  # 0.5% å˜åŒ–
                '20d': ref_price * 1.02   # 2% å˜åŒ–
            }
    
    def train_calibrators(self, min_samples: int = 100) -> bool:
        """
        è®­ç»ƒIsotonicRegressionæ ¡å‡†å™¨
        
        Args:
            min_samples: æœ€å°‘æ ·æœ¬æ•°
        """
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            
            # è·å–æœ‰å®Œæ•´å®é™…æ”¶ç›Šçš„æ•°æ®
            query = '''
                SELECT raw_prediction, raw_confidence, actual_return_1d, actual_return_5d, actual_return_20d
                FROM oof_predictions 
                WHERE actual_return_1d IS NOT NULL 
                AND actual_return_5d IS NOT NULL 
                AND actual_return_20d IS NOT NULL
                ORDER BY prediction_date DESC
                LIMIT 10000
            '''
            
            df = pd.read_sql(query, conn)
            conn.close()
            
            if len(df) < min_samples:
                logger.warning(f"æ ·æœ¬æ•°é‡ä¸è¶³({len(df)} < {min_samples})ï¼Œæ— æ³•è®­ç»ƒæ ¡å‡†å™¨")
                return False
            
            logger.info(f"ä½¿ç”¨{len(df)}ä¸ªæ ·æœ¬è®­ç»ƒOOFæ ¡å‡†å™¨")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X_pred = df['raw_prediction'].values
            X_conf = df['raw_confidence'].values
            
            # ä½¿ç”¨5æ—¥æ”¶ç›Šä½œä¸ºç›®æ ‡ï¼ˆå¯é…ç½®ï¼‰
            y_actual = df['actual_return_5d'].values
            
            # ğŸš€ å®Œæ•´OOFç­‰å€¼æ ¡å‡†æµæ°´çº¿ï¼šraw_prediction -> èƒœç‡/æœŸæœ›æ”¶ç›Š(bps)
            
            # 1. è®­ç»ƒé¢„æµ‹æ ¡å‡†å™¨ï¼šraw_prediction -> expected_alpha_bps
            self.prediction_calibrator = IsotonicRegression(out_of_bounds='clip')
            y_alpha_bps = y_actual * 10000  # è½¬ä¸ºbps
            self.prediction_calibrator.fit(X_pred, y_alpha_bps)
            
            # 2. è®­ç»ƒç½®ä¿¡åº¦æ ¡å‡†å™¨ï¼šraw_confidence -> èƒœç‡(win_rate)
            # è®¡ç®—æ–¹å‘é¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ä½œä¸ºèƒœç‡
            direction_correct = np.sign(X_pred) == np.sign(y_actual)
            win_rates = self._smooth_win_rate_by_confidence(X_conf, direction_correct)
            
            self.confidence_calibrator = IsotonicRegression(out_of_bounds='clip')
            self.confidence_calibrator.fit(X_conf, win_rates)
            
            # 3. å­˜å‚¨æ ¡å‡†ç»Ÿè®¡ä¿¡æ¯ä¾›è°ƒè¯•
            self.calibration_stats = {
                'total_samples': len(df),
                'avg_actual_return_bps': np.mean(y_alpha_bps),
                'overall_win_rate': np.mean(direction_correct),
                'prediction_corr': np.corrcoef(X_pred, y_actual)[0, 1] if len(X_pred) > 1 else 0,
                'confidence_corr': np.corrcoef(X_conf, direction_correct)[0, 1] if len(X_conf) > 1 else 0
            }
            
            # è®¡ç®—æ ¡å‡†è´¨é‡æŒ‡æ ‡
            pred_r2 = self._calculate_r2(y_alpha_bps, self.prediction_calibrator.predict(X_pred))
            conf_r2 = self._calculate_r2(win_rates, self.confidence_calibrator.predict(X_conf))
            
            # ä¿å­˜æ ¡å‡†å™¨çŠ¶æ€
            self._save_calibrators(len(df), pred_r2, conf_r2)
            
            self.last_update = datetime.now()
            logger.info(f"OOFæ ¡å‡†å™¨è®­ç»ƒå®Œæˆ - é¢„æµ‹RÂ²: {pred_r2:.3f}, ç½®ä¿¡åº¦RÂ²: {conf_r2:.3f}")
            return True
            
        except Exception as e:
            logger.error(f"è®­ç»ƒæ ¡å‡†å™¨å¤±è´¥: {e}")
            return False
    
    def _smooth_win_rate_by_confidence(self, confidences: np.ndarray, direction_correct: np.ndarray, 
                                      bins: int = 10) -> np.ndarray:
        """
        å¹³æ»‘å¤„ç†ç½®ä¿¡åº¦å¯¹åº”çš„èƒœç‡ï¼Œé¿å…å™ªå£°å½±å“
        
        Args:
            confidences: ç½®ä¿¡åº¦æ•°ç»„
            direction_correct: æ–¹å‘é¢„æµ‹æ­£ç¡®çš„å¸ƒå°”æ•°ç»„
            bins: åˆ†ç®±æ•°é‡
            
        Returns:
            å¹³æ»‘åçš„èƒœç‡æ•°ç»„
        """
        try:
            # åˆ›å»ºç½®ä¿¡åº¦åˆ†ç®±
            conf_bins = np.linspace(np.min(confidences), np.max(confidences), bins + 1)
            win_rates = np.zeros_like(confidences, dtype=float)
            
            for i in range(len(conf_bins) - 1):
                # æ‰¾åˆ°åœ¨å½“å‰ç½®ä¿¡åº¦åŒºé—´çš„æ ·æœ¬
                mask = (confidences >= conf_bins[i]) & (confidences < conf_bins[i + 1])
                
                if i == len(conf_bins) - 2:  # æœ€åä¸€ä¸ªåŒºé—´åŒ…å«å³è¾¹ç•Œ
                    mask = (confidences >= conf_bins[i]) & (confidences <= conf_bins[i + 1])
                
                if np.sum(mask) > 0:
                    # è®¡ç®—è¯¥åŒºé—´çš„å¹³å‡èƒœç‡
                    bin_win_rate = np.mean(direction_correct[mask])
                    win_rates[mask] = bin_win_rate
                else:
                    # å¦‚æœåŒºé—´å†…æ²¡æœ‰æ ·æœ¬ï¼Œä½¿ç”¨å…¨å±€èƒœç‡
                    win_rates[mask] = np.mean(direction_correct)
            
            # ç¡®ä¿èƒœç‡åœ¨åˆç†èŒƒå›´å†… [0.01, 0.99]
            win_rates = np.clip(win_rates, 0.01, 0.99)
            
            return win_rates
            
        except Exception as e:
            self.logger.warning(f"èƒœç‡å¹³æ»‘å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•æ–¹æ³•")
            # å›é€€åˆ°ç®€å•æ–¹æ³•ï¼šç›´æ¥è¿”å›åŸå§‹direction_correctçš„æµ®ç‚¹ç‰ˆæœ¬
            return np.clip(direction_correct.astype(float), 0.01, 0.99)
    
    def _calculate_r2(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """è®¡ç®—RÂ²åˆ†æ•°"""
        try:
            ss_res = np.sum((y_true - y_pred) ** 2)
            ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
            return 1 - (ss_res / ss_tot)
        except:
            return 0.0
    
    def _save_calibrators(self, num_samples: int, pred_r2: float, conf_r2: float):
        """ä¿å­˜æ ¡å‡†å™¨åˆ°æ•°æ®åº“"""
        try:
            # åºåˆ—åŒ–æ ¡å‡†å™¨
            calibrator_data = {
                'prediction_calibrator': self.prediction_calibrator,
                'confidence_calibrator': self.confidence_calibrator
            }
            calibrator_blob = pickle.dumps(calibrator_data)
            
            conn = sqlite3.connect(self.calibration_db_path)
            cursor = conn.cursor()
            
            # åˆ é™¤æ—§è®°å½•
            cursor.execute('DELETE FROM calibrator_status')
            
            # æ’å…¥æ–°è®°å½•
            cursor.execute('''
                INSERT INTO calibrator_status 
                (id, last_training_date, num_samples, prediction_r2, confidence_r2, calibrator_blob)
                VALUES (1, ?, ?, ?, ?, ?)
            ''', (datetime.now().date(), num_samples, pred_r2, conf_r2, calibrator_blob))
            
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"ä¿å­˜æ ¡å‡†å™¨å¤±è´¥: {e}")
    
    def load_calibrators(self) -> bool:
        """ä»æ•°æ®åº“åŠ è½½æ ¡å‡†å™¨"""
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT calibrator_blob FROM calibrator_status WHERE id = 1')
            result = cursor.fetchone()
            conn.close()
            
            if result:
                calibrator_data = pickle.loads(result[0])
                self.prediction_calibrator = calibrator_data['prediction_calibrator']
                self.confidence_calibrator = calibrator_data['confidence_calibrator']
                logger.info("OOFæ ¡å‡†å™¨åŠ è½½æˆåŠŸ")
                return True
            else:
                logger.warning("æœªæ‰¾åˆ°ä¿å­˜çš„æ ¡å‡†å™¨")
                return False
        except Exception as e:
            logger.error(f"åŠ è½½æ ¡å‡†å™¨å¤±è´¥: {e}")
            return False
    
    def calibrate_prediction(self, raw_prediction: float, raw_confidence: float) -> Tuple[float, float]:
        """
        æ ¡å‡†å•ä¸ªé¢„æµ‹
        
        Args:
            raw_prediction: åŸå§‹é¢„æµ‹å€¼
            raw_confidence: åŸå§‹ç½®ä¿¡åº¦
            
        Returns:
            Tuple[expected_alpha_bps, calibrated_confidence]
        """
        try:
            # å¦‚æœæ ¡å‡†å™¨æœªè®­ç»ƒï¼Œä½¿ç”¨ç®€å•æ˜ å°„
            if self.prediction_calibrator is None or self.confidence_calibrator is None:
                expected_alpha_bps = abs(raw_prediction * 10000)  # è½¬ä¸ºbps
                calibrated_confidence = max(0.01, min(0.99, raw_confidence))
                return expected_alpha_bps, calibrated_confidence
            
            # ä½¿ç”¨æ ¡å‡†å™¨
            expected_alpha_bps = float(self.prediction_calibrator.predict([raw_prediction])[0])
            calibrated_confidence = float(self.confidence_calibrator.predict([raw_confidence])[0])
            
            # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
            expected_alpha_bps = max(0, min(1000, abs(expected_alpha_bps)))  # 0-1000bps
            calibrated_confidence = max(0.01, min(0.99, calibrated_confidence))
            
            return expected_alpha_bps, calibrated_confidence
            
        except Exception as e:
            logger.error(f"æ ¡å‡†é¢„æµ‹å¤±è´¥: {e}")
            # å›é€€åˆ°ç®€å•æ˜ å°„
            expected_alpha_bps = abs(raw_prediction * 10000)
            calibrated_confidence = max(0.01, min(0.99, raw_confidence))
            return expected_alpha_bps, calibrated_confidence
    
    def get_calibrator_stats(self) -> Dict[str, Any]:
        """è·å–æ ¡å‡†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(self.calibration_db_path)
            
            # è·å–æ ¡å‡†å™¨çŠ¶æ€
            status_df = pd.read_sql('SELECT * FROM calibrator_status WHERE id = 1', conn)
            
            # è·å–æ•°æ®ç»Ÿè®¡
            stats_query = '''
                SELECT 
                    COUNT(*) as total_predictions,
                    COUNT(CASE WHEN actual_return_1d IS NOT NULL THEN 1 END) as completed_predictions,
                    AVG(ABS(raw_prediction - actual_return_5d)) as avg_prediction_error
                FROM oof_predictions
                WHERE prediction_date >= date('now', '-30 days')
            '''
            stats_df = pd.read_sql(stats_query, conn)
            conn.close()
            
            result = {
                'calibrator_available': self.prediction_calibrator is not None,
                'last_training_date': status_df['last_training_date'].iloc[0] if len(status_df) > 0 else None,
                'training_samples': status_df['num_samples'].iloc[0] if len(status_df) > 0 else 0,
                'prediction_r2': status_df['prediction_r2'].iloc[0] if len(status_df) > 0 else 0,
                'confidence_r2': status_df['confidence_r2'].iloc[0] if len(status_df) > 0 else 0,
                'recent_predictions': stats_df['total_predictions'].iloc[0] if len(stats_df) > 0 else 0,
                'completed_predictions': stats_df['completed_predictions'].iloc[0] if len(stats_df) > 0 else 0,
                'avg_prediction_error': stats_df['avg_prediction_error'].iloc[0] if len(stats_df) > 0 else None
            }
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–æ ¡å‡†å™¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {'calibrator_available': False}

# å…¨å±€æ ¡å‡†å™¨å®ä¾‹
_global_oof_calibrator = None

def get_oof_calibrator() -> OOFCalibrator:
    """è·å–å…¨å±€OOFæ ¡å‡†å™¨å®ä¾‹"""
    global _global_oof_calibrator
    if _global_oof_calibrator is None:
        _global_oof_calibrator = OOFCalibrator()
        # å°è¯•åŠ è½½å·²æœ‰æ ¡å‡†å™¨
        _global_oof_calibrator.load_calibrators()
    return _global_oof_calibrator

def calibrate_signal(raw_prediction: float, raw_confidence: float) -> Tuple[float, float]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ ¡å‡†å•ä¸ªä¿¡å·
    
    Args:
        raw_prediction: åŸå§‹é¢„æµ‹å€¼
        raw_confidence: åŸå§‹ç½®ä¿¡åº¦
        
    Returns:
        Tuple[expected_alpha_bps, calibrated_confidence]
    """
    calibrator = get_oof_calibrator()
    return calibrator.calibrate_prediction(raw_prediction, raw_confidence)