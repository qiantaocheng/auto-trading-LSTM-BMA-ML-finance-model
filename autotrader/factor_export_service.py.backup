#!/usr/bin/env python3
"""Shared utilities for exporting polygon factor datasets."""
from __future__ import annotations

import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Iterable, List, Sequence, Dict, Any, Optional, Callable

import pandas as pd

from autotrader.database import StockDatabase
from bma_models.simple_25_factor_engine import Simple17FactorEngine
from bma_models.量化模型_bma_ultra_enhanced import UltraEnhancedQuantitativeModel

logger = logging.getLogger(__name__)
StatusCallback = Callable[[str], None]


def chunked(seq: Sequence[str], size: int) -> Iterable[List[str]]:
    for idx in range(0, len(seq), size):
        yield list(seq[idx: idx + size])


def default_date_window(years: int = 5) -> tuple[str, str]:
    end = datetime.utcnow().date()
    start = end - timedelta(days=365 * years + 30)
    return start.isoformat(), end.isoformat()


def normalize_factor_frame(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()
    result = df.copy()
    if isinstance(result.index, pd.MultiIndex) or result.index.name:
        result = result.reset_index()
    symbol_col = None
    for candidate in ('symbol', 'ticker'):
        if candidate in result.columns:
            symbol_col = candidate
            break
    if not symbol_col:
        raise ValueError('factor dataframe missing symbol/ticker column')
    if symbol_col != 'symbol':
        result.rename(columns={symbol_col: 'symbol'}, inplace=True)
    if 'as_of_date' not in result.columns:
        if 'date' in result.columns:
            result.rename(columns={'date': 'as_of_date'}, inplace=True)
        elif 'timestamp' in result.columns:
            result.rename(columns={'timestamp': 'as_of_date'}, inplace=True)
    result['as_of_date'] = pd.to_datetime(result['as_of_date'], errors='coerce')
    return result


def load_symbols(limit: Optional[int] = None) -> List[str]:
    with StockDatabase() as db:
        symbols = db.get_all_tickers()
    symbols = [s.strip().upper() for s in symbols if s]
    if limit is not None:
        symbols = symbols[:limit]
    return symbols


def export_polygon_factors(
    max_symbols: int = 2600,
    batch_size: int = 50,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    years: int = 5,
    output_dir: str | Path = 'data/factor_exports',
    log_level: str = 'INFO',
    status_callback: Optional[StatusCallback] = None,
    symbols: Optional[Sequence[str]] = None,
    pool_name: Optional[str] = None,
) -> Dict[str, Any]:
    """Export polygon-based factor dataset using Simple17/BMA pipeline."""
    logging.getLogger(__name__).setLevel(getattr(logging, log_level.upper(), logging.INFO))

    if not start_date or not end_date:
        start_date, end_date = default_date_window(years)

    if symbols:
        symbols = [s.strip().upper() for s in symbols if isinstance(s, str) and s.strip()]
        if not symbols:
            raise RuntimeError('Provided symbol list is empty')
        if max_symbols:
            symbols = symbols[:max_symbols]
    else:
        symbols = load_symbols(max_symbols)
    if not symbols:
        raise RuntimeError('No symbols available from StockDatabase')

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    if status_callback:
        pool_desc = pool_name or '数据库股票池'
        status_callback(f'准备导出因子数据【{pool_desc}】，股票数 {len(symbols)}，区间 {start_date} 到 {end_date}')

    model = UltraEnhancedQuantitativeModel(preserve_state=False)
    model.simple_25_engine = Simple17FactorEngine(mode='predict', lookback_days=252 * years)

    manifest: List[Dict[str, Any]] = []
    for batch_id, batch in enumerate(chunked(symbols, batch_size), start=1):
        try:
            if status_callback:
                status_callback(f'批次 {batch_id}: 处理 {len(batch)} 只股票')
            feature_df = model.get_data_and_features(batch, start_date, end_date, mode='predict')
            normalized = normalize_factor_frame(feature_df)
            if normalized.empty:
                logger.warning('Batch %s produced no data', batch_id)
                continue
            shard = output_path / f'polygon_factors_batch_{batch_id:04d}.parquet'
            normalized.to_parquet(shard, index=False)
            manifest.append({'batch_id': batch_id, 'file': str(shard), 'symbols': batch})
            if status_callback:
                status_callback(f'批次 {batch_id} 完成: {shard.name}')
        except Exception as exc:
            logger.exception('Batch %s failed', batch_id)
            if status_callback:
                status_callback(f'批次 {batch_id} 失败: {exc}')

    manifest_path = None
    if manifest:
        manifest_path = output_path / 'manifest.parquet'
        pd.DataFrame(manifest).to_parquet(manifest_path, index=False)
        if status_callback:
            status_callback(f'导出完成，共 {len(manifest)} 个批次 (manifest: {manifest_path})')
    else:
        if status_callback:
            status_callback('导出未产生任何批次，请查看日志')

    return {
        'output_dir': str(output_path),
        'manifest': str(manifest_path) if manifest_path else None,
        'batch_count': len(manifest),
        'start_date': start_date,
        'end_date': end_date,
        'total_symbols': len(symbols),
        'pool_name': pool_name or 'database',
    }
