#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AutoTraderç»Ÿä¸€å› å­åº“ - åŸºäºPolygon 15åˆ†é’Ÿå»¶è¿Ÿæ•°æ®
æ•´åˆæ‰€æœ‰å› å­è®¡ç®—ï¼Œç»Ÿä¸€æ•°æ®æºä¸ºPolygon API
æ”¯æŒautotraderç®—æ³•ä½¿ç”¨çš„æ‰€æœ‰å› å­ç±»å‹
"""

import logging
import math
import time
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass
import scipy.stats as stats

# Polygonå®¢æˆ·ç«¯å¯¼å…¥
try:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from polygon_client import polygon_client, download, Ticker
except ImportError as e:
    logging.warning(f"Polygon client import failed: {e}")
    polygon_client = None

# å»¶è¿Ÿæ•°æ®é…ç½®
try:
    from .delayed_data_config import DelayedDataConfig, DEFAULT_DELAYED_CONFIG, should_trade_with_delayed_data
except ImportError:
    # åˆ›å»ºç®€åŒ–é…ç½®ç±»ä»¥é˜²å¯¼å…¥å¤±è´¥
    @dataclass
    class DelayedDataConfig:
        enabled: bool = True
        data_delay_minutes: int = 15
        min_confidence_threshold: float = 0.8
        position_size_reduction: float = 0.4
        min_alpha_multiplier: float = 1.0  # æ·»åŠ ç¼ºå¤±å­—æ®µ
    
    DEFAULT_DELAYED_CONFIG = DelayedDataConfig()
    
    def should_trade_with_delayed_data(config: DelayedDataConfig) -> Tuple[bool, str]:
        """ç®€åŒ–çš„å»¶è¿Ÿæ•°æ®äº¤æ˜“æ£€æŸ¥"""
        if not config.enabled:
            return False, "Delayed data trading disabled"
        return True, "Delayed data trading allowed"

# å¯¼å…¥è‡ªé€‚åº”æƒé‡ç³»ç»Ÿ
try:
    from .adaptive_factor_weights import get_current_factor_weights, AdaptiveFactorWeights
    from .adaptive_weights_adapter import get_bma_enhanced_weights
    ADAPTIVE_WEIGHTS_AVAILABLE = True
    BMA_ENHANCED_WEIGHTS_AVAILABLE = True
except ImportError:
    ADAPTIVE_WEIGHTS_AVAILABLE = False
    BMA_ENHANCED_WEIGHTS_AVAILABLE = False
    logging.warning("Adaptive weights system not available, using fallback weights")

logger = logging.getLogger(__name__)

@dataclass
class FactorResult:
    """å› å­è®¡ç®—ç»“æœ"""
    factor_name: str
    value: float
    confidence: float
    timestamp: datetime
    metadata: Dict[str, Any]
    data_quality_score: float

class UnifiedPolygonFactors:
    """
    AutoTraderç»Ÿä¸€å› å­åº“
    åŸºäºPolygon 15åˆ†é’Ÿå»¶è¿Ÿæ•°æ®çš„æ‰€æœ‰å› å­è®¡ç®—
    """
    
    def __init__(self, config: DelayedDataConfig = None):
        """åˆå§‹åŒ–ç»Ÿä¸€å› å­åº“"""
        self.config = config or DEFAULT_DELAYED_CONFIG
        self.client = polygon_client
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        
        # å› å­æƒé‡é…ç½® - ç°åœ¨æ”¯æŒåŠ¨æ€æƒé‡å­¦ä¹ 
        self.fallback_weights = {
            'momentum': 0.20,        # åŠ¨é‡å› å­
            'mean_reversion': 0.30,  # å‡å€¼å›å½’ï¼ˆä¸»è¦ä¿¡å·ï¼‰
            'trend': 0.25,           # è¶‹åŠ¿å› å­
            'volatility': 0.15,      # æ³¢åŠ¨ç‡å› å­
            'volume': 0.10,          # æˆäº¤é‡å› å­
            'microstructure': 0.00   # å¾®è§‚ç»“æ„ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
        }
        
        # å»¶è¿Ÿåˆå§‹åŒ–è‡ªé€‚åº”æƒé‡ç³»ç»Ÿï¼ˆé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
        self.adaptive_weights = None
        
        # ğŸ”¥ å»¶è¿Ÿæƒé‡è·å–ï¼šä»…åœ¨å®é™…éœ€è¦æ—¶æ‰è·å–æƒé‡
        self.factor_weights = None
        self._weights_initialized = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_calculations': 0,
            'successful_calculations': 0,
            'failed_calculations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'cache_evictions': 0,
            'last_update': datetime.now()
        }
        
        # ç¼“å­˜ç®¡ç†
        self.max_cache_size = 1000  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        self.cache_timestamps = {}  # è·Ÿè¸ªç¼“å­˜æ—¶é—´æˆ³
        
        logger.info(f"UnifiedPolygonFactors initialized with {self.config.data_delay_minutes}min delay")
    
    def _ensure_weights_initialized(self):
        """ç¡®ä¿æƒé‡å·²åˆå§‹åŒ–ï¼ˆè½»é‡çº§å»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if not self._weights_initialized:
            logger.info("âš¡ è½»é‡çº§æƒé‡åˆå§‹åŒ–ï¼ˆé¿å…è®­ç»ƒå‰è§¦å‘MLï¼‰")
            
            # ğŸ”¥ å¯åŠ¨æ—¶ä»…ä½¿ç”¨è½»é‡çº§æƒé‡ï¼Œä¸è§¦å‘MLå­¦ä¹ 
            if self.adaptive_weights is not None:
                # å°è¯•åŠ è½½ç°æœ‰æƒé‡ï¼Œä¸è§¦å‘æ–°çš„å­¦ä¹ 
                latest_result = self.adaptive_weights.load_latest_weights()
                if latest_result is not None and latest_result.confidence >= 0.5:
                    logger.info(f"ğŸ“‚ åŠ è½½å†å²MLæƒé‡ï¼Œç½®ä¿¡åº¦: {latest_result.confidence:.3f}")
                    self.factor_weights = latest_result.weights
                else:
                    logger.info("ğŸ“‹ ä½¿ç”¨ä¼˜åŒ–å›é€€æƒé‡ï¼Œç­‰å¾…è®­ç»ƒå®Œæˆ")
                    self.factor_weights = self.fallback_weights.copy()
            else:
                self.factor_weights = self.fallback_weights.copy()
            
            # éªŒè¯æƒé‡æ€»å’Œ
            total_weight = sum(self.factor_weights.values())
            if abs(total_weight - 1.0) > 1e-6:
                self.factor_weights = {k: v/total_weight for k, v in self.factor_weights.items()}
            
            self._weights_initialized = True
            logger.info(f"âœ… è½»é‡çº§æƒé‡åˆå§‹åŒ–å®Œæˆï¼Œç­‰å¾…è®­ç»ƒåæ›´æ–°")

    def get_bma_enhanced_weights(self) -> Dict[str, float]:
        """
        ä¸“ä¸ºBMA Enhancedç³»ç»Ÿè·å–MLæƒé‡
        åªæœ‰åœ¨BMAè®­ç»ƒå®Œæˆåæ‰åº”è¯¥è°ƒç”¨æ­¤æ–¹æ³•
        """
        try:
            if BMA_ENHANCED_WEIGHTS_AVAILABLE:
                logger.info("ğŸ¯ BMA Enhancedè®­ç»ƒåè·å–MLæƒé‡")
                ml_weights = get_bma_enhanced_weights()
                
                # æ›´æ–°å†…éƒ¨æƒé‡ç¼“å­˜
                self.factor_weights = ml_weights
                self._weights_initialized = True
                
                return ml_weights
            else:
                logger.warning("BMA Enhancedæƒé‡é€‚é…å™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•")
                return self._get_current_weights(force_ml_learning=True)
        except Exception as e:
            logger.error(f"BMA Enhancedæƒé‡è·å–å¤±è´¥: {e}")
            return self._get_current_weights()
    
    def update_weights_post_training(self, training_context: str = "BMA_ENHANCED"):
        """
        è®­ç»ƒå®Œæˆåæ›´æ–°æƒé‡
        
        Args:
            training_context: è®­ç»ƒä¸Šä¸‹æ–‡ ("BMA_ENHANCED", "MANUAL", etc.)
        """
        try:
            logger.info(f"ğŸ“Š {training_context} è®­ç»ƒå®Œæˆï¼Œæ›´æ–°å› å­æƒé‡")
            
            if training_context == "BMA_ENHANCED":
                # BMAè®­ç»ƒå®Œæˆåï¼Œè·å–MLæƒé‡
                updated_weights = self.get_bma_enhanced_weights()
            else:
                # å…¶ä»–è®­ç»ƒæ¨¡å¼ï¼Œå¼ºåˆ¶æ›´æ–°æƒé‡
                updated_weights = self._get_current_weights(force_ml_learning=True)
            
            # éªŒè¯å¹¶åº”ç”¨æ–°æƒé‡
            total_weight = sum(updated_weights.values())
            if abs(total_weight - 1.0) > 1e-6:
                updated_weights = {k: v/total_weight for k, v in updated_weights.items()}
            
            self.factor_weights = updated_weights
            self._weights_initialized = True
            
            logger.info(f"âœ… æƒé‡æ›´æ–°å®Œæˆ: {updated_weights}")
            return updated_weights
            
        except Exception as e:
            logger.error(f"è®­ç»ƒåæƒé‡æ›´æ–°å¤±è´¥: {e}")
            # ä¿æŒç°æœ‰æƒé‡æˆ–ä½¿ç”¨å›é€€æƒé‡
            if not self._weights_initialized:
                self._ensure_weights_initialized()
            return self.factor_weights

    def _get_current_weights(self, force_ml_learning: bool = False) -> Dict[str, float]:
        """è·å–å½“å‰å› å­æƒé‡ï¼ˆä¼˜å…ˆMLå­¦ä¹ æƒé‡ï¼‰"""
        try:
            if self.adaptive_weights is not None:
                # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨ä¸»åŠ¨å­¦ä¹ æƒé‡ï¼Œé¿å…ç¡¬ç¼–ç å›é€€
                if force_ml_learning:
                    logger.info("ğŸš€ BMA Enhancedæ¨¡å¼ï¼šä¸»åŠ¨è·å–æˆ–å­¦ä¹ MLæƒé‡")
                    adaptive_weights = self.adaptive_weights.get_or_learn_weights()
                else:
                    adaptive_weights = self.adaptive_weights.get_current_weights()
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºç¡¬ç¼–ç å›é€€æƒé‡
                is_fallback = self._is_fallback_weights(adaptive_weights)
                if is_fallback:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°ç¡¬ç¼–ç æƒé‡ï¼Œå°è¯•ä¸»åŠ¨å­¦ä¹ MLæƒé‡")
                    try:
                        ml_weights = self.adaptive_weights.get_or_learn_weights()
                        if not self._is_fallback_weights(ml_weights):
                            logger.info("âœ… æˆåŠŸè·å–MLæƒé‡ï¼Œæ›¿æ¢ç¡¬ç¼–ç æƒé‡")
                            adaptive_weights = ml_weights
                    except Exception as ml_error:
                        logger.error(f"MLæƒé‡è·å–å¤±è´¥: {ml_error}")
                
                weight_type = "MLå­¦ä¹ æƒé‡" if not self._is_fallback_weights(adaptive_weights) else "ç¡¬ç¼–ç å›é€€æƒé‡"
                logger.info(f"ä½¿ç”¨{weight_type}: {adaptive_weights}")
                return adaptive_weights
            else:
                # ä½¿ç”¨å›é€€æƒé‡
                logger.info(f"ä½¿ç”¨å›é€€æƒé‡: {self.fallback_weights}")
                return self.fallback_weights.copy()
        except Exception as e:
            logger.error(f"è·å–æƒé‡å¤±è´¥: {e}")
            return self.fallback_weights.copy()
    
    def _is_fallback_weights(self, weights: Dict[str, float]) -> bool:
        """æ£€æµ‹æƒé‡æ˜¯å¦ä¸ºç¡¬ç¼–ç å›é€€æƒé‡"""
        try:
            # æ£€æŸ¥æƒé‡åˆ†å¸ƒç‰¹å¾
            values = list(weights.values())
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç­‰æƒé‡åˆ†å¸ƒ (0.2, 0.2, 0.2, 0.2, 0.2)
            if len(set(values)) == 1 and abs(values[0] - 0.2) < 0.001:
                return True
                
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…é¢„è®¾çš„å›é€€æƒé‡æ¨¡å¼
            fallback_signature = [0.30, 0.30, 0.25, 0.20, 0.15]  # å…¸å‹å›é€€æƒé‡
            sorted_weights = sorted(values, reverse=True)
            if len(sorted_weights) >= 3:
                if (abs(sorted_weights[0] - 0.3) < 0.05 and 
                    abs(sorted_weights[1] - 0.3) < 0.05):
                    return True
            
            return False
            
        except Exception:
            return False
    
    def _validate_client(self) -> bool:
        """éªŒè¯Polygonå®¢æˆ·ç«¯å¯ç”¨æ€§"""
        if not self.client:
            logger.error("Polygon client not available")
            return False
        return True
    
    def _get_cache_key(self, symbol: str, factor_name: str, lookback_days: int = 60) -> str:
        """ç”Ÿæˆå®‰å…¨çš„ç¼“å­˜é”®ï¼Œé¿å…å†²çª"""
        import hashlib
        
        # æ¸…ç†è¾“å…¥å‚æ•°ï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦
        clean_symbol = symbol.replace('_', '').replace('-', '').upper()
        clean_factor = factor_name.replace('_', '').replace('-', '').lower()
        
        # æ—¶é—´çª—å£ï¼ˆé˜²æ­¢è¾¹ç•Œæƒ…å†µçš„é”®å†²çªï¼‰
        time_window = int(time.time() // self.cache_ttl)
        
        # åˆ›å»ºå¤åˆé”®
        key_components = f"{clean_symbol}|{clean_factor}|{lookback_days}|{time_window}"
        
        # ç”Ÿæˆå“ˆå¸Œé¿å…è¿‡é•¿çš„é”®åå’Œæ½œåœ¨å†²çª
        key_hash = hashlib.md5(key_components.encode('utf-8')).hexdigest()[:16]
        
        # è¿”å›å¯è¯»æ€§å¥½çš„ç¼“å­˜é”®
        return f"factors_{clean_symbol}_{clean_factor}_{key_hash}"
    
    def _get_cached_result(self, cache_key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        if cache_key in self.cache:
            cached_time, cached_data = self.cache[cache_key]
            if time.time() - cached_time < self.cache_ttl:
                self.stats['cache_hits'] += 1
                # æ›´æ–°è®¿é—®æ—¶é—´
                self.cache_timestamps[cache_key] = time.time()
                return cached_data
            else:
                # è¿‡æœŸç¼“å­˜æ¸…ç†
                del self.cache[cache_key]
                if cache_key in self.cache_timestamps:
                    del self.cache_timestamps[cache_key]
        
        self.stats['cache_misses'] += 1
        return None
    
    def _set_cache(self, cache_key: str, data: Any):
        """è®¾ç½®ç¼“å­˜ï¼ŒåŒ…å«å¤§å°ç®¡ç†"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        if len(self.cache) >= self.max_cache_size:
            self._evict_old_cache_entries()
        
        # è®¾ç½®æ–°ç¼“å­˜
        self.cache[cache_key] = (current_time, data)
        self.cache_timestamps[cache_key] = current_time
        
    def _evict_old_cache_entries(self):
        """æ¸…ç†è€æ—§ç¼“å­˜æ¡ç›®"""
        if not self.cache_timestamps:
            return
            
        # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œç§»é™¤æœ€è€çš„æ¡ç›®
        sorted_entries = sorted(self.cache_timestamps.items(), key=lambda x: x[1])
        
        # ç§»é™¤æœ€è€çš„25%æ¡ç›®
        evict_count = max(1, len(sorted_entries) // 4)
        
        for cache_key, _ in sorted_entries[:evict_count]:
            if cache_key in self.cache:
                del self.cache[cache_key]
            if cache_key in self.cache_timestamps:
                del self.cache_timestamps[cache_key]
            self.stats['cache_evictions'] += 1
        
        logger.debug(f"ç¼“å­˜æ¸…ç†ï¼šç§»é™¤äº† {evict_count} ä¸ªè€æ—§æ¡ç›®")
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        cache_size = len(self.cache)
        self.cache.clear()
        self.cache_timestamps.clear()
        logger.info(f"ç¼“å­˜å·²æ¸…ç©ºï¼Œç§»é™¤äº† {cache_size} ä¸ªæ¡ç›®")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'cache_size': len(self.cache),
            'max_cache_size': self.max_cache_size,
            'cache_hit_rate': self.stats['cache_hits'] / max(1, self.stats['cache_hits'] + self.stats['cache_misses']),
            'total_evictions': self.stats['cache_evictions']
        }
    
    def get_market_data(self, symbol: str, days: int = 60) -> pd.DataFrame:
        """
        è·å–å¸‚åœºæ•°æ® - ç»Ÿä¸€æ•°æ®æº
        ä½¿ç”¨Polygon 15åˆ†é’Ÿå»¶è¿Ÿæ•°æ®
        """
        if not self._validate_client():
            return pd.DataFrame()
        
        cache_key = self._get_cache_key(symbol, "market_data", days)
        cached = self._get_cached_result(cache_key)
        if cached is not None:
            return cached
        
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=max(days * 2, 120))  # ç¡®ä¿è¶³å¤Ÿçš„æ•°æ®
            
            data = self.client.get_historical_bars(
                symbol,
                start_date.strftime('%Y-%m-%d'),
                end_date.strftime('%Y-%m-%d'),
                'day',
                1
            )
            
            if not data.empty and len(data) > 0:
                # æ·»åŠ å¿…è¦çš„æŠ€æœ¯æŒ‡æ ‡åˆ—
                data['Returns'] = data['Close'].pct_change()
                data['Volume_MA20'] = data['Volume'].rolling(20).mean()
                data['Price_MA20'] = data['Close'].rolling(20).mean()
                data['Price_MA5'] = data['Close'].rolling(5).mean()
                data['Price_MA50'] = data['Close'].rolling(50).mean()
                data['Volatility_20'] = data['Returns'].rolling(20).std()
                
                # å»é™¤NaNå€¼
                data = data.dropna()
                
                self._set_cache(cache_key, data)
                self.stats['successful_calculations'] += 1
                return data
            else:
                logger.warning(f"No data received for {symbol}")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Failed to get market data for {symbol}: {e}")
            self.stats['failed_calculations'] += 1
            return pd.DataFrame()
        finally:
            self.stats['total_calculations'] += 1
    
    # ===============================
    # æ ¸å¿ƒå› å­ - AutoTraderå¼•æ“ä½¿ç”¨
    # ===============================
    
    def calculate_zscore(self, values: List[float], n: int = 20) -> List[float]:
        """
        Z-Scoreè®¡ç®— - AutoTraderæ ¸å¿ƒå‡å€¼å›å½’ä¿¡å·
        ç§»æ¤è‡ªautotrader.factors.zscore
        """
        try:
            if len(values) < n:
                return [math.nan] * len(values)
            
            out = []
            for i in range(len(values)):
                if i < n - 1:
                    out.append(math.nan)
                else:
                    window = values[i - n + 1:i + 1]
                    mean_val = sum(window) / n
                    variance = sum((x - mean_val) ** 2 for x in window) / n
                    std_val = math.sqrt(variance) if variance > 0 else 0
                    
                    if std_val > 0:
                        z = (values[i] - mean_val) / std_val
                        out.append(z)
                    else:
                        out.append(0.0)
            
            return out
        except Exception as e:
            logger.error(f"Z-score calculation failed: {e}")
            return [math.nan] * len(values)
    
    def calculate_atr(self, highs: List[float], lows: List[float], closes: List[float], n: int = 14) -> List[float]:
        """
        ATR (Average True Range) è®¡ç®—
        ç§»æ¤è‡ªautotrader.factors.atr
        """
        try:
            if len(highs) != len(lows) or len(highs) != len(closes):
                return [math.nan] * len(closes)
            
            # è®¡ç®—True Range
            tr_values = []
            for i in range(len(closes)):
                if i == 0:
                    tr = highs[i] - lows[i]
                else:
                    tr = max(
                        highs[i] - lows[i],
                        abs(highs[i] - closes[i - 1]),
                        abs(lows[i] - closes[i - 1])
                    )
                tr_values.append(tr)
            
            # è®¡ç®—SMA of TR
            atr_values = []
            for i in range(len(tr_values)):
                if i < n - 1:
                    atr_values.append(math.nan)
                else:
                    window_tr = tr_values[i - n + 1:i + 1]
                    atr = sum(window_tr) / n
                    atr_values.append(atr)
            
            return atr_values
        except Exception as e:
            logger.error(f"ATR calculation failed: {e}")
            return [math.nan] * len(closes)
    
    def calculate_sma(self, values: List[float], n: int) -> List[float]:
        """ç®€å•ç§»åŠ¨å¹³å‡è®¡ç®—"""
        try:
            out = []
            for i in range(len(values)):
                if i < n - 1:
                    out.append(math.nan)
                else:
                    window = values[i - n + 1:i + 1]
                    sma = sum(window) / n
                    out.append(sma)
            return out
        except Exception as e:
            logger.error(f"SMA calculation failed: {e}")
            return [math.nan] * len(values)
    
    def calculate_mean_reversion_signal(self, symbol: str) -> FactorResult:
        """
        å‡å€¼å›å½’ä¿¡å· - AutoTraderä¸»è¦ç­–ç•¥
        åŸºäº20æ—¥Z-Scoreï¼Œç§»æ¤è‡ªengine.pyçš„mr_signal
        """
        try:
            data = self.get_market_data(symbol, days=60)
            if data.empty or len(data) < 20:
                return self._create_failed_result('mean_reversion', 'Insufficient data')
            
            closes = data['Close'].tolist()
            z_scores = self.calculate_zscore(closes, 20)
            
            if not z_scores or len(z_scores) == 0:
                return self._create_failed_result('mean_reversion', 'Z-score calculation failed')
            
            current_z = z_scores[-1]
            if math.isnan(current_z):
                return self._create_failed_result('mean_reversion', 'Invalid Z-score')
            
            # AutoTraderä¿¡å·é€»è¾‘
            if current_z > 2.5:
                signal = -1.0  # å¼ºå–å‡ºä¿¡å·
            elif current_z > 1.5:
                signal = -0.5  # å¼±å–å‡ºä¿¡å·
            elif current_z < -2.5:
                signal = 1.0   # å¼ºä¹°å…¥ä¿¡å·
            elif current_z < -1.5:
                signal = 0.5   # å¼±ä¹°å…¥ä¿¡å·
            else:
                signal = -current_z  # çº¿æ€§ç¼©æ”¾
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = min(abs(current_z) / 2.5, 1.0) * 0.9
            
            return FactorResult(
                factor_name='mean_reversion',
                value=signal,
                confidence=confidence,
                timestamp=datetime.now(),
                metadata={
                    'z_score': current_z,
                    'data_points': len(closes),
                    'lookback_period': 20
                },
                data_quality_score=0.95 if len(data) >= 30 else 0.8
            )
            
        except Exception as e:
            logger.error(f"Mean reversion calculation failed for {symbol}: {e}")
            return self._create_failed_result('mean_reversion', str(e))
    
    def calculate_momentum_signal(self, symbol: str, period: int = 20) -> FactorResult:
        """
        åŠ¨é‡ä¿¡å·è®¡ç®—
        ç§»æ¤è‡ªengine.pyçš„calculate_momentum
        """
        try:
            data = self.get_market_data(symbol, days=60)
            if data.empty or len(data) < period + 1:
                return self._create_failed_result('momentum', 'Insufficient data')
            
            prices = data['Close'].tolist()
            
            # è®¡ç®—æ”¶ç›Šç‡
            returns = []
            for i in range(1, len(prices)):
                if prices[i] > 0 and prices[i-1] > 0:
                    ret = (prices[i] - prices[i-1]) / prices[i-1]
                    returns.append(ret)
            
            if len(returns) < period:
                return self._create_failed_result('momentum', 'Insufficient returns data')
            
            # ä½¿ç”¨æœ€è¿‘periodä¸ªæ”¶ç›Šç‡è®¡ç®—åŠ¨é‡
            recent_returns = returns[-period:]
            momentum = sum(recent_returns) / len(recent_returns)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            volatility = np.std(recent_returns) if len(recent_returns) > 1 else 0
            confidence = min(abs(momentum) / (volatility + 1e-6), 1.0) * 0.8
            
            return FactorResult(
                factor_name='momentum',
                value=momentum,
                confidence=confidence,
                timestamp=datetime.now(),
                metadata={
                    'period': period,
                    'avg_returns': momentum,
                    'volatility': volatility,
                    'data_points': len(recent_returns)
                },
                data_quality_score=0.9
            )
            
        except Exception as e:
            logger.error(f"Momentum calculation failed for {symbol}: {e}")
            return self._create_failed_result('momentum', str(e))
    
    def calculate_trend_signal(self, symbol: str) -> FactorResult:
        """
        è¶‹åŠ¿ä¿¡å·è®¡ç®—
        ç§»æ¤è‡ªengine.pyçš„multi_factor_signalä¸­çš„è¶‹åŠ¿éƒ¨åˆ†
        """
        try:
            data = self.get_market_data(symbol, days=60)
            if data.empty or len(data) < 50:
                return self._create_failed_result('trend', 'Insufficient data')
            
            closes = data['Close'].tolist()
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            sma5 = sum(closes[-5:]) / 5
            sma20 = sum(closes[-20:]) / 20
            sma50 = sum(closes[-50:]) / 50
            
            trend_score = 0.0
            current_price = closes[-1]
            
            # è¶‹åŠ¿è¯„åˆ†é€»è¾‘ï¼ˆæ¥è‡ªengine.pyï¼‰
            if sma5 > sma20 > sma50:
                trend_score += 0.4
            elif sma5 > sma20:
                trend_score += 0.2
            elif current_price > sma20:
                trend_score += 0.1
            
            # å‡çº¿æ–œç‡
            if len(closes) >= 25:
                sma20_prev = sum(closes[-25:-5]) / 20
                if sma20_prev > 0:
                    slope = (sma20 - sma20_prev) / abs(sma20_prev)
                    if slope > 0.01:
                        trend_score += 0.3
                    elif slope > 0:
                        trend_score += 0.1
            
            # ä»·æ ¼ç›¸å¯¹ä½ç½®
            if current_price > sma5 * 1.02:
                trend_score += 0.3
            elif current_price > sma5:
                trend_score += 0.2
            
            # å½’ä¸€åŒ–åˆ°[-1, 1]
            normalized_trend = max(-1.0, min(1.0, trend_score))
            
            # è®¡ç®—ç½®ä¿¡åº¦
            price_variance = np.var(closes[-20:]) if len(closes) >= 20 else 0
            confidence = 0.8 if abs(normalized_trend) > 0.3 else 0.6
            
            return FactorResult(
                factor_name='trend',
                value=normalized_trend,
                confidence=confidence,
                timestamp=datetime.now(),
                metadata={
                    'sma5': sma5,
                    'sma20': sma20,
                    'sma50': sma50,
                    'trend_score': trend_score,
                    'current_price': current_price
                },
                data_quality_score=0.9
            )
            
        except Exception as e:
            logger.error(f"Trend calculation failed for {symbol}: {e}")
            return self._create_failed_result('trend', str(e))
    
    def calculate_volume_signal(self, symbol: str) -> FactorResult:
        """
        æˆäº¤é‡ä¿¡å·è®¡ç®—
        ç§»æ¤è‡ªengine.pyçš„multi_factor_signalä¸­çš„æˆäº¤é‡éƒ¨åˆ†
        """
        try:
            data = self.get_market_data(symbol, days=40)
            if data.empty or len(data) < 20:
                return self._create_failed_result('volume', 'Insufficient data')
            
            volumes = data['Volume'].tolist()
            
            volume_score = 0.0
            
            # 20æ—¥å‡é‡æ¯”è¾ƒ
            if len(volumes) >= 20:
                v20 = sum(volumes[-20:]) / 20
                v_current = max(volumes[-1], 0.0)
                ratio = v_current / v20 if v20 > 0 else 1.0
                
                if ratio > 1.5:
                    volume_score += 0.4
                elif ratio > 1.2:
                    volume_score += 0.2
                elif ratio > 0.8:
                    volume_score += 0.1
                
                # è¿‘5æ—¥ç›¸å¯¹æå‡
                if len(volumes) >= 20:
                    recent5 = sum(volumes[-5:]) / 5
                    prev15 = sum(volumes[-20:-5]) / 15
                    if recent5 > prev15 * 1.2:
                        volume_score += 0.3
                    elif recent5 > prev15:
                        volume_score += 0.1
            
            # å½’ä¸€åŒ–
            normalized_volume = max(-1.0, min(1.0, volume_score))
            
            # è®¡ç®—ç½®ä¿¡åº¦
            volume_stability = 1.0 / (1.0 + np.std(volumes[-10:]) / np.mean(volumes[-10:]))
            confidence = volume_stability * 0.7
            
            return FactorResult(
                factor_name='volume',
                value=normalized_volume,
                confidence=confidence,
                timestamp=datetime.now(),
                metadata={
                    'volume_score': volume_score,
                    'current_volume': volumes[-1],
                    'avg_volume_20d': sum(volumes[-20:]) / 20 if len(volumes) >= 20 else 0,
                    'volume_ratio': ratio if 'ratio' in locals() else 1.0
                },
                data_quality_score=0.85
            )
            
        except Exception as e:
            logger.error(f"Volume calculation failed for {symbol}: {e}")
            return self._create_failed_result('volume', str(e))
    
    def calculate_volatility_signal(self, symbol: str) -> FactorResult:
        """
        æ³¢åŠ¨ç‡ä¿¡å·è®¡ç®—
        åŸºäºATRå’Œé€‚å®œæ³¢åŠ¨ç‡åŒºé—´åˆ¤æ–­
        """
        try:
            data = self.get_market_data(symbol, days=30)
            if data.empty or len(data) < 15:
                return self._create_failed_result('volatility', 'Insufficient data')
            
            highs = data['High'].tolist()
            lows = data['Low'].tolist()
            closes = data['Close'].tolist()
            
            # è®¡ç®—ATR
            atr_values = self.calculate_atr(highs, lows, closes, 14)
            current_atr = atr_values[-1] if atr_values and not math.isnan(atr_values[-1]) else 0
            
            volatility_score = 0.0
            current_price = closes[-1]
            
            if current_atr > 0 and current_price > 0:
                atr_pct = (current_atr / current_price) * 100
                
                # é€‚å®œæ³¢åŠ¨ç‡åŒºé—´ï¼ˆæ¥è‡ªengine.pyï¼‰
                if 1.5 <= atr_pct <= 4.0:
                    volatility_score += 0.4
                elif 1.0 <= atr_pct <= 6.0:
                    volatility_score += 0.2
            
            # å½’ä¸€åŒ–
            normalized_volatility = max(-1.0, min(1.0, volatility_score))
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = 0.8 if current_atr > 0 else 0.3
            
            return FactorResult(
                factor_name='volatility',
                value=normalized_volatility,
                confidence=confidence,
                timestamp=datetime.now(),
                metadata={
                    'atr_14': current_atr,
                    'atr_percentage': (current_atr / current_price) * 100 if current_price > 0 else 0,
                    'volatility_score': volatility_score,
                    'current_price': current_price
                },
                data_quality_score=0.9
            )
            
        except Exception as e:
            logger.error(f"Volatility calculation failed for {symbol}: {e}")
            return self._create_failed_result('volatility', str(e))
    
    def calculate_composite_signal(self, symbol: str) -> FactorResult:
        """
        ç»¼åˆä¿¡å·è®¡ç®—
        æ•´åˆæ‰€æœ‰æ ¸å¿ƒå› å­ï¼Œç§»æ¤è‡ªengine.pyçš„multi_factor_signal
        """
        try:
            # è®¡ç®—å„ä¸ªå› å­
            mr_result = self.calculate_mean_reversion_signal(symbol)
            momentum_result = self.calculate_momentum_signal(symbol)
            trend_result = self.calculate_trend_signal(symbol)
            volume_result = self.calculate_volume_signal(symbol)
            volatility_result = self.calculate_volatility_signal(symbol)
            
            # æ„å»ºå› å­å­—å…¸
            factors = {
                'mean_reversion': mr_result.value if mr_result.confidence > 0.3 else 0.0,
                'momentum': momentum_result.value if momentum_result.confidence > 0.3 else 0.0,
                'trend': trend_result.value if trend_result.confidence > 0.3 else 0.0,
                'volume': volume_result.value if volume_result.confidence > 0.3 else 0.0,
                'volatility': volatility_result.value if volatility_result.confidence > 0.3 else 0.0
            }
            
            # åŠ æƒè®¡ç®—ç»¼åˆå¾—åˆ†
            composite_score = 0.0
            total_weight = 0.0
            
            # ä½¿ç”¨AutoTraderæƒé‡ï¼ˆæ¥è‡ªengine.pyï¼‰
            weights = {
                'trend': 0.30,
                'momentum': 0.25,
                'volume': 0.20,
                'volatility': 0.15,
                'mean_reversion': 0.30  # ä¸»è¦ä¿¡å·
            }
            
            for factor_name, weight in weights.items():
                if factor_name in factors and not math.isnan(factors[factor_name]):
                    composite_score += factors[factor_name] * weight
                    total_weight += weight
            
            # å½’ä¸€åŒ–
            if total_weight > 0:
                composite_score = composite_score / total_weight
            
            # æœ€ç»ˆé™åˆ¶åœ¨[-1, 1]
            final_score = max(-1.0, min(1.0, composite_score))
            
            # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            confidences = [mr_result.confidence, momentum_result.confidence, 
                          trend_result.confidence, volume_result.confidence, volatility_result.confidence]
            avg_confidence = sum(confidences) / len(confidences)
            
            # åº”ç”¨å»¶è¿Ÿæ•°æ®è°ƒæ•´
            if self.config.enabled:
                final_score *= self.config.min_alpha_multiplier
                final_score = max(-1.0, min(1.0, final_score))  # é‡æ–°é™åˆ¶
                avg_confidence = min(avg_confidence, self.config.min_confidence_threshold)
            
            return FactorResult(
                factor_name='composite',
                value=final_score,
                confidence=avg_confidence,
                timestamp=datetime.now(),
                metadata={
                    'individual_factors': factors,
                    'weights_used': weights,
                    'total_weight': total_weight,
                    'raw_score': composite_score,
                    'delay_adjusted': self.config.enabled,
                    'factors_count': len([f for f in factors.values() if not math.isnan(f)])
                },
                data_quality_score=min([r.data_quality_score for r in [mr_result, momentum_result, trend_result, volume_result, volatility_result]])
            )
            
        except Exception as e:
            logger.error(f"Composite signal calculation failed for {symbol}: {e}")
            return self._create_failed_result('composite', str(e))
    
    def _create_failed_result(self, factor_name: str, reason: str) -> FactorResult:
        """åˆ›å»ºå¤±è´¥ç»“æœ"""
        return FactorResult(
            factor_name=factor_name,
            value=0.0,
            confidence=0.0,
            timestamp=datetime.now(),
            metadata={'error': reason},
            data_quality_score=0.0
        )
    
    # ===============================
    # é«˜çº§å› å­æ¥å£
    # ===============================
    
    def calculate_all_signals(self, symbol: str) -> Dict[str, FactorResult]:
        """è®¡ç®—æ‰€æœ‰ä¿¡å·"""
        results = {}
        
        try:
            results['mean_reversion'] = self.calculate_mean_reversion_signal(symbol)
            results['momentum'] = self.calculate_momentum_signal(symbol)
            results['trend'] = self.calculate_trend_signal(symbol)
            results['volume'] = self.calculate_volume_signal(symbol)
            results['volatility'] = self.calculate_volatility_signal(symbol)
            results['composite'] = self.calculate_composite_signal(symbol)
            
        except Exception as e:
            logger.error(f"Failed to calculate all signals for {symbol}: {e}")
        
        return results
    
    def get_trading_signal(self, symbol: str, threshold: float = 0.3) -> Dict[str, Any]:
        """
        è·å–äº¤æ˜“ä¿¡å·
        è¿”å›AutoTraderå¼•æ“å…¼å®¹çš„ä¿¡å·æ ¼å¼
        """
        try:
            composite_result = self.calculate_composite_signal(symbol)
            
            signal_strength = abs(composite_result.value)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³äº¤æ˜“æ¡ä»¶
            meets_threshold = signal_strength >= threshold
            meets_confidence = composite_result.confidence >= self.config.min_confidence_threshold
            
            # å»¶è¿Ÿæ•°æ®äº¤æ˜“æ—¶é—´æ£€æŸ¥
            can_trade_delayed, delay_reason = should_trade_with_delayed_data(self.config)
            
            can_trade = meets_threshold and meets_confidence and can_trade_delayed
            
            # ç¡®å®šäº¤æ˜“æ–¹å‘
            side = "BUY" if composite_result.value > 0 else "SELL"
            
            return {
                'symbol': symbol,
                'signal_value': composite_result.value,
                'signal_strength': signal_strength,
                'confidence': composite_result.confidence,
                'side': side,
                'can_trade': can_trade,
                'meets_threshold': meets_threshold,
                'meets_confidence': meets_confidence,
                'can_trade_delayed': can_trade_delayed,
                'threshold': threshold,
                'timestamp': composite_result.timestamp,
                'data_quality': composite_result.data_quality_score,
                'delay_reason': delay_reason if not can_trade_delayed else None,
                'metadata': composite_result.metadata
            }
            
        except Exception as e:
            logger.error(f"Failed to get trading signal for {symbol}: {e}")
            return {
                'symbol': symbol,
                'signal_value': 0.0,
                'signal_strength': 0.0,
                'confidence': 0.0,
                'side': 'HOLD',
                'can_trade': False,
                'error': str(e),
                'timestamp': datetime.now()
            }
    
    def validate_polygon_data(self, symbol: str) -> Dict[str, Any]:
        """éªŒè¯Polygonæ•°æ®è´¨é‡å’Œå»¶è¿Ÿ"""
        try:
            data = self.get_market_data(symbol, days=5)
            
            if data.empty:
                return {
                    'symbol': symbol,
                    'data_available': False,
                    'error': 'No data available'
                }
            
            latest_date = data.index[-1]
            data_age_hours = (datetime.now() - latest_date.to_pydatetime()).total_seconds() / 3600
            
            # è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡
            price_gaps = (data['Close'].pct_change().abs() > 0.1).sum()  # å¤§äº10%çš„ä»·æ ¼è·³ç©º
            zero_volume_days = (data['Volume'] == 0).sum()
            
            data_quality = 1.0
            if price_gaps > 0:
                data_quality -= 0.2 * price_gaps / len(data)
            if zero_volume_days > 0:
                data_quality -= 0.3 * zero_volume_days / len(data)
            
            return {
                'symbol': symbol,
                'data_available': True,
                'latest_date': latest_date.strftime('%Y-%m-%d %H:%M:%S'),
                'data_age_hours': data_age_hours,
                'within_delay_window': data_age_hours <= (self.config.data_delay_minutes / 60 + 24),  # å»¶è¿Ÿ+1å¤©ç¼“å†²
                'data_points': len(data),
                'price_gaps': price_gaps,
                'zero_volume_days': zero_volume_days,
                'data_quality_score': max(0.0, data_quality),
                'delay_minutes': self.config.data_delay_minutes,
                'polygon_connected': self.client is not None
            }
            
        except Exception as e:
            logger.error(f"Data validation failed for {symbol}: {e}")
            return {
                'symbol': symbol,
                'data_available': False,
                'error': str(e),
                'polygon_connected': self.client is not None
            }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        stats['cache_size'] = len(self.cache)
        stats['config'] = self.config.__dict__
        stats['polygon_available'] = self.client is not None
        return stats
    
    def clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        self.cache.clear()
        logger.info("Factor cache cleared")

# å…¨å±€å®ä¾‹
_unified_factors_instance = None

def get_unified_polygon_factors(config: DelayedDataConfig = None) -> UnifiedPolygonFactors:
    """è·å–ç»Ÿä¸€å› å­åº“å®ä¾‹"""
    global _unified_factors_instance
    if _unified_factors_instance is None:
        _unified_factors_instance = UnifiedPolygonFactors(config)
    return _unified_factors_instance

# ä¾¿æ·å‡½æ•° - AutoTraderå¼•æ“å…¼å®¹æ¥å£
def zscore(values: List[float], n: int = 20) -> List[float]:
    """Z-Scoreè®¡ç®— - å‘åå…¼å®¹"""
    factors = get_unified_polygon_factors()
    return factors.calculate_zscore(values, n)

def atr(highs: List[float], lows: List[float], closes: List[float], n: int = 14) -> List[float]:
    """ATRè®¡ç®— - å‘åå…¼å®¹"""
    factors = get_unified_polygon_factors()
    return factors.calculate_atr(highs, lows, closes, n)

def sma(values: List[float], n: int) -> List[float]:
    """ç®€å•ç§»åŠ¨å¹³å‡ - å‘åå…¼å®¹autotrader.factors"""
    out: List[float] = []
    s = 0.0
    for i, v in enumerate(values):
        s += v
        if i >= n:
            s -= values[i - n]
        out.append(s / n if i >= n - 1 else math.nan)
    return out

def stddev(values: List[float], n: int) -> List[float]:
    """æ ‡å‡†å·®è®¡ç®— - å‘åå…¼å®¹autotrader.factors"""
    out: List[float] = []
    s = 0.0
    s2 = 0.0
    for i, v in enumerate(values):
        s += v
        s2 += v * v
        if i >= n:
            s -= values[i - n]
            s2 -= values[i - n] * values[i - n]
        if i >= n - 1:
            mean = s / n
            var = max(s2 / n - mean * mean, 0.0)
            out.append(math.sqrt(var))
        else:
            out.append(math.nan)
    return out

def rsi(values: List[float], n: int) -> List[float]:
    """RSIæŒ‡æ ‡è®¡ç®— - å‘åå…¼å®¹autotrader.factors"""
    gains = [0.0]
    losses = [0.0]
    for i in range(1, len(values)):
        chg = values[i] - values[i - 1]
        gains.append(max(chg, 0.0))
        losses.append(max(-chg, 0.0))
    avg_gain = sma(gains, n)
    avg_loss = sma(losses, n)
    out: List[float] = []
    for g, l in zip(avg_gain, avg_loss):
        if math.isnan(g) or math.isnan(l) or l == 0:
            out.append(math.nan)
        else:
            rs = g / l
            out.append(100.0 - 100.0 / (1.0 + rs))
    return out

def bollinger(values: List[float], n: int, k: float = 2.0) -> Tuple[List[float], List[float], List[float]]:
    """å¸ƒæ—å¸¦è®¡ç®— - å‘åå…¼å®¹autotrader.factors"""
    ma = sma(values, n)
    sd = stddev(values, n)
    upper: List[float] = []
    lower: List[float] = []
    for m, s in zip(ma, sd):
        if math.isnan(m) or math.isnan(s):
            upper.append(math.nan)
            lower.append(math.nan)
        else:
            upper.append(m + k * s)
            lower.append(m - k * s)
    return ma, upper, lower

def get_trading_signal_for_autotrader(symbol: str, threshold: float = 0.3) -> Dict[str, Any]:
    """ä¸ºAutoTraderå¼•æ“æä¾›äº¤æ˜“ä¿¡å·"""
    factors = get_unified_polygon_factors()
    return factors.get_trading_signal(symbol, threshold)

# å…¼å®¹polygon_unified_factors.pyçš„å‡½æ•°
def get_polygon_unified_factors():
    """å…¼å®¹æ€§å‡½æ•° - è¿”å›ç»Ÿä¸€å› å­å®ä¾‹"""
    return get_unified_polygon_factors()

def enable_polygon_factors():
    """å¯ç”¨Polygonå› å­ - å…¼å®¹æ€§å‡½æ•°"""
    manager = get_unified_polygon_factors()
    logger.info("Polygonå› å­å·²å¯ç”¨")

def enable_polygon_risk_balancer():
    """å¯ç”¨Polygoné£é™©å¹³è¡¡å™¨ - å…¼å®¹æ€§å‡½æ•°"""
    manager = get_unified_polygon_factors()
    logger.info("Polygoné£é™©å¹³è¡¡å™¨å·²å¯ç”¨")

def disable_polygon_risk_balancer():
    """ç¦ç”¨Polygoné£é™©å¹³è¡¡å™¨ - å…¼å®¹æ€§å‡½æ•°"""
    manager = get_unified_polygon_factors()
    logger.info("Polygoné£é™©å¹³è¡¡å™¨å·²ç¦ç”¨")

def check_polygon_trading_conditions(symbol: str) -> Dict[str, Any]:
    """æ£€æŸ¥Polygonäº¤æ˜“æ¡ä»¶ - å…¼å®¹æ€§å‡½æ•°"""
    manager = get_unified_polygon_factors()
    validation = manager.validate_polygon_data(symbol)
    return {
        'trading_allowed': validation.get('data_available', False),
        'data_quality': validation.get('data_quality_score', 0.0),
        'last_update': validation.get('latest_data_time', 'Unknown'),
        'conditions_met': validation.get('data_available', False)
    }

def process_signals_with_polygon(signals) -> List[Dict]:
    """ä½¿ç”¨Polygonå¤„ç†ä¿¡å· - å…¼å®¹æ€§å‡½æ•°"""
    manager = get_unified_polygon_factors()
    processed_signals = []
    
    # å¤„ç†ä¸åŒè¾“å…¥æ ¼å¼
    if hasattr(signals, 'to_dict'):  # DataFrame
        signals_list = signals.to_dict('records')
    elif isinstance(signals, list):
        signals_list = signals
    else:
        signals_list = [signals]
    
    for signal in signals_list:
        if isinstance(signal, dict) and 'symbol' in signal:
            try:
                # ä½¿ç”¨ç»Ÿä¸€å› å­éªŒè¯å’Œå¢å¼ºä¿¡å·
                enhanced_signal = manager.get_trading_signal(signal['symbol'])
                signal.update(enhanced_signal)
                processed_signals.append(signal)
            except Exception as e:
                logger.warning(f"å¤„ç†ä¿¡å·å¤±è´¥ {signal.get('symbol', 'Unknown')}: {e}")
                processed_signals.append(signal)  # ä¿ç•™åŸä¿¡å·
        else:
            processed_signals.append(signal)
    
    return processed_signals

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("AutoTraderç»Ÿä¸€å› å­åº“æµ‹è¯•")
    print("=" * 50)
    
    factors = get_unified_polygon_factors()
    
    # æµ‹è¯•å•ä¸ªè‚¡ç¥¨
    test_symbol = "AAPL"
    print(f"æµ‹è¯•è‚¡ç¥¨: {test_symbol}")
    
    # æ•°æ®éªŒè¯
    validation = factors.validate_polygon_data(test_symbol)
    print(f"æ•°æ®éªŒè¯: {validation}")
    
    if validation['data_available']:
        # äº¤æ˜“ä¿¡å·
        signal = factors.get_trading_signal(test_symbol)
        print(f"äº¤æ˜“ä¿¡å·: {signal}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = factors.get_stats()
        print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")
    else:
        print("æ•°æ®ä¸å¯ç”¨ï¼Œè·³è¿‡ä¿¡å·æµ‹è¯•")