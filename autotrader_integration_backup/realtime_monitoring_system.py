#!/usr/bin/env python3
"""
ğŸ“ˆ P1çº§åˆ«ä¿®å¤ï¼šå®æ—¶ç›‘æ§æŒ‡æ ‡ç³»ç»Ÿ
=======================================

å®ç°å…³é”®äº¤æ˜“æŒ‡æ ‡çš„å®æ—¶ç›‘æ§ï¼ŒåŒ…æ‹¬ï¼š
- è®¢å•å»¶è¿Ÿç›‘æ§ (order_latency)
- èµ„é‡‘åˆ©ç”¨ç‡ç›‘æ§ (capital_utilization)  
- æ•°æ®æ–°é²œåº¦ç›‘æ§ (data_freshness)
- æ‹’å•ç‡ç›‘æ§ (rejection_rate)
- èƒœç‡ç›‘æ§ (win_rate)
- PnLè·Ÿè¸ª (pnl_tracking)
"""

import time
import logging
import sqlite3
import json
import threading
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from pathlib import Path
from collections import deque, defaultdict
import statistics
import asyncio

logger = logging.getLogger(__name__)


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    GAUGE = "GAUGE"          # ç¬æ—¶å€¼
    COUNTER = "COUNTER"      # ç´¯è®¡è®¡æ•°
    HISTOGRAM = "HISTOGRAM"  # åˆ†å¸ƒç»Ÿè®¡
    RATE = "RATE"           # é€Ÿç‡


@dataclass
class MetricPoint:
    """æŒ‡æ ‡æ•°æ®ç‚¹"""
    name: str
    value: float
    timestamp: datetime
    tags: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    alert_id: str
    metric_name: str
    level: AlertLevel
    message: str
    value: float
    threshold: float
    timestamp: datetime
    resolved: bool = False
    resolved_at: Optional[datetime] = None


class MetricCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, name: str, metric_type: MetricType, 
                 retention_seconds: int = 3600):
        self.name = name
        self.metric_type = metric_type
        self.retention_seconds = retention_seconds
        self._data_points = deque()
        self._lock = threading.RLock()
    
    def add_point(self, value: float, tags: Dict[str, str] = None, 
                  metadata: Dict[str, Any] = None):
        """æ·»åŠ æ•°æ®ç‚¹"""
        point = MetricPoint(
            name=self.name,
            value=value,
            timestamp=datetime.now(timezone.utc),
            tags=tags or {},
            metadata=metadata or {}
        )
        
        with self._lock:
            self._data_points.append(point)
            # æ¸…ç†è¿‡æœŸæ•°æ®
            self._cleanup_old_points()
    
    def _cleanup_old_points(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®ç‚¹"""
        cutoff_time = datetime.now(timezone.utc) - timedelta(seconds=self.retention_seconds)
        while self._data_points and self._data_points[0].timestamp < cutoff_time:
            self._data_points.popleft()
    
    def get_current_value(self) -> Optional[float]:
        """è·å–å½“å‰å€¼"""
        with self._lock:
            if not self._data_points:
                return None
            return self._data_points[-1].value
    
    def get_statistics(self, window_seconds: int = 300) -> Dict[str, float]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆé»˜è®¤5åˆ†é’Ÿçª—å£ï¼‰"""
        cutoff_time = datetime.now(timezone.utc) - timedelta(seconds=window_seconds)
        
        with self._lock:
            values = [p.value for p in self._data_points if p.timestamp >= cutoff_time]
            
            if not values:
                return {}
            
            return {
                'count': len(values),
                'min': min(values),
                'max': max(values),
                'mean': statistics.mean(values),
                'median': statistics.median(values),
                'stdev': statistics.stdev(values) if len(values) > 1 else 0.0,
                'p95': self._percentile(values, 0.95),
                'p99': self._percentile(values, 0.99)
            }
    
    def _percentile(self, values: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not values:
            return 0.0
        sorted_values = sorted(values)
        index = int(len(sorted_values) * percentile)
        return sorted_values[min(index, len(sorted_values) - 1)]


class RealtimeMonitoringSystem:
    """å®æ—¶ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self, db_path: str = "data/monitoring.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æŒ‡æ ‡æ”¶é›†å™¨
        self._collectors: Dict[str, MetricCollector] = {}
        
        # å‘Šè­¦é…ç½®
        self._alert_rules: Dict[str, Dict[str, Any]] = {}
        self._active_alerts: Dict[str, Alert] = {}
        
        # å‘Šè­¦å›è°ƒ
        self._alert_callbacks: List[Callable[[Alert], None]] = []
        
        # ç›‘æ§çº¿ç¨‹
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        
        self._lock = threading.RLock()
        
        self._init_database()
        self._init_standard_metrics()
        self._start_monitoring()
        
        logger.info("Realtime monitoring system initialized")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # æŒ‡æ ‡è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL,
                    value REAL NOT NULL,
                    timestamp TEXT NOT NULL,
                    tags TEXT,
                    metadata TEXT
                );
                CREATE INDEX IF NOT EXISTS idx_metrics_name ON metrics(name);
                CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON metrics(timestamp)
                )
            """)
            
            # å‘Šè­¦è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS alerts (
                    alert_id TEXT PRIMARY KEY,
                    metric_name TEXT NOT NULL,
                    level TEXT NOT NULL,
                    message TEXT NOT NULL,
                    value REAL NOT NULL,
                    threshold REAL NOT NULL,
                    timestamp TEXT NOT NULL,
                    resolved BOOLEAN DEFAULT FALSE,
                    resolved_at TEXT
                );
                CREATE INDEX IF NOT EXISTS idx_alerts_metric_name ON alerts(metric_name);
                CREATE INDEX IF NOT EXISTS idx_alerts_level ON alerts(level);
                CREATE INDEX IF NOT EXISTS idx_alerts_timestamp ON alerts(timestamp)
                )
            """)
            
            conn.commit()
    
    def _init_standard_metrics(self):
        """åˆå§‹åŒ–æ ‡å‡†æŒ‡æ ‡"""
        # æ ¸å¿ƒäº¤æ˜“æŒ‡æ ‡
        self.register_metric("order_latency_ms", MetricType.HISTOGRAM)
        self.register_metric("capital_utilization_pct", MetricType.GAUGE)  
        self.register_metric("data_freshness_seconds", MetricType.GAUGE)
        self.register_metric("rejection_rate_pct", MetricType.GAUGE)
        self.register_metric("win_rate_pct", MetricType.GAUGE)
        self.register_metric("unrealized_pnl_usd", MetricType.GAUGE)
        self.register_metric("realized_pnl_usd", MetricType.COUNTER)
        
        # ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
        self.register_metric("orders_per_second", MetricType.RATE)
        self.register_metric("fills_per_second", MetricType.RATE)
        self.register_metric("memory_usage_mb", MetricType.GAUGE)
        self.register_metric("cpu_usage_pct", MetricType.GAUGE)
        
        # é…ç½®é»˜è®¤å‘Šè­¦é˜ˆå€¼
        self.set_alert_rule("order_latency_ms", {
            'max_threshold': 1000,  # 1ç§’
            'level': AlertLevel.WARNING,
            'message_template': "Order latency too high: {value:.1f}ms > {threshold}ms"
        })
        
        self.set_alert_rule("capital_utilization_pct", {
            'max_threshold': 95,
            'level': AlertLevel.WARNING,
            'message_template': "Capital utilization high: {value:.1f}% > {threshold}%"
        })
        
        self.set_alert_rule("data_freshness_seconds", {
            'max_threshold': 300,  # 5åˆ†é’Ÿ
            'level': AlertLevel.ERROR,
            'message_template': "Data staleness detected: {value:.1f}s > {threshold}s"
        })
        
        self.set_alert_rule("rejection_rate_pct", {
            'max_threshold': 5,  # 5%
            'level': AlertLevel.WARNING,
            'message_template': "High rejection rate: {value:.1f}% > {threshold}%"
        })
    
    def register_metric(self, name: str, metric_type: MetricType, 
                       retention_seconds: int = 3600):
        """æ³¨å†Œæ–°æŒ‡æ ‡"""
        with self._lock:
            if name in self._collectors:
                logger.warning(f"Metric {name} already registered")
                return
            
            self._collectors[name] = MetricCollector(name, metric_type, retention_seconds)
            logger.info(f"Registered metric: {name} ({metric_type.value})")
    
    def record_metric(self, name: str, value: float, 
                     tags: Dict[str, str] = None, 
                     metadata: Dict[str, Any] = None):
        """è®°å½•æŒ‡æ ‡å€¼"""
        if name not in self._collectors:
            logger.warning(f"Unknown metric: {name}")
            return
        
        self._collectors[name].add_point(value, tags, metadata)
        
        # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
        threading.Thread(
            target=self._save_metric_to_db,
            args=(name, value, tags, metadata),
            daemon=True
        ).start()
        
        # æ£€æŸ¥å‘Šè­¦
        self._check_alerts(name, value)
    
    def _save_metric_to_db(self, name: str, value: float,
                          tags: Dict[str, str] = None,
                          metadata: Dict[str, Any] = None):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO metrics (name, value, timestamp, tags, metadata)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    name, value, datetime.now(timezone.utc).isoformat(),
                    json.dumps(tags) if tags else None,
                    json.dumps(metadata) if metadata else None
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save metric {name}: {e}")
    
    def set_alert_rule(self, metric_name: str, rule_config: Dict[str, Any]):
        """è®¾ç½®å‘Šè­¦è§„åˆ™"""
        with self._lock:
            self._alert_rules[metric_name] = rule_config
            logger.info(f"Alert rule set for {metric_name}: {rule_config}")
    
    def _check_alerts(self, metric_name: str, value: float):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        if metric_name not in self._alert_rules:
            return
        
        rule = self._alert_rules[metric_name]
        
        # æ£€æŸ¥æœ€å¤§é˜ˆå€¼
        if 'max_threshold' in rule and value > rule['max_threshold']:
            self._trigger_alert(metric_name, value, rule['max_threshold'], rule)
        
        # æ£€æŸ¥æœ€å°é˜ˆå€¼
        elif 'min_threshold' in rule and value < rule['min_threshold']:
            self._trigger_alert(metric_name, value, rule['min_threshold'], rule)
    
    def _trigger_alert(self, metric_name: str, value: float, threshold: float, rule: Dict[str, Any]):
        """è§¦å‘å‘Šè­¦"""
        alert_key = f"{metric_name}_{rule.get('level', 'WARNING')}"
        
        # é¿å…é‡å¤å‘Šè­¦ï¼ˆ5åˆ†é’Ÿå†…ï¼‰
        if alert_key in self._active_alerts:
            last_alert = self._active_alerts[alert_key]
            if (datetime.now(timezone.utc) - last_alert.timestamp).total_seconds() < 300:
                return
        
        # åˆ›å»ºå‘Šè­¦
        alert = Alert(
            alert_id=f"{int(time.time())}_{alert_key}",
            metric_name=metric_name,
            level=AlertLevel(rule.get('level', 'WARNING')),
            message=rule.get('message_template', 'Alert: {metric} = {value}').format(
                metric=metric_name, value=value, threshold=threshold
            ),
            value=value,
            threshold=threshold,
            timestamp=datetime.now(timezone.utc)
        )
        
        with self._lock:
            self._active_alerts[alert_key] = alert
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_alert_to_db(alert)
            
            # è§¦å‘å›è°ƒ
            for callback in self._alert_callbacks:
                try:
                    callback(alert)
                except Exception as e:
                    logger.error(f"Alert callback failed: {e}")
        
        logger.warning(f"ALERT [{alert.level.value}] {alert.message}")
    
    def _save_alert_to_db(self, alert: Alert):
        """ä¿å­˜å‘Šè­¦åˆ°æ•°æ®åº“"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO alerts 
                    (alert_id, metric_name, level, message, value, threshold, timestamp, resolved, resolved_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    alert.alert_id, alert.metric_name, alert.level.value, alert.message,
                    alert.value, alert.threshold, alert.timestamp.isoformat(),
                    alert.resolved, alert.resolved_at.isoformat() if alert.resolved_at else None
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to save alert: {e}")
    
    def add_alert_callback(self, callback: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å›è°ƒ"""
        with self._lock:
            self._alert_callbacks.append(callback)
    
    def get_metric_value(self, name: str) -> Optional[float]:
        """è·å–æŒ‡æ ‡å½“å‰å€¼"""
        if name not in self._collectors:
            return None
        return self._collectors[name].get_current_value()
    
    def get_metric_statistics(self, name: str, window_seconds: int = 300) -> Dict[str, float]:
        """è·å–æŒ‡æ ‡ç»Ÿè®¡ä¿¡æ¯"""
        if name not in self._collectors:
            return {}
        return self._collectors[name].get_statistics(window_seconds)
    
    def get_dashboard_data(self) -> Dict[str, Any]:
        """è·å–ä»ªè¡¨ç›˜æ•°æ®"""
        dashboard = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'metrics': {},
            'alerts': {
                'active': len([a for a in self._active_alerts.values() if not a.resolved]),
                'critical': len([a for a in self._active_alerts.values() 
                               if a.level == AlertLevel.CRITICAL and not a.resolved])
            }
        }
        
        # è·å–æ‰€æœ‰æŒ‡æ ‡çš„å½“å‰å€¼å’Œç»Ÿè®¡
        for name, collector in self._collectors.items():
            current_value = collector.get_current_value()
            stats = collector.get_statistics(300)  # 5åˆ†é’Ÿçª—å£
            
            dashboard['metrics'][name] = {
                'current_value': current_value,
                'statistics': stats
            }
        
        return dashboard
    
    def _start_monitoring(self):
        """å¯åŠ¨ç›‘æ§çº¿ç¨‹"""
        if self._monitoring_thread and self._monitoring_thread.is_alive():
            return
        
        self._monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            name="MonitoringLoop",
            daemon=True
        )
        self._monitoring_thread.start()
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while not self._stop_monitoring.wait(10):  # 10ç§’æ£€æŸ¥ä¸€æ¬¡
            try:
                self._collect_system_metrics()
                self._cleanup_old_data()
            except Exception as e:
                logger.error(f"Monitoring loop error: {e}")
    
    def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
            import psutil
            
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            self.record_metric("cpu_usage_pct", cpu_percent)
            
            # å†…å­˜ä½¿ç”¨
            memory_info = psutil.virtual_memory()
            memory_mb = (memory_info.total - memory_info.available) / 1024 / 1024
            self.record_metric("memory_usage_mb", memory_mb)
            
        except ImportError:
            # psutilä¸å¯ç”¨ï¼Œè·³è¿‡ç³»ç»ŸæŒ‡æ ‡
            pass
    
    def _cleanup_old_data(self):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=24)
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æ¸…ç†æ—§æŒ‡æ ‡æ•°æ®
                cursor.execute("DELETE FROM metrics WHERE timestamp < ?", 
                             (cutoff_time.isoformat(),))
                
                # æ¸…ç†æ—§å‘Šè­¦æ•°æ®
                cursor.execute("DELETE FROM alerts WHERE timestamp < ? AND resolved = TRUE", 
                             (cutoff_time.isoformat(),))
                
                conn.commit()
        except Exception as e:
            logger.error(f"Failed to cleanup old data: {e}")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self._stop_monitoring.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=5)
        logger.info("Monitoring system stopped")


# ä¸“ç”¨ç›‘æ§å‡½æ•°
class TradingMetrics:
    """äº¤æ˜“æŒ‡æ ‡è®°å½•å™¨"""
    
    def __init__(self, monitoring_system: RealtimeMonitoringSystem):
        self.monitoring = monitoring_system
        self._order_start_times: Dict[str, float] = {}
        
    def start_order_timing(self, order_id: str):
        """å¼€å§‹è®¢å•è®¡æ—¶"""
        self._order_start_times[order_id] = time.time()
    
    def end_order_timing(self, order_id: str, success: bool = True):
        """ç»“æŸè®¢å•è®¡æ—¶"""
        if order_id in self._order_start_times:
            latency_ms = (time.time() - self._order_start_times[order_id]) * 1000
            self.monitoring.record_metric("order_latency_ms", latency_ms, 
                                        tags={'success': str(success)})
            del self._order_start_times[order_id]
    
    def record_capital_utilization(self, used_capital: float, total_capital: float):
        """è®°å½•èµ„é‡‘åˆ©ç”¨ç‡"""
        utilization_pct = (used_capital / total_capital) * 100 if total_capital > 0 else 0
        self.monitoring.record_metric("capital_utilization_pct", utilization_pct)
    
    def record_data_freshness(self, data_age_seconds: float, symbol: str = None):
        """è®°å½•æ•°æ®æ–°é²œåº¦"""
        tags = {'symbol': symbol} if symbol else {}
        self.monitoring.record_metric("data_freshness_seconds", data_age_seconds, tags=tags)
    
    def record_order_rejection(self, total_orders: int, rejected_orders: int):
        """è®°å½•æ‹’å•ç‡"""
        rejection_rate = (rejected_orders / total_orders) * 100 if total_orders > 0 else 0
        self.monitoring.record_metric("rejection_rate_pct", rejection_rate)
    
    def record_trade_result(self, pnl: float, is_win: bool):
        """è®°å½•äº¤æ˜“ç»“æœ"""
        self.monitoring.record_metric("realized_pnl_usd", pnl)
        # è®¡ç®—èƒœç‡éœ€è¦ç´¯è®¡æ•°æ®ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        win_value = 100.0 if is_win else 0.0
        self.monitoring.record_metric("win_rate_pct", win_value, tags={'trade_result': str(is_win)})


# å…¨å±€å®ä¾‹
_global_monitoring: Optional[RealtimeMonitoringSystem] = None
_global_trading_metrics: Optional[TradingMetrics] = None


def get_monitoring_system() -> RealtimeMonitoringSystem:
    """è·å–å…¨å±€ç›‘æ§ç³»ç»Ÿ"""
    global _global_monitoring
    if _global_monitoring is None:
        _global_monitoring = RealtimeMonitoringSystem()
    return _global_monitoring


def get_trading_metrics() -> TradingMetrics:
    """è·å–äº¤æ˜“æŒ‡æ ‡è®°å½•å™¨"""
    global _global_trading_metrics
    if _global_trading_metrics is None:
        monitoring = get_monitoring_system()
        _global_trading_metrics = TradingMetrics(monitoring)
    return _global_trading_metrics


if __name__ == "__main__":
    # æµ‹è¯•ç›‘æ§ç³»ç»Ÿ
    logging.basicConfig(level=logging.INFO)
    
    monitoring = RealtimeMonitoringSystem()
    trading_metrics = TradingMetrics(monitoring)
    
    # æ·»åŠ ç®€å•çš„å‘Šè­¦å›è°ƒ
    def alert_callback(alert: Alert):
        print(f"ğŸš¨ ALERT: {alert.message}")
    
    monitoring.add_alert_callback(alert_callback)
    
    # æ¨¡æ‹Ÿä¸€äº›æŒ‡æ ‡æ•°æ®
    trading_metrics.record_capital_utilization(85000, 100000)  # 85%ä½¿ç”¨ç‡
    trading_metrics.record_data_freshness(120, "AAPL")  # 2åˆ†é’Ÿå»¶è¿Ÿ
    trading_metrics.record_order_rejection(100, 3)  # 3%æ‹’å•ç‡
    
    # æ¨¡æ‹Ÿè®¢å•å»¶è¿Ÿ
    trading_metrics.start_order_timing("ORDER_001")
    time.sleep(0.1)  # 100ms
    trading_metrics.end_order_timing("ORDER_001", True)
    
    # è·å–ä»ªè¡¨ç›˜æ•°æ®
    dashboard = monitoring.get_dashboard_data()
    print("Dashboard:", json.dumps(dashboard, indent=2, default=str))
    
    # ç­‰å¾…ä¸€ä¸‹è®©ç›‘æ§çº¿ç¨‹è¿è¡Œ
    time.sleep(2)
    
    monitoring.stop_monitoring()