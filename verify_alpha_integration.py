#!/usr/bin/env python3
"""
æ·±åº¦éªŒè¯Alphaç‰¹å¾é™ç»´é›†æˆåˆ°MLè®­ç»ƒæµç¨‹
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def deep_verify_alpha_integration():
    """æ·±åº¦éªŒè¯Alphaç‰¹å¾é›†æˆçš„æ¯ä¸ªç¯èŠ‚"""
    try:
        logger.info("=== æ·±åº¦éªŒè¯Alphaç‰¹å¾é™ç»´é›†æˆ ===")
        
        # 1. éªŒè¯Alphaå¼•æ“æœ¬èº«
        logger.info("ç¬¬1æ­¥: éªŒè¯Alphaå¼•æ“...")
        from bma_models.é‡åŒ–æ¨¡å‹_bma_ultra_enhanced import UltraEnhancedQuantitativeModel
        
        model = UltraEnhancedQuantitativeModel()
        
        # æ£€æŸ¥Alphaå¼•æ“çŠ¶æ€
        alpha_engine_available = hasattr(model, 'alpha_engine') and model.alpha_engine is not None
        logger.info(f"Alphaå¼•æ“å¯ç”¨: {alpha_engine_available}")
        
        if alpha_engine_available:
            logger.info(f"Alphaå‡½æ•°æ•°é‡: {len(model.alpha_engine.alpha_functions)}")
            logger.info(f"Configä¸­çš„å› å­: {len(model.alpha_engine.config.get('alphas', []))}")
            
            # æµ‹è¯•Alphaè®¡ç®—åŠŸèƒ½
            test_data = pd.DataFrame({
                'date': pd.date_range('2023-01-01', periods=100),
                'open': np.random.randn(100) * 10 + 100,
                'high': np.random.randn(100) * 10 + 105,
                'low': np.random.randn(100) * 10 + 95, 
                'close': np.random.randn(100) * 10 + 100,
                'volume': np.random.randint(1000000, 5000000, 100)
            })
            
            try:
                alpha_result = model.alpha_engine.compute_all_alphas(test_data)
                logger.info(f"Alphaè®¡ç®—æˆåŠŸ: {alpha_result.shape if alpha_result is not None else 'None'}")
                if alpha_result is not None:
                    alpha_cols = [col for col in alpha_result.columns if col not in ['date', 'ticker']]
                    logger.info(f"ç”Ÿæˆçš„Alphaç‰¹å¾: {len(alpha_cols)}ä¸ª")
                    logger.info(f"Alphaç‰¹å¾ç¤ºä¾‹: {alpha_cols[:5]}")
                else:
                    logger.warning("Alphaè®¡ç®—è¿”å›None")
            except Exception as e:
                logger.error(f"Alphaè®¡ç®—å¤±è´¥: {e}")
        else:
            logger.error("Alphaå¼•æ“ä¸å¯ç”¨ - è¿™æ˜¯é—®é¢˜çš„æ ¹æº")
            return False
        
        # 2. éªŒè¯Alphaæ‘˜è¦å¤„ç†å™¨
        logger.info("\nç¬¬2æ­¥: éªŒè¯Alphaæ‘˜è¦å¤„ç†å™¨...")
        alpha_processor_available = hasattr(model, 'alpha_summary_processor') and model.alpha_summary_processor is not None
        logger.info(f"Alphaæ‘˜è¦å¤„ç†å™¨å¯ç”¨: {alpha_processor_available}")
        
        if not alpha_processor_available:
            logger.warning("Alphaæ‘˜è¦å¤„ç†å™¨ä¸å¯ç”¨ - é™ç»´åŠŸèƒ½æ— æ³•å·¥ä½œ")
        
        # 3. åˆ›å»ºå®Œæ•´çš„æµ‹è¯•æ•°æ®å¹¶éªŒè¯ç‰¹å¾åˆ›å»º
        logger.info("\nç¬¬3æ­¥: éªŒè¯å®Œæ•´ç‰¹å¾åˆ›å»ºæµç¨‹...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        dates = pd.date_range('2023-01-01', '2023-06-30', freq='D')
        tickers = ['AAPL', 'MSFT', 'GOOGL']
        
        test_data = []
        for date in dates[::7]:  # æ¯å‘¨ä¸€æ¬¡
            for ticker in tickers:
                test_data.append({
                    'date': date,
                    'ticker': ticker,
                    'open': 100 + np.random.randn() * 5,
                    'high': 105 + np.random.randn() * 5,
                    'low': 95 + np.random.randn() * 5,
                    'close': 100 + np.random.randn() * 5,
                    'volume': 1000000 + np.random.randint(-100000, 100000),
                    'target': np.random.randn() * 0.02,
                    'COUNTRY': 'US'
                })
        
        feature_data = pd.DataFrame(test_data)
        logger.info(f"æµ‹è¯•æ•°æ®åˆ›å»º: {feature_data.shape}")
        
        # å‡†å¤‡è‚¡ç¥¨æ•°æ®
        stock_data = {}
        for ticker in tickers:
            ticker_data = feature_data[feature_data['ticker'] == ticker].copy()
            ticker_data = ticker_data.sort_values('date').reset_index(drop=True)
            stock_data[ticker] = ticker_data[['date', 'open', 'high', 'low', 'close', 'volume', 'COUNTRY']]
        
        # 4. æµ‹è¯•ä¼ ç»Ÿç‰¹å¾åˆ›å»º
        logger.info("\nç¬¬4æ­¥: æµ‹è¯•ä¼ ç»Ÿç‰¹å¾åˆ›å»º...")
        try:
            traditional_features = model.create_traditional_features(stock_data)
            if traditional_features is not None and not traditional_features.empty:
                traditional_cols = len([col for col in traditional_features.columns 
                                      if col not in ['ticker', 'date', 'target']])
                logger.info(f"ä¼ ç»Ÿç‰¹å¾æˆåŠŸ: {traditional_features.shape}, ç‰¹å¾åˆ—æ•°: {traditional_cols}")
            else:
                logger.error("ä¼ ç»Ÿç‰¹å¾åˆ›å»ºå¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"ä¼ ç»Ÿç‰¹å¾åˆ›å»ºå¼‚å¸¸: {e}")
            return False
        
        # 5. æµ‹è¯•Alphaç‰¹å¾é›†æˆ
        logger.info("\nç¬¬5æ­¥: æµ‹è¯•Alphaç‰¹å¾é›†æˆ...")
        try:
            alpha_result = model._integrate_alpha_summary_features(traditional_features, stock_data)
            if alpha_result is not None and not alpha_result.empty:
                integrated_cols = len([col for col in alpha_result.columns 
                                     if col not in ['ticker', 'date', 'target']])
                added_alpha_features = integrated_cols - traditional_cols
                logger.info(f"Alphaé›†æˆç»“æœ: {alpha_result.shape}")
                logger.info(f"æ€»ç‰¹å¾åˆ—æ•°: {integrated_cols}")
                logger.info(f"æ–°å¢Alphaç‰¹å¾: {added_alpha_features}ä¸ª")
                
                # æ£€æŸ¥Alphaç‰¹å¾åç§°
                alpha_feature_names = [col for col in alpha_result.columns 
                                     if any(x in col.lower() for x in ['alpha_pc', 'alpha_composite', 'alpha_summary'])]
                logger.info(f"Alphaç‰¹å¾åç§°: {alpha_feature_names}")
                
                if added_alpha_features > 0:
                    logger.info("SUCCESS: Alphaç‰¹å¾æˆåŠŸæ·»åŠ !")
                    integrated_features = alpha_result
                else:
                    logger.warning("WARNING: Alphaç‰¹å¾æœªæ·»åŠ ï¼Œä½¿ç”¨ä¼ ç»Ÿç‰¹å¾")
                    integrated_features = traditional_features
            else:
                logger.warning("Alphaé›†æˆè¿”å›Noneï¼Œä½¿ç”¨ä¼ ç»Ÿç‰¹å¾")
                integrated_features = traditional_features
        except Exception as e:
            logger.error(f"Alphaç‰¹å¾é›†æˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            integrated_features = traditional_features
        
        # 6. éªŒè¯MLè®­ç»ƒæµç¨‹ä¸­çš„ç‰¹å¾ä½¿ç”¨
        logger.info("\nç¬¬6æ­¥: éªŒè¯MLè®­ç»ƒæµç¨‹ä¸­çš„ç‰¹å¾ä½¿ç”¨...")
        try:
            # æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹ä¸­çš„ç‰¹å¾æå–
            feature_cols = [col for col in integrated_features.columns 
                           if col not in ['ticker', 'date', 'target', 'COUNTRY']]
            
            X = integrated_features[feature_cols]
            y = integrated_features['target']
            
            logger.info(f"MLè®­ç»ƒç‰¹å¾çŸ©é˜µ: X.shape = {X.shape}")
            logger.info(f"MLè®­ç»ƒç›®æ ‡å˜é‡: y.shape = {y.shape}")
            logger.info(f"ç‰¹å¾åˆ—æ•°: {len(feature_cols)}")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«Alphaç‰¹å¾
            alpha_features_in_X = [col for col in feature_cols 
                                 if any(x in col.lower() for x in ['alpha_pc', 'alpha_composite', 'alpha_summary'])]
            logger.info(f"Xä¸­çš„Alphaç‰¹å¾: {len(alpha_features_in_X)}ä¸ª")
            logger.info(f"Alphaç‰¹å¾åç§°: {alpha_features_in_X}")
            
            # éªŒè¯æ•°æ®è´¨é‡
            nan_count = X.isnull().sum().sum()
            inf_count = np.isinf(X.select_dtypes(include=[np.number])).sum().sum()
            
            logger.info(f"æ•°æ®è´¨é‡æ£€æŸ¥: NaN={nan_count}, Inf={inf_count}")
            
            if len(alpha_features_in_X) > 0:
                logger.info("ğŸ‰ SUCCESS: Alphaç‰¹å¾å·²æˆåŠŸé›†æˆåˆ°MLè®­ç»ƒæµç¨‹!")
                return True
            else:
                logger.warning("âš ï¸ WARNING: MLè®­ç»ƒæµç¨‹ä¸­æœªå‘ç°Alphaç‰¹å¾")
                # ä½†ä¼ ç»Ÿç‰¹å¾å·¥ä½œæ­£å¸¸ä¹Ÿç®—éƒ¨åˆ†æˆåŠŸ
                if X.shape[1] > 10:  # è‡³å°‘æœ‰ä¸€äº›ç‰¹å¾
                    logger.info("âœ“ ä¼ ç»Ÿç‰¹å¾æ­£å¸¸å·¥ä½œï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
                    return "partial"
                else:
                    logger.error("âŒ ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œç³»ç»Ÿä¸å¯ç”¨")
                    return False
                    
        except Exception as e:
            logger.error(f"MLè®­ç»ƒæµç¨‹éªŒè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        
    except Exception as e:
        logger.error(f"éªŒè¯è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    result = deep_verify_alpha_integration()
    
    print("\n" + "="*60)
    print("æ·±åº¦éªŒè¯ç»“æœ:")
    print("="*60)
    
    if result is True:
        print("ğŸ‰ å®Œå…¨æˆåŠŸ: Alphaç‰¹å¾é™ç»´å·²å®Œå…¨é›†æˆåˆ°MLè®­ç»ƒæµç¨‹")
        print("âœ“ Alphaå¼•æ“å·¥ä½œæ­£å¸¸")  
        print("âœ“ é™ç»´å¤„ç†æˆåŠŸ")
        print("âœ“ ç‰¹å¾è‡ªåŠ¨åŒ…å«åœ¨MLè®­ç»ƒä¸­")
    elif result == "partial":
        print("âš ï¸ éƒ¨åˆ†æˆåŠŸ: ç³»ç»ŸåŸºæœ¬å¯ç”¨ä½†Alphaç‰¹å¾é›†æˆæœªå®Œå…¨å·¥ä½œ")
        print("âœ“ ä¼ ç»Ÿç‰¹å¾æ­£å¸¸")
        print("âš ï¸ Alphaç‰¹å¾é›†æˆéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    else:
        print("âŒ å¤±è´¥: Alphaç‰¹å¾é™ç»´é›†æˆå­˜åœ¨ä¸¥é‡é—®é¢˜")
        print("éœ€è¦æ£€æŸ¥å’Œä¿®å¤å…³é”®ç»„ä»¶")
    print("="*60)