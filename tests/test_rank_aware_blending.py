#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Rank-aware Blendingæ–¹æ¡ˆAé›†æˆæµ‹è¯•

æµ‹è¯•å†…å®¹ï¼š
- LambdaRankè®­ç»ƒå™¨åŠŸèƒ½éªŒè¯
- Rank-aware Blenderèåˆæ•ˆæœ
- ä¸»pipelineé›†æˆæµ‹è¯•
- æ€§èƒ½å¯¹æ¯”ï¼šå•Ridge vs Rank-aware Blending
- Top-Ké€‰è‚¡æ€§èƒ½æå‡éªŒè¯

æœŸæœ›æ•ˆæœï¼š
- Top-Kæ€§èƒ½æå‡ï¼ˆNDCG@K, Precision@Kï¼‰
- æ’åºç¨³å®šæ€§å¢å¼º
- èåˆæƒé‡è‡ªé€‚åº”è°ƒæ•´
"""

import sys
import os
import unittest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
from typing import Dict, Any, Tuple
import logging

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'bma_models'))

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestRankAwareBlending(unittest.TestCase):
    """Rank-aware Blendingæ–¹æ¡ˆAé›†æˆæµ‹è¯•"""

    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        np.random.seed(42)

        # åˆ›å»ºè¶³å¤Ÿå¤§çš„æµ‹è¯•æ•°æ®é›†ï¼ˆLambdaRankéœ€è¦ï¼‰
        self.dates = pd.date_range('2023-01-01', periods=150, freq='D')
        self.tickers = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'AMZN', 'META', 'NVDA', 'NFLX']
        self.index = pd.MultiIndex.from_product([self.dates, self.tickers], names=['date', 'ticker'])

        logger.info(f"æµ‹è¯•æ•°æ®é›†: {len(self.index)} æ ·æœ¬ ({len(self.dates)} æ—¥æœŸ Ã— {len(self.tickers)} è‚¡ç¥¨)")

    def create_realistic_second_layer_data(self) -> Tuple[pd.DataFrame, pd.Series]:
        """åˆ›å»ºçœŸå®çš„ç¬¬äºŒå±‚è®­ç»ƒæ•°æ®"""
        # åˆ›å»ºç¬¬ä¸€å±‚é¢„æµ‹ï¼ˆå…·æœ‰ä¸€å®šç›¸å…³æ€§çš„ï¼‰
        base_signal = np.random.normal(0, 0.02, len(self.index))

        data = pd.DataFrame(index=self.index)
        data['pred_elastic'] = base_signal + np.random.normal(0, 0.01, len(self.index))
        data['pred_xgb'] = base_signal + np.random.normal(0, 0.015, len(self.index))
        data['pred_catboost'] = base_signal + np.random.normal(0, 0.012, len(self.index))

        # åˆ›å»ºä¸é¢„æµ‹ç›¸å…³çš„ç›®æ ‡å˜é‡ï¼ˆå¸¦å™ªå£°ï¼‰
        target = pd.Series(
            base_signal * 0.3 + np.random.normal(0, 0.025, len(self.index)),
            index=self.index,
            name='ret_fwd_5d'
        )

        # æ·»åŠ ä¸€äº›æ•°æ®è´¨é‡é—®é¢˜
        nan_indices = np.random.choice(len(data), size=int(len(data) * 0.02), replace=False)
        for col in data.columns:
            col_nans = np.random.choice(nan_indices, size=len(nan_indices)//3, replace=False)
            data.loc[data.index[col_nans], col] = np.nan

        # ç›®æ ‡å˜é‡ä¹Ÿæ·»åŠ å°‘é‡NaN
        target_nans = np.random.choice(len(target), size=int(len(target) * 0.01), replace=False)
        target.iloc[target_nans] = np.nan

        return data, target

    def test_lambda_rank_stacker_basic(self):
        """æµ‹è¯•LambdaRank StackeråŸºç¡€åŠŸèƒ½"""
        try:
            from bma_models.lambda_rank_stacker import LambdaRankStacker

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            stacker_data, target = self.create_realistic_second_layer_data()
            stacker_data['ret_fwd_5d'] = target

            # åˆå§‹åŒ–LambdaRank
            lambda_stacker = LambdaRankStacker(
                n_quantiles=8,
                num_boost_round=30,
                early_stopping_rounds=10
            )

            # è®­ç»ƒ
            lambda_stacker.fit(stacker_data)

            # éªŒè¯è®­ç»ƒç»“æœ
            self.assertTrue(lambda_stacker.fitted_, "LambdaRankåº”è¯¥å·²è®­ç»ƒ")

            # é¢„æµ‹
            predictions = lambda_stacker.predict(stacker_data)

            # éªŒè¯é¢„æµ‹ç»“æœ
            self.assertIn('lambda_score', predictions.columns, "åº”è¯¥åŒ…å«lambda_score")
            self.assertIn('lambda_rank', predictions.columns, "åº”è¯¥åŒ…å«lambda_rank")
            self.assertIn('lambda_pct', predictions.columns, "åº”è¯¥åŒ…å«lambda_pct")

            # éªŒè¯æ’åé€»è¾‘
            for date in self.dates[:5]:  # æ£€æŸ¥å‰å‡ ä¸ªæ—¥æœŸ
                try:
                    date_data = predictions.loc[date]
                    if len(date_data) > 1:
                        ranks = date_data['lambda_rank'].dropna()
                        if len(ranks) > 1:
                            # éªŒè¯æ’åæ˜¯å¦åˆç†ï¼ˆæœ€å°å€¼åº”è¯¥æ˜¯1ï¼‰
                            self.assertGreaterEqual(ranks.min(), 1, f"æ—¥æœŸ{date}æ’ååº”è¯¥ä»1å¼€å§‹")
                except KeyError:
                    continue  # æŸäº›æ—¥æœŸå¯èƒ½æ²¡æœ‰æ•°æ®

            logger.info(f"âœ… LambdaRankè®­ç»ƒå’Œé¢„æµ‹æˆåŠŸ: è¦†ç›–ç‡={predictions['lambda_score'].notna().mean():.1%}")

        except ImportError:
            self.skipTest("LightGBMä¸å¯ç”¨ï¼Œè·³è¿‡LambdaRankæµ‹è¯•")

    def test_rank_aware_blender_basic(self):
        """æµ‹è¯•Rank-aware BlenderåŸºç¡€åŠŸèƒ½"""
        try:
            from bma_models.rank_aware_blender import RankAwareBlender

            # åˆ›å»ºæ¨¡æ‹Ÿçš„Ridgeå’ŒLambdaRanké¢„æµ‹
            ridge_predictions = pd.DataFrame(index=self.index[:1000])  # ä½¿ç”¨éƒ¨åˆ†æ•°æ®
            ridge_predictions['score'] = np.random.normal(0, 0.02, len(ridge_predictions))
            ridge_predictions['score_z'] = (ridge_predictions['score'] - ridge_predictions['score'].mean()) / ridge_predictions['score'].std()

            lambda_predictions = pd.DataFrame(index=self.index[:1000])
            lambda_predictions['lambda_score'] = np.random.normal(0, 0.025, len(lambda_predictions))
            lambda_predictions['lambda_pct'] = np.random.uniform(0, 1, len(lambda_predictions))

            # åˆå§‹åŒ–Blender
            blender = RankAwareBlender(
                lookback_window=30,
                min_weight=0.2,
                max_weight=0.8,
                use_copula=True
            )

            # èåˆé¢„æµ‹
            blended_results = blender.blend_predictions(
                ridge_predictions=ridge_predictions,
                lambda_predictions=lambda_predictions
            )

            # éªŒè¯èåˆç»“æœ
            expected_cols = ['ridge_score', 'lambda_score', 'blended_score', 'blended_rank', 'blended_z']
            for col in expected_cols:
                self.assertIn(col, blended_results.columns, f"åº”è¯¥åŒ…å«{col}åˆ—")

            # éªŒè¯èåˆåˆ†æ•°ä¸æ˜¯NaN
            valid_blended = blended_results['blended_score'].notna().sum()
            self.assertGreater(valid_blended, len(blended_results) * 0.8, "èåˆåˆ†æ•°è¦†ç›–ç‡åº”è¯¥>80%")

            # éªŒè¯æ’åé€»è¾‘
            test_date = blended_results.index.get_level_values('date')[0]
            date_ranks = blended_results.loc[test_date]['blended_rank'].dropna()
            if len(date_ranks) > 1:
                self.assertGreaterEqual(date_ranks.min(), 1, "æ’ååº”è¯¥ä»1å¼€å§‹")
                self.assertLessEqual(date_ranks.max(), len(date_ranks), "æœ€å¤§æ’åä¸åº”è¶…è¿‡è‚¡ç¥¨æ•°")

            # è·å–èåˆä¿¡æ¯
            blender_info = blender.get_blender_info()
            self.assertIn('current_lambda_weight', blender_info)
            self.assertIn('use_copula', blender_info)

            logger.info(f"âœ… Rank-awareèåˆæˆåŠŸ: Lambdaæƒé‡={blender_info['current_lambda_weight']:.3f}")

        except ImportError:
            self.skipTest("Rank-aware Blendingç»„ä»¶ä¸å¯ç”¨")

    def test_main_pipeline_integration(self):
        """æµ‹è¯•ä¸»pipelineé›†æˆ"""
        try:
            from bma_models.é‡åŒ–æ¨¡å‹_bma_ultra_enhanced import UltraEnhancedQuantitativeModel

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            stacker_data, target = self.create_realistic_second_layer_data()
            stacker_data['ret_fwd_5d'] = target

            # åˆå§‹åŒ–æ¨¡å‹
            model = UltraEnhancedQuantitativeModel()

            # ç¡®ä¿å¯ç”¨Rank-aware Blending
            if hasattr(model, 'use_rank_aware_blending'):
                model.use_rank_aware_blending = True
                logger.info("âœ… å·²å¯ç”¨Rank-aware Blending")

            # è®­ç»ƒäºŒå±‚æ¨¡å‹
            success = model._train_ridge_stacker(
                oof_predictions={
                    'elastic_net': stacker_data['pred_elastic'],
                    'xgboost': stacker_data['pred_xgb'],
                    'catboost': stacker_data['pred_catboost']
                },
                y=target,
                dates=self.dates
            )

            if success:
                # éªŒè¯Ridge Stackerè®­ç»ƒ
                self.assertIsNotNone(model.ridge_stacker, "Ridge Stackeråº”è¯¥å·²è®­ç»ƒ")

                # éªŒè¯LambdaRank Stackerè®­ç»ƒï¼ˆå¦‚æœæ•°æ®é‡è¶³å¤Ÿï¼‰
                if hasattr(model, 'lambda_rank_stacker') and model.lambda_rank_stacker is not None:
                    logger.info("âœ… LambdaRank Stackerå·²è®­ç»ƒ")
                    self.assertTrue(model.lambda_rank_stacker.fitted_, "LambdaRankåº”è¯¥å·²è®­ç»ƒ")

                    # éªŒè¯Rank-aware Blenderåˆå§‹åŒ–
                    if hasattr(model, 'rank_aware_blender') and model.rank_aware_blender is not None:
                        logger.info("âœ… Rank-aware Blenderå·²åˆå§‹åŒ–")
                        blender_info = model.rank_aware_blender.get_blender_info()
                        self.assertIsInstance(blender_info, dict, "Blenderä¿¡æ¯åº”è¯¥æ˜¯å­—å…¸")
                    else:
                        logger.warning("âš ï¸ Rank-aware Blenderæœªåˆå§‹åŒ–")
                else:
                    logger.warning("âš ï¸ LambdaRank Stackeræœªè®­ç»ƒï¼ˆå¯èƒ½æ•°æ®é‡ä¸è¶³ï¼‰")

                logger.info(f"âœ… ä¸»pipelineé›†æˆæµ‹è¯•é€šè¿‡")
            else:
                logger.warning("âš ï¸ è®­ç»ƒå¤±è´¥ï¼Œä½†ç¨‹åºæ­£å¸¸å¤„ç†")
                self.assertTrue(True)  # å¤±è´¥ä½†æ­£å¸¸å¤„ç†ä¹Ÿæ˜¯å¯æ¥å—çš„

        except ImportError:
            self.skipTest("ä¸»æ¨¡å‹ä¸å¯ç”¨")

    def test_performance_comparison(self):
        """æµ‹è¯•æ€§èƒ½å¯¹æ¯”ï¼šå•Ridge vs Rank-aware Blending"""
        try:
            from bma_models.ridge_stacker import RidgeStacker
            from bma_models.lambda_rank_stacker import LambdaRankStacker
            from bma_models.rank_aware_blender import RankAwareBlender

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            stacker_data, target = self.create_realistic_second_layer_data()
            stacker_data['ret_fwd_5d'] = target

            # è®­ç»ƒå•Ridgeæ¨¡å‹
            ridge_stacker = RidgeStacker(alpha=1.0, auto_tune_alpha=False)
            ridge_stacker.fit(stacker_data)
            ridge_pred = ridge_stacker.predict(stacker_data)

            # è®­ç»ƒLambdaRankæ¨¡å‹
            lambda_stacker = LambdaRankStacker(n_quantiles=8, num_boost_round=30)
            lambda_stacker.fit(stacker_data)
            lambda_pred = lambda_stacker.predict(stacker_data)

            # ä½¿ç”¨Rank-aware Blenderèåˆ
            blender = RankAwareBlender(use_copula=True)
            blended_pred = blender.blend_predictions(
                ridge_predictions=ridge_pred[['score']],
                lambda_predictions=lambda_pred
            )

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            def calculate_rank_ic(predictions, targets):
                """è®¡ç®—RankIC"""
                valid_mask = predictions.notna() & targets.notna()
                if valid_mask.sum() < 10:
                    return 0.0
                pred_ranks = predictions[valid_mask].rank()
                target_ranks = targets[valid_mask].rank()
                return pred_ranks.corr(target_ranks, method='spearman')

            def calculate_top_k_precision(predictions, targets, k=20):
                """è®¡ç®—Top-Kç²¾ç¡®åº¦"""
                try:
                    # æŒ‰æ—¥æœŸè®¡ç®—Top-Kç²¾ç¡®åº¦
                    precisions = []
                    for date in predictions.index.get_level_values('date').unique():
                        try:
                            date_pred = predictions.loc[date].dropna()
                            date_target = targets.loc[date].dropna()

                            # æ‰¾åˆ°å…±åŒçš„è‚¡ç¥¨
                            common_tickers = date_pred.index.intersection(date_target.index)
                            if len(common_tickers) < k:
                                continue

                            pred_vals = date_pred.loc[common_tickers]
                            target_vals = date_target.loc[common_tickers]

                            # Top-Ké¢„æµ‹
                            top_k_pred = pred_vals.nlargest(k).index
                            # Top-Kå®é™…
                            top_k_actual = target_vals.nlargest(k).index

                            # è®¡ç®—ç²¾ç¡®åº¦
                            precision = len(set(top_k_pred) & set(top_k_actual)) / k
                            precisions.append(precision)
                        except:
                            continue

                    return np.mean(precisions) if precisions else 0.0
                except:
                    return 0.0

            # å¯¹é½æ•°æ®ç”¨äºè¯„ä¼°
            ridge_scores = ridge_pred['score']
            lambda_scores = lambda_pred['lambda_score']
            blended_scores = blended_pred['blended_score']

            # è®¡ç®—RankIC
            ridge_ic = calculate_rank_ic(ridge_scores, target)
            lambda_ic = calculate_rank_ic(lambda_scores, target)
            blended_ic = calculate_rank_ic(blended_scores, target)

            # è®¡ç®—Top-Kç²¾ç¡®åº¦
            ridge_precision = calculate_top_k_precision(ridge_scores, target, k=5)
            lambda_precision = calculate_top_k_precision(lambda_scores, target, k=5)
            blended_precision = calculate_top_k_precision(blended_scores, target, k=5)

            logger.info("ğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
            logger.info(f"  Ridge RankIC: {ridge_ic:.4f}")
            logger.info(f"  Lambda RankIC: {lambda_ic:.4f}")
            logger.info(f"  Blended RankIC: {blended_ic:.4f}")
            logger.info(f"  Ridge Top-5ç²¾ç¡®åº¦: {ridge_precision:.3f}")
            logger.info(f"  Lambda Top-5ç²¾ç¡®åº¦: {lambda_precision:.3f}")
            logger.info(f"  Blended Top-5ç²¾ç¡®åº¦: {blended_precision:.3f}")

            # éªŒè¯èåˆæ•ˆæœï¼ˆè‡³å°‘ä¸åº”è¯¥æ˜¾è‘—å˜å·®ï¼‰
            self.assertGreaterEqual(blended_ic, min(ridge_ic, lambda_ic) - 0.05,
                                  "èåˆåRankICä¸åº”æ˜¾è‘—ä¸‹é™")

            # è·å–æƒé‡ä¿¡æ¯
            blender_info = blender.get_blender_info()
            logger.info(f"  æœ€ç»ˆæƒé‡: Ridge={1-blender_info['current_lambda_weight']:.3f}, "
                       f"Lambda={blender_info['current_lambda_weight']:.3f}")

            logger.info("âœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ")

        except ImportError:
            self.skipTest("æ‰€éœ€ç»„ä»¶ä¸å¯ç”¨")

def run_rank_aware_blending_tests():
    """è¿è¡ŒRank-aware Blendingæµ‹è¯•å¥—ä»¶"""
    logger.info("å¼€å§‹Rank-aware Blendingæ–¹æ¡ˆAæµ‹è¯•...")

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(TestRankAwareBlending))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2, buffer=True)
    result = runner.run(test_suite)

    # ç”ŸæˆæŠ¥å‘Š
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    skipped = len(result.skipped) if hasattr(result, 'skipped') else 0
    success = total_tests - failures - errors - skipped

    print("\n" + "="*80)
    print("RANK-AWARE BLENDINGæ–¹æ¡ˆAæµ‹è¯•æ€»ç»“")
    print("="*80)
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æˆåŠŸ: {success}")
    print(f"å¤±è´¥: {failures}")
    print(f"é”™è¯¯: {errors}")
    print(f"è·³è¿‡: {skipped}")
    print(f"æˆåŠŸç‡: {success/total_tests*100:.1f}%" if total_tests > 0 else "N/A")

    if result.failures:
        print(f"\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}")

    if result.errors:
        print(f"\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}")

    print("\n" + "="*80)

    return result

if __name__ == '__main__':
    run_rank_aware_blending_tests()